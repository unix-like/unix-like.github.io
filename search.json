[{"title":"命令行的艺术","url":"/2017/06/01/system/命令行的艺术/","content":"\n\n\n<ul>\n<li><a href=\"#%E5%89%8D%E8%A8%80\">前言</a></li>\n<li><a href=\"#%E5%9F%BA%E7%A1%80\">基础</a></li>\n<li><a href=\"#%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8\">日常使用</a></li>\n<li><a href=\"#%E6%96%87%E4%BB%B6%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86\">文件及数据处理</a></li>\n<li><a href=\"#%E7%B3%BB%E7%BB%9F%E8%B0%83%E8%AF%95\">系统调试</a></li>\n<li><a href=\"#%E5%8D%95%E8%A1%8C%E8%84%9A%E6%9C%AC\">单行脚本</a></li>\n<li><a href=\"#%E5%86%B7%E9%97%A8%E4%BD%86%E6%9C%89%E7%94%A8\">冷门但有用</a></li>\n<li><a href=\"#%E4%BB%85%E9%99%90-os-x-%E7%B3%BB%E7%BB%9F\">仅限 OS X 系统</a></li>\n<li><a href=\"#%E4%BB%85%E9%99%90-windows-%E7%B3%BB%E7%BB%9F\">仅限 Windows 系统</a></li>\n<li><a href=\"#%E6%9B%B4%E5%A4%9A%E8%B5%84%E6%BA%90\">更多资源</a></li>\n<li><a href=\"#%E5%85%8D%E8%B4%A3%E5%A3%B0%E6%98%8E\">免责声明</a></li>\n</ul>\n\n<!-- more -->\n\n<p>熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文是一份我在 Linux 上工作时，发现的一些命令行使用技巧的摘要。有些技巧非常基础，而另一些则相当复杂，甚至晦涩难懂。这篇文章并不长，但当你能够熟练掌握这里列出的所有技巧时，你就学会了很多关于命令行的东西了。</p>\n\n<p>这篇文章是<a href=\"/jlevy/the-art-of-command-line/blob/master/AUTHORS.md\">许多作者和译者</a>共同的成果。\n这里的部分内容\n<a href=\"http://www.quora.com/What-are-some-lesser-known-but-useful-Unix-commands\">首次</a>\n<a href=\"http://www.quora.com/What-are-the-most-useful-Swiss-army-knife-one-liners-on-Unix\">出现</a>\n于 <a href=\"http://www.quora.com/What-are-some-time-saving-tips-that-every-Linux-user-should-know\">Quora</a>，\n但已经迁移到了 Github，并由众多高手做出了许多改进。\n如果你在本文中发现了错误或者存在可以改善的地方，请<a href=\"/jlevy/the-art-of-command-line/blob/master/CONTRIBUTING.md\"><strong>贡献你的一份力量</strong></a>。</p>\n\n<h2><a id=\"user-content-前言\" class=\"anchor\" href=\"#前言\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>前言</h2>\n\n<p>涵盖范围：</p>\n\n<ul>\n<li>这篇文章对刚接触命令行的新手，以及具有命令行使用经验的人都有用处。本文致力于做到<em>覆盖面广</em>（尽量包括一切重要的内容），<em>具体</em>（给出最常见的具体的例子），以及<em>简洁</em>（避免不必要的，或是可以在其他地方轻松查到的细枝末节）。每个技巧在特定情境下或是基本的，或是能显著节约时间。</li>\n<li>本文为 Linux 所写，除了<a href=\"#%E4%BB%85%E9%99%90-os-x-%E7%B3%BB%E7%BB%9F\">仅限 OS X 系统</a>和<a href=\"#%E4%BB%85%E9%99%90-windows-%E7%B3%BB%E7%BB%9F\">仅限 Windows 系统</a>的部分。其它节中的大部分内容都适用于其它 Unix 系统或 OS X，甚至 Cygwin。</li>\n<li>本文关注于交互式 Bash，尽管很多技巧也适用于其他 shell 或 Bash 脚本。</li>\n<li>本文包括了“标准的”Unix 命令和需要安装特定包的命令，只要它们足够重要。</li>\n</ul>\n\n<p>注意事项：</p>\n\n<ul>\n<li>为了能在一页内展示尽量多的东西，一些具体的信息会被间接地包含在引用页里。聪明机智的你，如果掌握了使用 Google 搜索引擎的基本思路与命令，那么你将可以查阅到更多的详细信息。使用 <code>apt-get</code>，<code>yum</code>，<code>dnf</code>，<code>pacman</code>，\n<code>pip</code> 或 <code>brew</code>（以及其它合适的包管理器）来安装新程序。</li>\n<li>使用 <a href=\"http://explainshell.com/\">Explainshell</a> 去获取相关命令、参数、管道等内容的解释。</li>\n</ul>\n\n<h2><a id=\"user-content-基础\" class=\"anchor\" href=\"#基础\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>基础</h2>\n\n<ul>\n<li>学习 Bash 的基础知识。具体来说，输入 <code>man bash</code> 并至少全文浏览一遍; 它很简单并且不长。其他的 shell 可能很好用，但 Bash 功能强大到几乎所有情况下都是可用的 （ <em>只</em>学习 zsh，fish 或其他的 shell 的话，在你自己的电脑上会显得很方便，但在很多情况下会限制你，比如当你需要在服务器上工作时）。</li>\n<li>学习并掌握至少一个基于文本的编辑器。通常 Vim （<code>vi</code>） 会是你最好的选择，因为在终端里进行随机编辑，Vim 真的毫无敌手，哪怕是 Emacs、某大型 IDE 甚至时下非常流行的编辑器。</li>\n<li>学会如何使用 <code>man</code> 命令去阅读文档。学会使用 <code>apropos</code> 去查找文档。了解有些命令并不对应可执行文件，而是Bash内置的，可以使用 <code>help</code> 和 <code>help -d</code> 命令获取帮助信息。你可以用 <code>type 命令</code> 来判断它到底是可执行文件、shell 内置命令、还是别名。</li>\n<li>学会使用 <code>&gt;</code> 和 <code>&lt;</code> 来重定向输出和输入，学会使用 <code>|</code> 来重定向管道。明白 <code>&gt;</code> 会覆盖了输出文件而 <code>&gt;&gt;</code> 是在文件末添加。了解标准输出 stdout 和标准错误 stderr。</li>\n<li>学会使用通配符 <code>*</code> （或许再算上 <code>?</code> 和 <code>[</code>...<code>]</code>） 和引用以及引用中 <code>'</code> 和 <code>\"</code> 的区别。</li>\n<li>熟悉 Bash 任务管理工具：<code>&amp;</code>，<strong>ctrl-z</strong>，<strong>ctrl-c</strong>，<code>jobs</code>，<code>fg</code>，<code>bg</code>，<code>kill</code> 等。</li>\n<li>了解 <code>ssh</code>，以及学会通过使用 <code>ssh-agent</code>，<code>ssh-add</code> 等命令来实现基本的无密码认证。</li>\n<li>学会基本的文件管理：<code>ls</code> 和 <code>ls -l</code> （了解 <code>ls -l</code> 中每一列代表的意义），<code>less</code>，<code>head</code>，<code>tail</code> 和 <code>tail -f</code> （甚至 <code>less +F</code>），<code>ln</code> 和 <code>ln -s</code> （了解硬链接与软链接的区别），<code>chown</code>，<code>chmod</code>，<code>du</code> （硬盘使用情况概述：<code>du -hs *</code>）。 关于文件系统的管理，学习 <code>df</code>，<code>mount</code>，<code>fdisk</code>，<code>mkfs</code>，<code>lsblk</code>。知道 inode 是什么（与 <code>ls -i</code> 和 <code>df -i</code> 等命令相关）。</li>\n<li>学习基本的网络管理：<code>ip</code> 或 <code>ifconfig</code>，<code>dig</code>。</li>\n<li>学习并使用一种版本控制管理系统，例如 <code>git</code>。</li>\n<li>熟悉正则表达式，以及 <code>grep</code>／<code>egrep</code> 里不同参数的作用，例如 <code>-i</code>，<code>-o</code>，<code>-v</code>，<code>-A</code>，<code>-B</code> 和 <code>-C</code>，这些参数是值得学习并掌握的。</li>\n<li>学会使用 <code>apt-get</code>，<code>yum</code>，<code>dnf</code> 或 <code>pacman</code> （取决于你使用的 Linux 发行版）来查找或安装软件包。并确保你的环境中有 <code>pip</code> 来安装基于 Python 的命令行工具 （接下来提到的部分程序使用 <code>pip</code> 来安装会很方便）。</li>\n</ul>\n\n<h2><a id=\"user-content-日常使用\" class=\"anchor\" href=\"#日常使用\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>日常使用</h2>\n\n<ul>\n<li>在 Bash 中，可以使用 <strong>Tab</strong> 自动补全参数，使用 <strong>ctrl-r</strong> 搜索命令行历史（在按下之后，键入便可以搜索，重复按下 <strong>ctrl-r</strong> 会在更多匹配中循环，按下 <strong>Enter</strong> 会执行找到的命令，按下右方向键会将结果放入当前行中，使你可以进行编辑）。</li>\n<li>在 Bash 中，可以使用 <strong>ctrl-w</strong> 删除你键入的最后一个单词，使用 <strong>ctrl-u</strong> 删除整行，使用 <strong>alt-b</strong> 和 <strong>alt-f</strong> 以单词为单位移动光标，使用 <strong>ctrl-a</strong> 将光标移至行首，使用 <strong>ctrl-e</strong> 将光标移至行尾，使用 <strong>ctrl-k</strong> 删除光标至行尾的所有内容，使用 <strong>ctrl-l</strong> 清屏。键入 <code>man readline</code> 查看 Bash 中的默认快捷键，内容很多。例如 <strong>alt-.</strong> 循环地移向前一个参数，以及 <strong>alt-</strong>* 展开通配符。</li>\n<li>你喜欢的话，可以键入 <code>set -o vi</code> 来使用 vi 风格的快捷键，而 <code>set -o emacs</code> 可以把它改回来。</li>\n<li>为了方便地键入长命令，在设置你的编辑器后（例如 <code>export EDITOR=vim</code>），键入 <strong>ctrl-x</strong> <strong>ctrl-e</strong> 会打开一个编辑器来编辑当前命令。在 vi 模式下则键入 <strong>escape-v</strong> 实现相同的功能。</li>\n<li>键入 <code>history</code> 查看命令行历史记录，再用 <code>!n</code>（<code>n</code> 是命令编号）就可以再次执行。其中有许多缩写，最有用的大概就是用 <code>!$</code> 指代上次键入的参数，以及用 <code>!!</code> 指代上次键入的命令了（参考 man 页面中的“HISTORY EXPANSION”）。不过这些通常被 <strong>ctrl-r</strong> 和 <strong>alt-.</strong> 取代。</li>\n<li>要进入 home 目录可以用 <code>cd</code>。要访问你的 home 目录中的文件，可以使用前缀 <code>~</code>（例如 <code>~/.bashrc</code>）。在 <code>sh</code> 脚本里则用 <code>$HOME</code> 指代 home 目录。</li>\n<li>回到上一个工作路径：<code>cd -</code></li>\n<li>如果你输入命令的时候改变了主意，按下 <strong>alt-#</strong> 在行首添加 <code>#</code>，或者依次按下 <strong>ctrl-a</strong>， <strong>#</strong>， <strong>enter</strong>。这样做的话，之后你可以很方便的利用命令行历史回到你刚才输入到一半的命令。</li>\n<li>使用 <code>xargs</code> （ 或 <code>parallel</code>）。他们非常给力。注意到你可以控制每行参数个数（<code>-L</code>）和最大并行数（<code>-P</code>）。如果你不确定它们是否会按你想的那样工作，先使用 <code>xargs echo</code> 查看一下。此外，使用 <code>-I{}</code> 会很方便。例如：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      find <span class=\"pl-c1\">.</span> -name <span class=\"pl-s\"><span class=\"pl-pds\">'</span>*.py<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> xargs grep some_function\n      cat hosts <span class=\"pl-k\">|</span> xargs -I{} ssh root@{} hostname</pre></div>\n\n<ul>\n<li><code>pstree -p</code> 有助于展示进程树。</li>\n<li>使用 <code>pgrep</code> 和 <code>pkill</code> 根据名字查找进程或发送信号（<code>-f</code> 参数通常有用）。</li>\n<li>了解你可以发往进程的信号的种类。比如，使用 <code>kill -STOP [pid]</code> 停止一个进程。使用 <code>man 7 signal</code> 查看详细列表。</li>\n<li>使用 <code>nohup</code> 或 <code>disown</code> 使一个后台进程持续运行。</li>\n<li>使用 <code>netstat -lntp</code> 或 <code>ss -plat</code> 检查哪些进程在监听端口（默认是检查 TCP 端口; 使用参数 <code>-u</code> 检查 UDP 端口）。</li>\n<li>有关打开套接字和文件，请参阅 <code>lsof</code>。</li>\n<li>使用 <code>uptime</code> 或 <code>w</code> 来查看系统已经运行多长时间。</li>\n<li>使用 <code>alias</code> 来创建常用命令的快捷形式。例如：<code>alias ll='ls -latr'</code> 创建了一个新的命令别名 <code>ll</code>。</li>\n<li>把别名、shell 选项和常用函数保存在 <code>~/.bashrc</code>，然后<a href=\"http://superuser.com/a/183980/7106\">安排登陆 shell 来读取</a>。这样你就可以在所有 shell 会话中使用你的设定。</li>\n<li>把环境变量的设定以及登陆时要执行的命令保存在 <code>~/.bash_profile</code>。对于从图形界面启动的，以及 <code>cron</code> 工作的 shell，需要单独配置。</li>\n<li>要在几台电脑中同步你的配置文件（例如 <code>.bashrc</code> 和 <code>.bash_profile</code>），可以用 Git。</li>\n<li>当变量和文件名中包含空格的时候要格外小心。Bash 变量要用引号括起来，比如 <code>\"FOO\"</code>。尽量使用 <code>-0</code> 或 <code>-print0</code> 选项以便用空字符来分隔文件名，例如 <code>locate -0 pattern | xargs -0 ls -al</code> 或 <code>find / -print0 -type d | xargs -0 ls -al</code>。如果 for 循环中循环访问的文件名含有空格，只需用 <code>IFS=$'\\n'</code> 把内部字段分隔符设为换行符。</li>\n<li>在 Bash 脚本中，使用 <code>set -x</code> 去调试输出，尽可能地使用严格模式，使用 <code>set -e</code> 令脚本在发生错误时退出而不是继续运行，使用 <code>set -u</code> 来检查是否使用了未赋值的变量，使用 <code>set -o pipefail</code> 严谨地对待错误（尽管问题可能很微妙）。当牵扯到很多脚本时，使用 <code>trap</code>。一个好的习惯是在脚本文件开头这样写，这会使它检测一些错误，并在错误发生时中断程序并输出信息：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      <span class=\"pl-c1\">set</span> -euo pipefail\n      <span class=\"pl-c1\">trap</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>echo 'error: Script failed: see failed command above'<span class=\"pl-pds\">\"</span></span> ERR</pre></div>\n\n<ul>\n<li>在 Bash 脚本中，子 shell（使用括号 <code>(...)</code>）是一种组织参数的便捷方式。一个常见的例子是临时地移动工作路径，代码如下：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      <span class=\"pl-c\"># do something in current dir</span>\n      (<span class=\"pl-c1\">cd</span> /some/other/dir <span class=\"pl-k\">&amp;&amp;</span> other-command)\n      <span class=\"pl-c\"># continue in original dir</span></pre></div>\n\n<ul>\n<li>在 Bash 中，要注意其中有许多形式的扩展。检查变量是否存在：<code>${name:?error message}</code>。例如，当 Bash 脚本需要一个参数时，可以使用这样的代码 <code>input_file=${1:?usage: $0 input_file}</code>。数学表达式：<code>i=$(( (i + 1) % 5 ))</code>。序列：<code>{1..10}</code>。截断字符串：<code>${var%suffix}</code> 和 <code>${var#prefix}</code>。例如，假设 <code>var=foo.pdf</code>，那么 <code>echo ${var%.pdf}.txt</code> 将输出 <code>foo.txt</code>。</li>\n<li>使用括号扩展（<code>{</code>...<code>}</code>）来减少输入相似文本，并自动化文本组合。这在某些情况下会很有用，例如 <code>mv foo.{txt,pdf} some-dir</code>（同时移动两个文件），<code>cp somefile{,.bak}</code>（会被扩展成 <code>cp somefile somefile.bak</code>）或者 <code>mkdir -p test-{a,b,c}/subtest-{1,2,3}</code>（会被扩展成所有可能的组合，并创建一个目录树）。</li>\n<li>通过使用 <code>&lt;(some command)</code> 可以将输出视为文件。例如，对比本地文件 <code>/etc/hosts</code> 和一个远程文件：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      diff /etc/hosts <span class=\"pl-s\"><span class=\"pl-pds\">&lt;(</span>ssh somehost cat /etc/hosts<span class=\"pl-pds\">)</span></span></pre></div>\n\n<ul>\n<li>了解 Bash 中的“here documents”，例如 <code>cat &lt;&lt;EOF ...</code>。</li>\n<li>在 Bash 中，同时重定向标准输出和标准错误，<code>some-command &gt;logfile 2&gt;&amp;1</code>。通常，为了保证命令不会在标准输入里残留一个打开了的文件句柄导致你当前所在的终端无法操作，添加 <code>&lt;/dev/null</code> 是一个好习惯。</li>\n<li>使用 <code>man ascii</code> 查看具有十六进制和十进制值的ASCII表。<code>man unicode</code>，<code>man utf-8</code>，以及 <code>man latin1</code> 有助于你去了解通用的编码信息。</li>\n<li>使用 <code>screen</code> 或 <a href=\"https://tmux.github.io/\"><code>tmux</code></a> 来使用多个屏幕，当你在使用 ssh 时（保存 session 信息）将尤为有用。另一个轻量级的解决方案是 <a href=\"https://github.com/bogner/dtach\"><code>dtach</code></a>。</li>\n<li>ssh 中，了解如何使用 <code>-L</code> 或 <code>-D</code>（偶尔需要用 <code>-R</code>）去开启隧道是非常有用的，例如当你需要从一台远程服务器上访问 web。</li>\n<li>对 ssh 设置做一些小优化可能是很有用的，例如这个 <code>~/.ssh/config</code> 文件包含了防止特定环境下断开连接、压缩数据、多通道等选项：</li>\n</ul>\n\n<pre><code>      TCPKeepAlive=yes\n      ServerAliveInterval=15\n      ServerAliveCountMax=6\n      Compression=yes\n      ControlMaster auto\n      ControlPath /tmp/%r@%h:%p\n      ControlPersist yes\n</code></pre>\n\n<ul>\n<li>部分其他的关于 ssh 的选项是安全敏感的，而且应当小心启用。例如在可信任的网络中：<code>StrictHostKeyChecking=no</code>，<code>ForwardAgent=yes</code></li>\n<li>考虑使用 <a href=\"https://mosh.mit.edu/\"><code>mosh</code></a> 作为 ssh 的替代品，它使用 UDP 协议。</li>\n<li>获取文件的八进制格式权限，使用类似如下的代码：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      stat -c <span class=\"pl-s\"><span class=\"pl-pds\">'</span>%A %a %n<span class=\"pl-pds\">'</span></span> /etc/timezone</pre></div>\n\n<ul>\n<li>使用 <a href=\"https://github.com/mooz/percol\"><code>percol</code></a> 或者 <a href=\"https://github.com/junegunn/fzf\"><code>fzf</code></a> 可以交互式地从另一个命令输出中选取值。</li>\n<li>使用 <code>fpp</code>（<a href=\"https://github.com/facebook/PathPicker\">PathPicker</a>）可以与基于另一个命令(例如 <code>git</code>）输出的文件交互。</li>\n<li>将 web 服务器上当前目录下所有的文件（以及子目录）暴露给你所处网络的所有用户，使用：\n<code>python -m SimpleHTTPServer 7777</code> （使用端口 7777 和 Python 2）或<code>python -m http.server 7777</code> （使用端口 7777 和 Python 3）。</li>\n<li>以某种权限执行命令，使用<code>sudo</code>（root 权限）或<code>sudo -u</code>（其他用户）。使用<code>su</code>或者<code>sudo bash</code>来启动一个以对应用户权限运行的 shell。使用<code>su -</code>模拟其他用户的登录。</li>\n<li>了解命令行的 <a href=\"https://wiki.debian.org/CommonErrorMessages/ArgumentListTooLong\">128K 限制</a>。使用通配符匹配大量文件名时，常会遇到“Argument list too long”的错误信息。（这种情况下换用 <code>find</code> 或 <code>xargs</code> 通常可以解决。）</li>\n<li>要实现基本的计算器功能（或者一般地使用 Python），可以使用 <code>python</code> 解释器。例如：</li>\n</ul>\n\n<pre><code>&gt;&gt;&gt; 2+3\n5\n</code></pre>\n\n<h2><a id=\"user-content-文件及数据处理\" class=\"anchor\" href=\"#文件及数据处理\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>文件及数据处理</h2>\n\n<ul>\n<li>在当前路径下通过文件名定位一个文件，<code>find . -iname '*something*'</code>（或类似的）。在所有路径下通过文件名查找文件，使用 <code>locate something</code> （但请记住 <code>updatedb</code> 可能没有对最近新建的文件建立索引）。</li>\n<li>使用 <a href=\"https://github.com/ggreer/the_silver_searcher\"><code>ag</code></a> 在源代码或数据文件里检索（比 <code>grep -r</code> 更好）。</li>\n<li>将 HTML 转为文本：<code>lynx -dump -stdin</code></li>\n<li>Markdown，HTML，以及所有文档格式之间的转换，试试 <a href=\"http://pandoc.org/\"><code>pandoc</code></a>。</li>\n<li>如果你不得不处理 XML，<code>xmlstarlet</code> 宝刀未老。</li>\n<li>使用 <a href=\"http://stedolan.github.io/jq/\"><code>jq</code></a> 处理 JSON。</li>\n<li>使用 <a href=\"https://github.com/0k/shyaml\"><code>shyaml</code></a> 处理 YAML。</li>\n<li>Excel 或 CSV 文件的处理，<a href=\"https://github.com/onyxfish/csvkit\">csvkit</a> 提供了 <code>in2csv</code>，<code>csvcut</code>，<code>csvjoin</code>，<code>csvgrep</code> 等工具。</li>\n<li>关于 Amazon S3，<a href=\"https://github.com/s3tools/s3cmd\"><code>s3cmd</code></a> 很方便而 <a href=\"https://github.com/bloomreach/s4cmd\"><code>s4cmd</code></a> 更快。Amazon 官方的 <a href=\"https://github.com/aws/aws-cli\"><code>aws</code></a> 以及  <a href=\"https://github.com/donnemartin/saws\"><code>saws</code></a> 是其他 AWS 相关工作的基础。</li>\n<li>了解如何使用 <code>sort</code> 和 <code>uniq</code>，包括 uniq 的 <code>-u</code> 参数和 <code>-d</code> 参数，详见后文单行脚本节。另外可以了解一下 <code>comm</code>。</li>\n<li>了解如何使用 <code>cut</code>，<code>paste</code> 和 <code>join</code> 来更改文件。很多人都会使用 <code>cut</code>，但几乎都不会使用 <code>join</code>。</li>\n<li>了解如何运用 <code>wc</code> 去计算新行数（<code>-l</code>），字符数（<code>-m</code>），单词数（<code>-w</code>）以及字节数（<code>-c</code>）。</li>\n<li>了解如何使用 <code>tee</code> 将标准输入复制到文件甚至标准输出，例如 <code>ls -al | tee file.txt</code>。</li>\n<li>了解语言环境对许多命令行工具的微妙影响，包括排序的顺序和性能。大多数 Linux 的安装过程会将 <code>LANG</code> 或其他有关的变量设置为符合本地的设置。意识到当你改变语言环境时，排序的结果可能会改变。明白国际化可能会使 sort 或其他命令运行效率下降<em>许多倍</em>。某些情况下（例如集合运算）你可以放心的使用 <code>export LC_ALL=C</code> 来忽略掉国际化并使用基于字节的顺序。</li>\n<li>你可以单独指定某一条命令的环境，只需在调用时把环境变量设定放在前面，例如 <code>TZ=Pacific/Fiji date</code>。</li>\n<li>了解 <code>awk</code> 和 <code>sed</code> 关于数据的简单处理的用法。例如，将文本文件中第三列的所有数字求和：<code>awk '{ x += $3 } END { print x }'</code>. 这可能比同等作用的 Python 代码快三倍且代码量少三倍。</li>\n<li>替换一个或多个文件中出现的字符串：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      perl -pi.bak -e <span class=\"pl-s\"><span class=\"pl-pds\">'</span>s/old-string/new-string/g<span class=\"pl-pds\">'</span></span> my-files-<span class=\"pl-k\">*</span>.txt</pre></div>\n\n<ul>\n<li>使用 <a href=\"https://github.com/jlevy/repren\"><code>repren</code></a> 来批量重命名，或是在多个文件中搜索替换。（有些时候 <code>rename</code> 命令也可以批量重命名，但要注意，它在不同 Linux 发行版中的功能并不完全一样。）</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      <span class=\"pl-c\"># 将文件、目录和内容全部重命名 foo -&gt; bar:</span>\n      repren --full --preserve-case --from foo --to bar <span class=\"pl-c1\">.</span>\n      <span class=\"pl-c\"># 还原所有备份文件 whatever.bak -&gt; whatever:</span>\n      repren --renames --from <span class=\"pl-s\"><span class=\"pl-pds\">'</span>(.*)\\.bak<span class=\"pl-pds\">'</span></span> --to <span class=\"pl-s\"><span class=\"pl-pds\">'</span>\\1<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">*</span>.bak\n      <span class=\"pl-c\"># 用 rename 实现上述功能（若可用）:</span>\n      rename <span class=\"pl-s\"><span class=\"pl-pds\">'</span>s/\\.bak$//<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">*</span>.bak</pre></div>\n\n<ul>\n<li>根据 man 页面的描述，<code>rsync</code> 真的是一个快速且非常灵活的文件复制工具。它通常被用于机器间的同步，但在本地也同样有用。在安全限制允许下，用 <code>rsync</code> 代替 <code>scp</code> 可以实现续传，而不用重新从头开始。它同时也是删除大量文件的<a href=\"https://web.archive.org/web/20130929001850/http://linuxnote.net/jianingy/en/linux/a-fast-way-to-remove-huge-number-of-files.html\">最快方法</a>之一：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>mkdir empty <span class=\"pl-k\">&amp;&amp;</span> rsync -r --delete empty/ some-dir <span class=\"pl-k\">&amp;&amp;</span> rmdir some-dir</pre></div>\n\n<ul>\n<li>使用 <code>shuf</code> 从一个文件中随机选取多行。</li>\n<li>了解 <code>sort</code> 的参数。处理数字方面，使用 <code>-n</code> 或者 <code>-h</code> 来处理可读性数字（例如 <code>du -h</code> 的输出）。明白键的工作原理（<code>-t</code> 和 <code>-k</code>）。例如，注意到你需要 <code>-k1，1</code> 来仅按第一个域来排序，而 <code>-k1</code> 意味着按整行排序。稳定排序（<code>sort -s</code>）在某些情况下很有用。例如，以第二个域为主关键字，第一个域为次关键字进行排序，你可以使用 <code>sort -k1，1 | sort -s -k2，2</code>。</li>\n<li>如果你想在 Bash 命令行中写 tab 制表符，按下 <strong>ctrl-v</strong> <strong>[Tab]</strong> 或键入 <code>$'\\t'</code> （后者可能更好，因为你可以复制粘贴它）。</li>\n<li>标准的源代码对比及合并工具是 <code>diff</code> 和 <code>patch</code>。使用 <code>diffstat</code> 查看变更总览数据。注意到 <code>diff -r</code> 对整个文件夹有效。使用 <code>diff -r tree1 tree2 | diffstat</code> 查看变更总览数据。</li>\n<li>对于二进制文件，使用 <code>hd</code> 使其以十六进制显示以及使用 <code>bvi</code> 来编辑二进制。</li>\n<li>同样对于二进制文件，<code>strings</code>（包括 <code>grep</code> 等等）允许你查找一些文本。</li>\n<li>二进制文件对比（Delta 压缩），使用 <code>xdelta3</code>。</li>\n<li>使用 <code>iconv</code> 更改文本编码。而更高级的用法，可以使用 <code>uconv</code>，它支持一些高级的 Unicode 功能。例如，这条命令将所有元音字母转为小写并移除了：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      uconv -f utf-8 -t utf-8 -x <span class=\"pl-s\"><span class=\"pl-pds\">'</span>::Any-Lower; ::Any-NFD; [:Nonspacing Mark:] &gt;; ::Any-NFC; <span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&lt;</span> input.txt <span class=\"pl-k\">&gt;</span> output.txt</pre></div>\n\n<ul>\n<li>拆分文件，查看 <code>split</code>（按大小拆分）和 <code>csplit</code>（按模式拆分）。</li>\n<li>用 <a href=\"http://www.fresse.org/dateutils/\"><code>dateutils</code></a> 中的 <code>dateadd</code>、<code>datediff</code>、<code>strptime</code> 等工具操作日期和时间表达式。</li>\n<li>使用 <code>zless</code>、<code>zmore</code>、<code>zcat</code> 和 <code>zgrep</code> 对压缩过的文件进行操作。</li>\n<li>文件属性可以通过 <code>chattr</code> 进行设置，它比文件权限更加底层。例如，为了保护文件不被意外删除，可以使用不可修改标记：<code>sudo chattr +i /critical/directory/or/file</code></li>\n<li>使用 <code>getfacl</code> 和 <code>setfacl</code> 以保存和恢复文件权限。例如：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>   getfacl -R /some/path <span class=\"pl-k\">&gt;</span> permissions.txt\n   setfacl --restore=permissions.txt</pre></div>\n\n<h2><a id=\"user-content-系统调试\" class=\"anchor\" href=\"#系统调试\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>系统调试</h2>\n\n<ul>\n<li><code>curl</code> 和 <code>curl -I</code> 可以便捷地被应用于 web 调试中，它们的好兄弟 <code>wget</code> 也可以，或者是更潮的 <a href=\"https://github.com/jkbrzt/httpie\"><code>httpie</code></a>。</li>\n<li>使用 <code>iostat</code>、<code>netstat</code>、<code>top</code> （<code>htop</code> 更佳）和 <code>dstat</code> 去获取硬盘、cpu 和网络的状态。熟练掌握这些工具可以使你快速的对系统的当前状态有一个大概的认识。</li>\n<li>使用 <code>netstat</code> 和 <code>ss</code> 查看网络连接的细节。</li>\n<li>若要对系统有一个深度的总体认识，使用 <a href=\"https://github.com/nicolargo/glances\"><code>glances</code></a>。它在一个终端窗口中向你提供一些系统级的数据。这对于快速的检查各个子系统非常有帮助。</li>\n<li>若要了解内存状态，运行并理解 <code>free</code> 和 <code>vmstat</code> 的输出。尤其注意“cached”的值，它指的是 Linux 内核用来作为文件缓存的内存大小，因此它与空闲内存无关。</li>\n<li>Java 系统调试则是一件截然不同的事，一个可以用于 Oracle 的 JVM 或其他 JVM 上的调试的技巧是你可以运行 <code>kill -3 &lt;pid&gt;</code> 同时一个完整的栈轨迹和堆概述（包括 GC 的细节）会被保存到标准输出/日志文件。JDK 中的 <code>jps</code>，<code>jstat</code>，<code>jstack</code>，<code>jmap</code> 很有用。<a href=\"https://github.com/aragozin/jvm-tools\">SJK tools</a> 更高级.</li>\n<li>使用 <a href=\"http://www.bitwizard.nl/mtr/\"><code>mtr</code></a> 去跟踪路由，用于确定网络问题。</li>\n<li>用 <a href=\"https://dev.yorhel.nl/ncdu\"><code>ncdu</code></a> 来查看磁盘使用情况，它比常用的命令，如 <code>du -sh *</code>，更节省时间。</li>\n<li>查找正在使用带宽的套接字连接或进程，使用 <a href=\"http://www.ex-parrot.com/%7Epdw/iftop/\"><code>iftop</code></a> 或 <a href=\"https://github.com/raboof/nethogs\"><code>nethogs</code></a>。</li>\n<li><code>ab</code> 工具（捆绑于 Apache）可以简单粗暴地检查 web 服务器的性能。对于更复杂的负载测试，使用 <code>siege</code>。</li>\n<li><a href=\"https://wireshark.org/\"><code>wireshark</code></a>，<a href=\"https://www.wireshark.org/docs/wsug_html_chunked/AppToolstshark.html\"><code>tshark</code></a> 和 <a href=\"http://ngrep.sourceforge.net/\"><code>ngrep</code></a> 可用于复杂的网络调试。</li>\n<li>了解 <code>strace</code> 和 <code>ltrace</code>。这俩工具在你的程序运行失败、挂起甚至崩溃，而你却不知道为什么或你想对性能有个总体的认识的时候是非常有用的。注意 profile 参数（<code>-c</code>）和附加到一个运行的进程参数 （<code>-p</code>）。</li>\n<li>了解使用 <code>ldd</code> 来检查共享库。</li>\n<li>了解如何运用 <code>gdb</code> 连接到一个运行着的进程并获取它的堆栈轨迹。</li>\n<li>学会使用 <code>/proc</code>。它在调试正在出现的问题的时候有时会效果惊人。比如：<code>/proc/cpuinfo</code>，<code>/proc/meminfo</code>，<code>/proc/cmdline</code>，<code>/proc/xxx/cwd</code>，<code>/proc/xxx/exe</code>，<code>/proc/xxx/fd/</code>，<code>/proc/xxx/smaps</code>（这里的 <code>xxx</code> 表示进程的 id 或 pid）。</li>\n<li>当调试一些之前出现的问题的时候，<a href=\"http://sebastien.godard.pagesperso-orange.fr/\"><code>sar</code></a> 非常有用。它展示了 cpu、内存以及网络等的历史数据。</li>\n<li>关于更深层次的系统分析以及性能分析，看看 <code>stap</code>（<a href=\"https://sourceware.org/systemtap/wiki\">SystemTap</a>），<a href=\"https://en.wikipedia.org/wiki/Perf_(Linux)\"><code>perf</code></a>，以及<a href=\"https://github.com/draios/sysdig\"><code>sysdig</code></a>。</li>\n<li>查看你当前使用的系统，使用 <code>uname</code> ， <code>uname -a</code> （Unix／kernel 信息） 或者 <code>lsb_release -a</code> （Linux 发行版信息）。</li>\n<li>无论什么东西工作得很欢乐时试试 <code>dmesg</code>（可能是硬件或驱动问题）。</li>\n<li>如果你删除了一个文件，但通过 <code>du</code> 发现没有释放预期的磁盘空间，请检查文件是否被进程占用：\n<code>lsof | grep deleted | grep \"filename-of-my-big-file\"</code></li>\n</ul>\n\n<h2><a id=\"user-content-单行脚本\" class=\"anchor\" href=\"#单行脚本\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>单行脚本</h2>\n\n<p>一些命令组合的例子：</p>\n\n<ul>\n<li>当你需要对文本文件做集合交、并、差运算时，结合使用 <code>sort</code>/<code>uniq</code> 很有帮助。假设 <code>a</code> 与 <code>b</code> 是两内容不同的文件。这种方式效率很高，并且在小文件和上G的文件上都能运用 （<code>sort</code> 不被内存大小约束，尽管在 <code>/tmp</code> 在一个小的根分区上时你可能需要 <code>-T</code> 参数），参阅前文中关于 <code>LC_ALL</code> 和 <code>sort</code> 的 <code>-u</code> 参数的部分。</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      cat a b <span class=\"pl-k\">|</span> sort <span class=\"pl-k\">|</span> uniq <span class=\"pl-k\">&gt;</span> c   <span class=\"pl-c\"># c is a union b</span>\n      cat a b <span class=\"pl-k\">|</span> sort <span class=\"pl-k\">|</span> uniq -d <span class=\"pl-k\">&gt;</span> c   <span class=\"pl-c\"># c is a intersect b</span>\n      cat a b b <span class=\"pl-k\">|</span> sort <span class=\"pl-k\">|</span> uniq -u <span class=\"pl-k\">&gt;</span> c   <span class=\"pl-c\"># c is set difference a - b</span></pre></div>\n\n<ul>\n<li>使用 <code>grep . *</code>（每行都会附上文件名）或者 <code>head -100 *</code>（每个文件有一个标题）来阅读检查目录下所有文件的内容。这在检查一个充满配置文件的目录（如 <code>/sys</code>、<code>/proc</code>、<code>/etc</code>）时特别好用。</li>\n<li>计算文本文件第三列中所有数的和（可能比同等作用的 Python 代码快三倍且代码量少三倍）：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      awk <span class=\"pl-s\"><span class=\"pl-pds\">'</span>{ x += $3 } END { print x }<span class=\"pl-pds\">'</span></span> myfile</pre></div>\n\n<ul>\n<li>如果你想在文件树上查看大小/日期，这可能看起来像递归版的 <code>ls -l</code> 但比 <code>ls -lR</code> 更易于理解：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      find <span class=\"pl-c1\">.</span> -type f -ls</pre></div>\n\n<ul>\n<li>假设你有一个类似于 web 服务器日志文件的文本文件，并且一个确定的值只会出现在某些行上，假设一个 <code>acct_id</code> 参数在URI中。如果你想计算出每个 <code>acct_id</code> 值有多少次请求，使用如下代码：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      cat access.log <span class=\"pl-k\">|</span> egrep -o <span class=\"pl-s\"><span class=\"pl-pds\">'</span>acct_id=[0-9]+<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> cut -d= -f2 <span class=\"pl-k\">|</span> sort <span class=\"pl-k\">|</span> uniq -c <span class=\"pl-k\">|</span> sort -rn</pre></div>\n\n<ul>\n<li>要连续地监测变化，可以使用 <code>watch</code>，例如检查某个文件夹中文件的改变，可以用 <code>watch -d -n 2 'ls -rtlh | tail'</code>；或者在排查 WiFi 设置故障时要监测网络设置的更改，可以用 <code>watch -d -n 2 ifconfig</code>。</li>\n<li>运行这个函数从这篇文档中随机获取一条技巧（解析 Markdown 文件并抽取项目）：</li>\n</ul>\n\n<div class=\"highlight highlight-source-shell\"><pre>      <span class=\"pl-k\">function</span> <span class=\"pl-en\">taocl()</span> {\n        curl -s https://raw.githubusercontent.com/jlevy/the-art-of-command-line/master/README-zh.md<span class=\"pl-k\">|</span>\n          pandoc -f markdown -t html <span class=\"pl-k\">|</span>\n          iconv -f <span class=\"pl-s\"><span class=\"pl-pds\">'</span>utf-8<span class=\"pl-pds\">'</span></span> -t <span class=\"pl-s\"><span class=\"pl-pds\">'</span>unicode<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span>\n          xmlstarlet fo --html --dropdtd <span class=\"pl-k\">|</span>\n          xmlstarlet sel -t -v <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>(html/body/ul/li[count(p)&gt;0])[<span class=\"pl-smi\">$RANDOM</span> mod last()+1]<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">|</span>\n          xmlstarlet unesc <span class=\"pl-k\">|</span> fmt -80\n      }</pre></div>\n\n<h2><a id=\"user-content-冷门但有用\" class=\"anchor\" href=\"#冷门但有用\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>冷门但有用</h2>\n\n<ul>\n<li><code>expr</code>：计算表达式或正则匹配</li>\n<li><code>m4</code>：简单地宏处理器</li>\n<li><code>yes</code>：多次打印字符串</li>\n<li><code>cal</code>：漂亮的日历</li>\n<li><code>env</code>：执行一个命令（脚本文件中很有用）</li>\n<li><code>printenv</code>：打印环境变量（调试时或在使用脚本文件时很有用）</li>\n<li><code>look</code>：查找以特定字符串开头的单词</li>\n<li><code>cut</code>、<code>paste</code> 和 <code>join</code>：数据修改</li>\n<li><code>fmt</code>：格式化文本段落</li>\n<li><code>pr</code>：将文本格式化成页/列形式</li>\n<li><code>fold</code>：包裹文本中的几行</li>\n<li><code>column</code>：将文本格式化成多列或表格</li>\n<li><code>expand</code> 和 <code>unexpand</code>：制表符与空格之间转换</li>\n<li><code>nl</code>：添加行号</li>\n<li><code>seq</code>：打印数字</li>\n<li><code>bc</code>：计算器</li>\n<li><code>factor</code>：分解因数</li>\n<li><a href=\"https://gnupg.org/\"><code>gpg</code></a>：加密并签名文件</li>\n<li><code>toe</code>：terminfo entries 列表</li>\n<li><code>nc</code>：网络调试及数据传输</li>\n<li><code>socat</code>：套接字代理，与 <code>netcat</code> 类似</li>\n<li><a href=\"https://github.com/mattthias/slurm\"><code>slurm</code></a>：网络可视化</li>\n<li><code>dd</code>：文件或设备间传输数据</li>\n<li><code>file</code>：确定文件类型</li>\n<li><code>tree</code>：以树的形式显示路径和文件，类似于递归的 <code>ls</code></li>\n<li><code>stat</code>：文件信息</li>\n<li><code>time</code>：执行命令，并计算执行时间</li>\n<li><code>timeout</code>：在指定时长范围内执行命令，并在规定时间结束后停止进程</li>\n<li><code>lockfile</code>：使文件只能通过 <code>rm -f</code> 移除</li>\n<li><code>logrotate</code>： 切换、压缩以及发送日志文件</li>\n<li><code>watch</code>：重复运行同一个命令，展示结果并高亮有更改的部分</li>\n<li><code>tac</code>：反向输出文件</li>\n<li><code>shuf</code>：文件中随机选取几行</li>\n<li><code>comm</code>：一行一行的比较排序过的文件</li>\n<li><code>pv</code>：监视通过管道的数据</li>\n<li><code>hd</code>，<code>hexdump</code>，<code>xxd</code>，<code>biew</code> 和 <code>bvi</code>：保存或编辑二进制文件</li>\n<li><code>strings</code>：从二进制文件中抽取文本</li>\n<li><code>tr</code>：转换字母</li>\n<li><code>iconv</code> 或 <code>uconv</code>：简易的文件编码</li>\n<li><code>split</code> 和 <code>csplit</code>：分割文件</li>\n<li><code>sponge</code>：在写入前读取所有输入，在读取文件后再向同一文件写入时比较有用，例如 <code>grep -v something some-file | sponge some-file</code></li>\n<li><code>units</code>：将一种计量单位转换为另一种等效的计量单位（参阅 <code>/usr/share/units/definitions.units</code>）</li>\n<li><code>apg</code>：随机生成密码</li>\n<li><code>7z</code>：高比例的文件压缩</li>\n<li><code>ldd</code>：动态库信息</li>\n<li><code>nm</code>：提取 obj 文件中的符号</li>\n<li><code>ab</code>：性能分析 web 服务器</li>\n<li><code>strace</code>：系统调用调试</li>\n<li><a href=\"http://www.bitwizard.nl/mtr/\"><code>mtr</code></a>：更好的网络调试跟踪工具</li>\n<li><code>cssh</code>：可视化的并发 shell</li>\n<li><code>rsync</code>：通过 ssh 或本地文件系统同步文件和文件夹</li>\n<li><a href=\"https://wireshark.org/\"><code>wireshark</code></a> 和 <a href=\"https://www.wireshark.org/docs/wsug_html_chunked/AppToolstshark.html\"><code>tshark</code></a>：抓包和网络调试工具</li>\n<li><a href=\"http://ngrep.sourceforge.net/\"><code>ngrep</code></a>：网络层的 grep</li>\n<li><code>host</code> 和 <code>dig</code>：DNS 查找</li>\n<li><code>lsof</code>：列出当前系统打开文件的工具以及查看端口信息</li>\n<li><code>dstat</code>：系统状态查看</li>\n<li><a href=\"https://github.com/nicolargo/glances\"><code>glances</code></a>：高层次的多子系统总览</li>\n<li><code>iostat</code>：硬盘使用状态</li>\n<li><code>mpstat</code>： CPU 使用状态</li>\n<li><code>vmstat</code>： 内存使用状态</li>\n<li><code>htop</code>：top 的加强版</li>\n<li><code>last</code>：登入记录</li>\n<li><code>w</code>：查看处于登录状态的用户</li>\n<li><code>id</code>：用户/组 ID 信息</li>\n<li><a href=\"http://sebastien.godard.pagesperso-orange.fr/\"><code>sar</code></a>：系统历史数据</li>\n<li><a href=\"http://www.ex-parrot.com/%7Epdw/iftop/\"><code>iftop</code></a> 或 <a href=\"https://github.com/raboof/nethogs\"><code>nethogs</code></a>：套接字及进程的网络利用</li>\n<li><code>ss</code>：套接字数据</li>\n<li><code>dmesg</code>：引导及系统错误信息</li>\n<li><code>sysctl</code>： 在内核运行时动态地查看和修改内核的运行参数</li>\n<li><code>hdparm</code>：SATA/ATA 磁盘更改及性能分析</li>\n<li><code>lsblk</code>：列出块设备信息：以树形展示你的磁盘以及磁盘分区信息</li>\n<li><code>lshw</code>，<code>lscpu</code>，<code>lspci</code>，<code>lsusb</code> 和 <code>dmidecode</code>：查看硬件信息，包括 CPU、BIOS、RAID、显卡、USB设备等</li>\n<li><code>lsmod</code> 和 <code>modinfo</code>：列出内核模块，并显示其细节</li>\n<li><code>fortune</code>，<code>ddate</code> 和 <code>sl</code>：额，这主要取决于你是否认为蒸汽火车和莫名其妙的名人名言是否“有用”</li>\n</ul>\n\n<h2><a id=\"user-content-仅限-os-x-系统\" class=\"anchor\" href=\"#仅限-os-x-系统\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>仅限 OS X 系统</h2>\n\n<p>以下是<em>仅限于</em> OS X 系统的技巧</p>\n\n<ul>\n<li>用 <code>brew</code> （Homebrew）或者 <code>port</code> （MacPorts）进行包管理。这些可以用来在 OS X 系统上安装以上的大多数命令。</li>\n<li>用 <code>pbcopy</code> 复制任何命令的输出到桌面应用，用 <code>pbpaste</code> 粘贴输入。</li>\n<li>若要在 OS X 终端中将 Option 键视为 alt 键（例如在上面介绍的 <strong>alt-b</strong>、<strong>alt-f</strong> 等命令中用到），打开 偏好设置 -&gt; 描述文件 -&gt; 键盘 并勾选“使用 Option 键作为 Meta 键”。</li>\n<li>用 <code>open</code> 或者 <code>open -a /Applications/Whatever.app</code> 使用桌面应用打开文件。</li>\n<li>Spotlight： 用 <code>mdfind</code> 搜索文件，用 <code>mdls</code> 列出元数据（例如照片的 EXIF 信息）。</li>\n<li>注意 OS X 系统是基于 BSD UNIX 的，许多命令（例如 <code>ps</code>，<code>ls</code>，<code>tail</code>，<code>awk</code>，<code>sed</code>）都和 Linux 中有些微的不同，这些极大的被 System V-style Unix 和 GNU 工具影响。你可以通过标题为 \"BSD General Commands Manual\" 的 man 页面发现这些不同。在有些情况下 GNU 版本的命令也可能被安装（例如 <code>gawk</code> 和 <code>gsed</code> 对应 GNU 中的 awk 和 sed ）。如果要写跨平台的 Bash 脚本，避免使用这些命令（例如，考虑 Python 或者 <code>perl</code> ）或者经过仔细的测试。</li>\n<li>用 <code>sw_vers</code> 获取 OS X 的版本信息。</li>\n</ul>\n\n<h2><a id=\"user-content-仅限-windows-系统\" class=\"anchor\" href=\"#仅限-windows-系统\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>仅限 Windows 系统</h2>\n\n<ul>\n<li>要在 Microsoft Windows 中使用 Unix shell，可以安装 <a href=\"https://cygwin.com/\">Cygwin</a>。本文档中介绍的大多数内容都将适用。</li>\n<li>通过 Cygwin 的包管理器来安装额外的 Unix 程序。</li>\n<li>使用 <code>mintty</code> 作为你的命令行窗口。</li>\n<li>要访问 Windows 剪贴板，可以通过 <code>/dev/clipboard</code>。</li>\n<li>运行 <code>cygstart</code> 以通过默认程序打开一个文件。</li>\n<li>要访问 Windows 注册表，可以使用 <code>regtool</code>。</li>\n<li>注意 Windows 驱动器路径 <code>C:\\</code> 在 Cygwin 中用 <code>/cygdrive/c</code> 代表，而 Cygwin 的 <code>/</code> 在 Windows 中显示在 <code>C:\\cygwin</code>。要转换 Cygwin 和 Windows 风格的路径可以用 <code>cygpath</code>。这在需要调用 Windows 程序的脚本里很有用。</li>\n<li>学会使用 <code>wmic</code>，你就可以从命令行执行大多数 Windows 系统管理任务，并编成脚本。</li>\n</ul>\n\n<h2><a id=\"user-content-更多资源\" class=\"anchor\" href=\"#更多资源\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>更多资源</h2>\n\n<ul>\n<li><a href=\"https://github.com/alebcay/awesome-shell\">awesome-shell</a>：一份精心组织的命令行工具及资源的列表。</li>\n<li><a href=\"https://github.com/herrbischoff/awesome-osx-command-line\">awesome-osx-command-line</a>：一份针对 OS X 命令行的更深入的指南。</li>\n<li><a href=\"http://redsymbol.net/articles/unofficial-bash-strict-mode/\">Strict mode</a>：为了编写更好的脚本文件。</li>\n<li><a href=\"https://github.com/koalaman/shellcheck\">shellcheck</a>：一个静态 shell 脚本分析工具，本质上是 bash／sh／zsh 的 lint。</li>\n<li><a href=\"http://www.dwheeler.com/essays/filenames-in-shell.html\">Filenames and Pathnames in Shell</a>：有关如何在 shell 脚本里正确处理文件名的细枝末节。</li>\n<li><a href=\"http://datascienceatthecommandline.com/#tools\">Data Science at the Command Line</a>：用于数据科学的一些命令和工具，摘自同名书籍。</li>\n</ul>\n\n<h2><a id=\"user-content-免责声明\" class=\"anchor\" href=\"#免责声明\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>免责声明</h2>\n\n<p>除去特别微小的任务，编写代码是出于方便阅读的目的。能力往往伴随着责任。你 <em>可以</em> 在 Bash 中做一些事并不意味着你应该去做！;)</p>\n\n<h2><a id=\"user-content-授权条款\" class=\"anchor\" href=\"#授权条款\" aria-hidden=\"true\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>授权条款</h2>\n\n<p><a href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img src=\"https://camo.githubusercontent.com/e170e276291254896665fa8f612b99fe5b7dd005/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d73612f342e302f38387833312e706e67\" alt=\"Creative Commons License\" data-canonical-src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" style=\"max-width:100%;\"></a></p>\n\n<p>本文使用授权协议 <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>。</p>\n\n\n","tags":["bash"],"categories":["system"]},{"title":"LINUX下解决netstat查看TIME_WAIT状态过多问题","url":"/2017/05/31/system/LINUX下解决netstat查看TIME-WAIT状态过多问题/","content":"\n\n```sh\n# netstat -an|awk '/tcp/ {print $6}'|sort|uniq -c\n     16 CLOSING\n    130 ESTABLISHED\n    298 FIN_WAIT1\n     13 FIN_WAIT2\n      9 LAST_ACK\n      7 LISTEN\n    103 SYN_RECV\n   5204 TIME_WAIT\n\n状态：描述\nCLOSED：无连接是活动的或正在进行\nLISTEN：服务器在等待进入呼叫\nSYN_RECV：一个连接请求已经到达，等待确认\nSYN_SENT：应用已经开始，打开一个连接\nESTABLISHED：正常数据传输状态\nFIN_WAIT1：应用说它已经完成\nFIN_WAIT2：另一边已同意释放\nITMED_WAIT：等待所有分组死掉\nCLOSING：两边同时尝试关闭\nTIME_WAIT：另一边已初始化一个释放\nLAST_ACK：等待所有分组死掉\n```\n\n<!-- more -->\n \n如发现系统存在大量TIME_WAIT状态的连接，通过调整内核参数解决，\n\n```sh\nvim /etc/sysctl.conf\n```\n\n编辑文件，加入以下内容：\n```sh\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.ipv4.tcp_fin_timeout = 30\n```\n\n然后执行 `/sbin/sysctl -p` 让参数生效。\n \nnet.ipv4.tcp_syncookies = 1 表示开启SYN cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；\n \nnet.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；\n \nnet.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。\n \nnet.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间\n \n下面附上TIME_WAIT状态的意义：\n \n客户端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口\n \n状态为TIME_WAIT\n \n是不是所有执行主动关闭的socket都会进入TIME_WAIT状态呢？\n \n有没有什么情况使主动关闭的socket直接进入CLOSED状态呢？\n \n主动关闭的一方在发送最后一个 ack 后就会进入 TIME_WAIT 状态 停留2MSL（max segment lifetime）时间这个是TCP/IP必不可少的，也就是“解决”不了的。\n \n也就是TCP/IP设计者本来是这么设计的\n \n主要有两个原因\n \n1。防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）\n \n2。可靠的关闭TCP连接\n \n在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。\n \nTIME_WAIT 并不会占用很大资源的，除非受到攻击。\n \n还有，如果一方 send 或 recv 超时，就会直接进入 CLOSED 状态\n","tags":["调优"],"categories":["system"]},{"title":"logrotate切割日志nginx和php配置","url":"/2017/05/31/service/logrotate切割日志nginx和php配置/","content":"\n\n# nginx配置\n\n```sh\n/gotwo_data/logs/nginx/2mm.cn/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 644 nginx nginx\n        sharedscripts\n        postrotate\n                [ -f /gotwo_data/logs/nginx/nginx.pid ] && kill -USR1 `cat /gotwo_data/logs/nginx/nginx.pid`\n        endscript\n}\n```\n\n<!-- more -->\n\n# php配置\n\n```sh\n/gotwo_data/logs/php/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 666 nobody nobody\n        sharedscripts\n        postrotate\n                [ -f /gotwo_data/Application/php/var/run/php-fpm.pid ] && kill -USR1 `cat /gotwo_data/Application/php/var/run/php-fpm.pid`\n        endscript\n}\n```\n","tags":["logrotate"],"categories":["service"]},{"title":"nginx常见问题","url":"/2017/05/31/service/nginx常见问题/","content":"\n# 1.错误日志：warn：an upstream response is buffered to a temporary file\n\n```sh\n解决办法：增加fastcgi_buffers 8 4K;     fastcgi_buffer_size 4K;\n```\n<!-- more -->\n\n# 2. a client request body is buffered to a temporary file\n\n```sh\n解决办法：增加client_max_body_size 2050m;     client_body_buffer_size 1024k;\n```\n\n## Nginx 的 buffer 机制：\n\n对于来自 FastCGI Server 的 Response，Nginx 将其缓冲到内存中，然后依次发送到客户端浏览器。缓冲区的大小由 fastcgi_buffers 和 fastcgi_buffer_size 两个值控制。\n\n比如如下配置：\n\n```sh\nfastcgi_buffers      8 4K;\nfastcgi_buffer_size  4K;\n```\n\nfastcgi_buffers 控制 nginx 最多创建 8 个大小为 4K 的缓冲区，而 fastcgi_buffer_size 则是处理 Response 时第一个缓冲区的大小，不包含在前者中。所以总计能创建的最大内存缓冲区大小是 8*4K+4K = 36k。而这些缓冲区是根据实际的 Response 大小动态生成的，并不是一次性创建的。比如一个 8K 的页面，Nginx 会创建 2*4K 共 2 个 buffers。\n\n当 Response 小于等于 36k 时，所有数据当然全部在内存中处理。如果 Response 大于 36k 呢？fastcgi_temp 的作用就在于此。多出来的数据会被临时写入到文件中，放在这个目录下面。同时你会在 error.log 中看到一条类似 warning：\n\n```\n2010/03/13 03:42:22 [warn] 3994#0: *1 an upstream response is buffered to a temporary file\n/usr/local/nginx/fastcgi_temp/1/00/0000000001 while reading upstream, \nclient: 192.168.1.111,\nserver: www.xxx.cn,\nrequest: \"POST /test.php HTTP/1.1\",\nupstream: \"fastcgi://127.0.0.1:9000\", \nhost: \"xxx.cn\",\nreferrer: \"http://xxx.cn/test.php\"\n```\n\n显然，缓冲区设置的太小的话，Nginx 会频繁读写硬盘，对性能有很大的影响，但也不是越大越好，没意义. \n","tags":["nginx"],"categories":["service"]},{"title":"恢复linux被误删文件","url":"/2017/05/30/system/恢复linux被误删文件/","content":"\n# 一、首先我们先来了解下文件删除原理：\n* 1）linux是通过link的数量来控制文件删除的，只有当一个文件不存在任何link的时候，这个文件才会被删除。一般来说，每个文件都有2个link计数器：i_count和i_nlink。\n* 2）当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。\n* 3）当你发现你误删除了文件后，要做的第一件事是马上卸载被误删除文件所在的分区，或者以只读的方式来挂载该分区。原因大家都很清楚，文件被删除后，文件中的数据还存在磁盘上，除非存放这些数据的数据块又被操作系统分配出去了。我们这一步就是尽量降低数据块中数据被覆盖的风险，以提高恢复数据成功的比率。\n\n<!-- more -->\n\n# 二、了解完后，实战演练\n\n---\n\n## 方案 1）现在我向大家介绍使用extundelete恢复文件（适合rhel6.X系统的ext4)\n\n### 1.编译安装extundelete-0.2.4\n\n```sh\ntar -jxvf  extundelete-0.2.4.tar.bz2\ncd extundelete-0.2.4\n./configure （这步出现错误，请看下文）\nmount /dev/cdrom /mnt\nrpm -ivh  /mnt/Packages/e2fsprogs-devel-1.41.12-18.el6.x86_64.rpm  （必须安装否则，前面./configure报错）\n./configure （成功）\nmake && make install\n```\n\n### 2.软件安装完毕，下面我们来恢复文件吧\n\n```sh\nmkdir recover\ncd recover\nextundelete  /dev/sda4 --inode  2  （看到你所删除的文件）\nextundelete  /dev/sda4 -restore-inode 15 （按对应的节点来恢复文件）\nextundelete  /dev/sda4 -restore-file  a.txt   （按对应文件名来恢复文件）\nextundelete  /dev/sda4 -restore-dirctory etc  （按对应的目录，这里我以etc目录）\nextundelete  /dev/sda4 -restore-all （全部恢复）\n```\n\n---\n\n## 方案2）使用lsof自带一个的神秘功能\n\n　　原理：大多数与 lsof 相关的信息都存储于以进程的 PID命名的目录中,假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下：\n\n　　首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下：\n\n```sh\nlsof |grep /var/log/messages\n\nsyslogd 1283 root 2w REG 3,3 5381017 1773647 /var/log/messages (deleted)\n```\n\n　　从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：\n\n```sh\nhead -n 10 /proc/1283/fd/2\n\nAug 4 13:50:15 holmes86 syslogd 1.4.1: restart.\nAug 4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started.\nAug 4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org)\n(gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 Aug 4 13:50:15 holmes86 kernel:\nBIOS-provided physical RAM map: Aug 4 13:50:15 holmes86 kernel: BIOS-e820:\n0000000000000000 - 000000000009f000 (usable) Aug 4 13:50:15 holmes86 kernel: BIOS-e820:\n000000000009f000 - 00000000000a0000 (reserved) Aug 4 13:50:15 holmes86 kernel:\nBIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) Aug 4 13:50:15 holmes86 kernel:\nBIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) Aug 4 13:50:15 holmes86\nkernel: BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) Aug 4 13:50:15\nholmes86 kernel: BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)\n```\n\n　　从上面的信息可以看出，查看 /proc/8663/fd/15 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如:cat /proc/1283/fd/2 > /var/log/messages对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。\n\n---\n\n## 方案3）使用ext3grep恢复文件（适合rhel5.X系统的ext3)\n\n### 1. 编译安装ext3grep-0.10.1\n\n```sh\ntar -jxvf  ext3grep-0.10.1.tar.gz\ncd ext3grep-0.10.1\n./configure\nmake && make install\n```\n\n### 2. 软件安装完毕，下面我们来恢复文件吧\n\n```sh\nmkdir recover\ncd recover\next3grep /dev/your-device --restore-filepath/to/your/file/filename\n```\n\n　　需要注意的是，上面的文件路径，是在该分区上文件路径。假设我们要恢复/dev/sda3分区上文件，这个分区原来的安装点是/home，现在想恢复文件/home/easwy/vi/tips.xml，那么输入的命令应该是：\n\n```sh\next3grep /dev/sda3--restore-file easwy/vi/tips.xml\n```\n\n　　所有恢复的文件都会放在当前目下在`RESTORED_FILES`目录下，大小也一样，这里`RESTORED_FILES`目录是执行ext3grep的当前目录下\n\n　　如果你忘记了文件名，或者你误删除的是一个目录而你无法记全该目录中的文件，你可以先用下面的命令查询一下文件名：\n\n```sh\next3grep /dev/sda3 --dump-names | tee filename.txt\n```\n\n　　上面的命令把ext3grep命令的输出记录到文件filename.txt中，你可以慢慢查看，或者使用grep命令过滤出你需要的信息。\n\n　　当你知道了目录/文件的信息后，就可以用上面说的命令进行恢复了。\n\n　　复所有文件和目录，但是目录的话，如果删除时间较长，不一定能完全恢复，压缩文件一般都能恢复\n\n```sh\next3grep /termite/cc-disk --restore-all\next3grep /dev/sda3  --ls --inode 2 创建扫描分区文件：sda5.ext3grep.stage1和sda5.ext3grep.stage2\n```\n\n　　如果想要重新生成可以删除这个两个文件，再次执行这条命令。另外当第一次执行ext3grep /dev/sda3 --restore-file test/a.txt进行还原时也会自动生成扫描分区文件。\n","tags":["数据恢复"],"categories":["system"]},{"title":"Windows与Linux共享文件夹互相访问","url":"/2017/05/29/service/ Windows与Linux共享文件夹互相访问 /","content":"\n# 首先安装并配置软件samba\n\n```sh\nsudo yum install samba samba-client  \nvim /etc/samba/smb.conf  \n      \n找到security这行并将#注释符号去掉改成  \nsecurity = share     #共享模式  \n      \n添加如下代码：  \n      \n[share]  \ncomment = share  \npath = /home/test          #设置共享文件夹目录  \nbrowseable = yes  \nguest ok = yes  \nwritable = yes  \n\nservice smb start  \nservice smbd start   (ubuntu)  \n```\n<!-- more -->\n\n## （1）在windows下访问Linux共享：\n\n直接在windows运行里输入\\\\192.168.16.128即可访问linux共享资源，并且不需要密码。\n\n## （2）在linux下访问windows共享：\n```sh\nsmbclient -L 192.168.16.1 -U xiaoxing   # 查看共享了那些目录，由此知道主机名为XIAOXING-PC\n\nsmbclient //192.168.16.1/Users -U xiaoxing     输入windows密码即可进入\n```\n\n直接挂载windows共享目录\n\n```sh\nsudo mount -t smbfs -o username=xiaoxing,password=123456   //XIAOXING-PC/system /mnt/win/\n或者：\nsudo mount -t smbfs -o username=xiaoxing,password=123456   //192.168.16.1/system /mnt/win/\n或者：\nsudo mount -t smbfs -o username=xiaoxing,password=123456,ip=192.168.16.1 //XIAOXING-PC/system /mnt/win/\n```\n\n注意：\n\n如果出现如下错误：\n\n```sh\nmount: unknown filesystem type ’smbfs’\n```\n说明系统已经不能识别smbfs文件系统了，查资料说RHE5的kernel已经不再支持smbfs，而改用Common Internet File Systemcifs(cifs)取代了原有的smbfs，所以命令就改为:\n\n```sh\nsudo mount -t cifs -o username=xiaoxing,password=123456   //192.168.16.1/system /mnt/win/\n```\n解开挂载\n\n断开刚才挂载在linux /mnt/win/路径上的winodws共享文件夹。\n```sh\nsudo umount /mnt/win/\n```\n","tags":["samba"],"categories":["service"]},{"title":"系统运维工程师装逼完全指南","url":"/2017/05/28/life/系统运维工程师装逼完全指南/","content":"\n\n\n1、全球化的认证有助于提升逼格，什么OCM、CCIE、RHCA、CISSP等等能考都考，再不济，也要有一张系统架构设计师或者网络规划设计师的信产部认证。每过一个认证，逼格提升一档。\n\n<!-- more -->\n\n2、TCP/IP协议、Linux内核深入研究、ORACLE大全等等之类的超过1千页大本头的书能有效提升B格，一定要放手边。不懂不要紧，别人能看见就行了。真有人跟你谈这些，也别担心装B失败，谈网络就从TCP的实现谈起，谈Linux就从内存的管理谈起，谈数据库就从各数据库SQL语句的源码实现谈起。如果有人跟你谈MS的东西也不要紧，就说自己之前有多年的微软的工作经历，外包的也算。反正也不会有查。有人非要跟你谈硬件，最次也要从计算机部件分类谈起吧。\n\n3、大众化的东西要少用。能用ATS，就别用squid；能用postgresql，就别用MySQL；坚信什么nginx、lighty这种webserver要比apache好一万倍，而且apache能实现的功能，这些都能实现，不行就自己写模块、写扩展。实在要用apache，也别用高版本，抱死1.3的系统。有人要是问起，就说这是基于1.3的版是自己深度二次开发版本。实在要找不到的话也不要紧，没事在sf、oschina上看看什么下载量少的项目，背背项目简介啥的。不得不说，这两个网站太贴心，分类都给你做好了。总之，小众的东西能很有效的提升你的装逼级别。\n\n4、写脚本的话，别用grep、sort 、uniq、管道这类命令。使用纯粹的awk、sed的实现，长度不要紧，阅读性、性能也不是问题。功能实现了，别人都还不懂这就是关键。如果真有人来请教，也要装出一副很简单的表情。切记不要摇头尾巴晃。就算是你是从《sed和awk》这种书上抄你自己也不一定能看懂的代码。\n\n5、虽然会shell，但也要少用shell。初级装逼者，系统管理会首选perl、python、php这类3p的工具，而且要对shell这种语言有一种不屑。把什么性能、移植性、面向对象要常挂嘴边。如果还能再写几行什么erlang、ruby、lua这类语言做系统管理，绝对是装B神器，也是中级装逼的标准。高级装逼者会有Haskell这类函数式语言进行系统管理，这绝对是装B的B2轰炸机呀。当然，资深装逼者会返璞归真，使用面向对象进行shell编程。对，你没看错，是使用OO进行shell编程。\n\n6、当谈到Redhat、ubuntu这类大众发行版本时，就回复一个字“切！”LFS、Gentoo这类系统绝对是装逼的首选。不为什么，就为在无穷尽的编译中找到属于自己的快感。如果非装大众发行版，也要从开机画面、登陆提示等等地方打自己上深刻的烙印。装逼的寂寞岂是一般人能懂的。\n\n7、对什么checkpoint，juniper等表示不屑。必须天天把iptabes的链和表都挂在嘴边，尤其是mangle表。原则上对商用产品的一律不屑一顾，什么f5，radware一律自己开发实现。至于意外的将自己关在外面的事情一定要严格遵守各自公司的保密协议。\n\n8、对于操作终端呢，像SecureCRT、xshell这种绝对是不用的，一定要用最原始的，什么黑屏绿字只是初级装逼者的水平，中高级则是Alpha半透明终端，桌面背景在设置个全球internet流量趋势图。让你根本就不知道他天天对着屏幕在敲什么东西。有事没事编译一些大型软件，看着翻滚的屏幕做思考状。\n\n9、名片的title一定要是系统架构师，没有名片也不要紧，什么QQ签名、人人状态、微博简介上，有人看的地方一定要写上。这些都是提升B格的好地方。\n\n10、初级装逼谈流量、PV、自动化；中级装逼谈流程、谈规范，什么ITIL、ITSM要常挂嘴边；高级装逼谈架构、谈模式；资深装逼则谈合同、谈成本。\n\n11、混圈子对装逼来非常有必要的。什么XX沙龙、XX架构师大会、XX优化大会之类必要是常客，露个B脸就行。基本原则就是跟搞系统谈网络，跟搞网络的谈数据库，跟搞数据库的谈安全……对方不懂什么就谈什么对就了\n\n12、最后，骨灰级早就超出三界外，不在五行中，他们注定有着传奇的色彩。他们正忙于对装逼者们进行职业发展规划。装逼助理、初级装逼、高级装逼、资深装逼、装逼总监直至CBO。如果发展了到了CBO，那么你一定是一位惊天地、泣鬼神的一代B神，一统江湖的教主，供万千iBer敬仰。darling，我很看好你哟！","tags":["职业"],"categories":["life"]},{"title":"运维人装逼指南大全","url":"/2017/05/28/life/运维人装逼指南大全/","content":"\n\n曾经有一首诗是这么写的\n\n> 装逼，是一种态度??\n\n> 装逼的人生不可限量\n\n> 装逼如煲汤\n\n> 遇到烹制的高手，逼格立马飙升\n\n<!-- more -->\n\n装逼，已被业界大神誉为当代职场人的基本素养\n\n可是\n\n网上流传的装逼指南一大把\n\n唯独缺少咱运维人的这一发\n\n今天线哥就帮大家来扒一扒\n\n咱们一起把这装逼宝典传承下\n\n\n　　话说，运维人拥有天然装逼优势，面对无数迭代升级的软硬件，数都数不过来的各类技术，互联网、云计算、大数据的热潮，跑断腿的各类行业大会……这些都为我们营造了极好的客观条件。\n\n　　可以说，在全民都看你的时代，你不装逼，不仅浪费了你这一身好手段，而且辜负了天恩浩荡呀！\n\n　　线哥虽是运营人，但长期浸淫在运维大咖身边，韬光养晦，苦练内功，总结了历来大神的装逼心得，并且通过实战检验，可谓天下无双，故取名曰《装逼宝典》，以补《葵花宝典》千年缺配。\n\n　　现在很多运维人逼格不高，主要是因其来路不正，“小米+步枪”的时代远去，来路不正永远低人一等。所以一张权威的架构师认证就显得无比重要了，国内比较权威的系统架构设计师或者网络规划设计师的认证要考，国际的什么OCM、CCIE、RHCA、CISSP等等更要考，有了这些证件决定你在哪一个层次装逼，当然了，逼格的飙升也有赖于部分努力。\n\n　　你会发现一些资深装逼手边永远摆着几本大部头的书，看着都瘆人。何谓大部头，什么？几百页的书你也好意思提，至少得上千页，才配称得上大部头。像什么TCP/IP协议、Linux内核研究、ORACLE大全等等。书一定要摆在显眼位置，你不用担心万一有人问起装逼遭遇滑铁卢。如果有人问硬件，你可以从计算机硬件基础谈起，有人问MS的内容，你那几年微软外包工作经历正好派上用场，现在数据库比较热，你可以从SQL语句的源码开聊，网络就谈TCP，Linux就谈内存管理。聊着聊着，你自己都被自己感动了，征服了。\n\n# 跟菜鸟划开界限\n\n　　菜鸟在管理系统上经常选用perl、python、php这些3p工具，你要避开这些工具，另外shell也要少用，当菜鸟问起，你要表现出不屑来。如果做系统管理你要会写几行erlang、ruby、lua这类语言，如果你胆儿够大，可以整一整Haskell这类函数式语言。我敢说，懂一点这个，你绝对把逼装大了。\n\n# 避开大众化路线\n\n　　当别人问你用squid吗？你说你用ATS；当别人问你用MySQL吗？你说你用postgresql；当别人为你用apache吗？你说你用nginx、lighty。如果你发现当别人也在学习这些技术了，你就到sf、oschina网站上看看那些下载量小的项目，多背背项目简介，当他们在你面前炫耀新技术时，你跟他们聊一聊这些项目，这时你发现他们只剩下长大了的嘴。你要记住，越小众的东西越显得高逼格，小众意味着高端，这是历史反复验证的。\n\n# 为自己代言\n\n　　不装逼的人永远不懂装逼人的寂寞，装逼到极致是高冷的，曲高和寡。比如当大家还在谈Redhat、ubuntu这类大众发行版本时，你总是有意无意间避开，别人问你看法的时候，你对此不置一词，反而大谈特谈LFS、Gentoo。因为大众的东西是别人的，扒到属于自己的东西才显得更有张力，会带来不一样的快感呦。\n\n　　很多人写脚本都爱用grep、sort 、uniq这类命令，这类命令的功能比较复杂，而你术业有专攻，使用最纯粹的awk、sed来实现，最关键的是当你用它们实现某些功能，别人都看不懂。别人不懂就会问，而这时你却表现出一副轻描淡写的表情。而这些对于他们来说，就算抄书也不一定真能看懂。\n\n# 设置屏幕放大招\n\n　　操作终端一定要大肆显摆，那种黑屏绿字好莱坞大片式简直弱爆了，你用的是什么，是Alpha半透明终端，最好在桌面设置一个全球internet流量走势图，偶尔对着翻滚的屏幕做深入思考状，谁也不知道你在琢磨什么惊天地泣鬼神的东西。\n\n# 处处留情\n\n　　软硬件都解决了，这时候作为运维人的装逼基础已经够完美了，可是距离互联网大神级别还有距离。这时候你要抓住一切手段营销自己。不要让“网管”这个词在你耳朵边出现，你要时刻在明面暗面提示别人，我是架构师或规划师，把所有能展示自己title的地方都写上，什么名片啊、微信啊、QQ签名、脉脉、拉勾网等等，当然如果你愿意加上”首都在线“的前缀，可能效果会出奇不意。\n\n# 混精英圈子\n\n　　混圈子对于装逼是极为重要的。现在各种大会很多，鱼龙混杂，像什么GMIC、ChinaJoy之类的大会很难找到自己定位，而一般的XX架构师大会、XX优化大会、XX沙龙最多混个脸熟就好了。主要瞄准几个特定场合可获得四两拨千斤的效果，比如什么青年计算机学会论坛，统计之都论坛，以及蝴蝶沙龙，尤其蝴蝶沙龙是一个比较纯粹的架构师聚会，多去混这种场子，争取能演讲，那么你在这个圈子就很接近大神级人物了。\n\n# 精通云计算\n\n　　一般而言，骨灰级的大神被当作信仰一样崇拜，这些人物大都具有传奇色彩，据线哥多年观察，这些人物的思考域比较广，他思考问题具有生态图谱效应，比如做架构师，你一定要多思考云计算，了解SAAS，熟悉PAAS，精通IAAS。尤其关注当前IAAS战略趋势以及差异化发展。当前的经济趋势是企业出海，不管是电商、游戏还是视频企业，都在向海外拓展业务，在倡导全球云计算布局领域中，国内首要关注首都在线，因为这是首家全球一体化云计算服务商，拥有全球私网GPN，通过它能够高效稳定安全连接世界。\n\n　　最后不得不说，装逼是个系统工程，从装逼助理、装逼专员、高级装逼、资深装逼、装逼总监直至CBO。取经之路漫长，你在哪个层级不重要，重要的是，装逼精神不弃，奋斗之路不止。送给万千参透“人生如戏”的职场运维人士们！","tags":["职业"],"categories":["life"]},{"title":"tc命令——Linux基于IP进行流量限速","url":"/2017/05/28/service/tc命令Linux基于IP进行流量限速/","content":"\n# 一、TC原理\n\n　　Linux操作系统中的流量控制器TC（Traffic Control）用于Linux内核的流量控制，主要是通过在输出端口处建立一个队列来实现流量控制。\n\n<!-- more -->\n\n　　接收包从输入接口进来后，经过流量限制丢弃不符合规定的数据包，由输入多路分配器进行判断选择：\n\n* 如果接收包的目的主机是本主机，那么将该包送给上层处理，否则需要进行转发，将接收包交到转发块（Forwarding Block）处理。\n* 转发块同时也接收本主机上层(TCP、UDP等)产生的包，通过查看路由表，决定所处理包的下一跳。\n* 然后，对包进行排列以便将它们送到输出接口。\n\n　　一般只能限制网卡发送的数据包，不能限制网卡接收的数据包，所以可以通过改变发送次序靠控制传输速率。Linux流量控制主要是在输出接口排列时进行处理和实现的。\n\n# 二、TC规则\n\n## 2.1、流量控制方式\n\n　　流量控制包括以下几种方式：\n\n* SHAPING(限制) \n\n　　当流量被限制，它的传输速率就被控制在某个值以下。限制值可以大大小于有效带宽，这样可以平滑突发数据流量，使网络更为稳定。shaping（限制）只适用于向外的流量。\n\n* SCHEDULING(调度)      \n\n　　通过调度数据包的传输，可以在带宽范围内，按照优先级分配带宽。SCHEDULING(调度)也只适于向外的流量。\n\n* POLICING(策略)      \n\n　　SHAPING用于处理向外的流量，而POLICIING(策略)用于处理接收到的数据。\n\n* DROPPING(丢弃)      \n\n　　如果流量超过某个设定的带宽，就丢弃数据包，不管是向内还是向外。\n\n## 2.2、流量控制处理对象\n\n　　流量的处理由三种对象控制，它们是：\n\n* qdisc(排队规则)\n* class(类别)\n* filter(过滤器)\n\n###  QDISC(排队规则)\n\n　　QDisc(排队规则)是queueing discipline的简写，它是理解流量控制(traffic control)的基础。**无论何时，内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的qdisc(排队规则)把数据包加入队列。** 然后，内核会尽可能多地从qdisc里面取出数据包，把它们交给网络适配器驱动模块。最简单的QDisc是pfifo它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。不过，它会保存网络接口一时无法处理的数据包。\n\n　　QDISC的类别如下：\n\n#### （1）、CLASSLESS QDisc(不可分类QDisc)\n\n##### 1. 无类别QDISC包括：\n\n　　**[p|b]fifo**\n\n　　使用最简单的qdisc，纯粹的先进先出。只有一个参数：limit，用来设置队列的长度,pfifo是以数据包的个数为单位；bfifo是以字节数为单位。\n\n　　**pfifo_fast**\n\n　　在编译内核时，如果打开了高级路由器(Advanced Router)编译选项，pfifo_fast就是系统的标准QDISC。它的队列包括三个波段(band)。在每个波段里面，使用先进先出规则。而三个波段(band)的优先级也不相同，band 0的优先级最高，band 2的最低。如果band里面有数据包，系统就不会处理band 1里面的数据包，band 1和band 2之间也是一样。数据包是按照服务类型(Type of Service,TOS)被分配多三个波段(band)里面的。\n\n　　**red**\n\n　　red是Random Early Detection(随机早期探测)的简写。如果使用这种QDISC，当带宽的占用接近于规定的带宽时，系统会随机地丢弃一些数据包。它非常适合高带宽应用。\n\n　　**sfq**\n\n　　sfq是Stochastic Fairness Queueing的简写。它按照会话(session--对应于每个TCP连接或者UDP流)为流量进行排序，然后循环发送每个会话的数据包。\n\n　　**tbf**\n\n　　tbf是Token Bucket Filter的简写，适合于把流速降低到某个值。\n\n##### 2. 不可分类QDisc的配置\n\n　　如果没有可分类QDisc，不可分类QDisc只能附属于设备的根。它们的用法如下：\n\n```sh\ntc qdisc add dev DEV root QDISC QDISC-PARAMETERS\n```\n\n　　要删除一个不可分类QDisc，需要使用如下命令：\n\n```sh\ntc qdisc del dev DEV root\n```\n\n　　一个网络接口上如果没有设置QDisc，pfifo_fast就作为缺省的QDisc。\n\n#### （2）、CLASSFUL QDISC(分类QDisc)\n\n##### 可分类的QDisc包括：\n\n　　**CBQ**\n\n　　CBQ是Class Based Queueing(基于类别排队)的缩写。它实现了一个丰富的连接共享类别结构，既有限制(shaping)带宽的能力，也具有带宽优先级管理的能力。带宽限制是通过计算连接的空闲时间完成的。空闲时间的计算标准是数据包离队事件的频率和下层连接(数据链路层)的带宽。\n\n　　**HTB**\n\n　　HTB是Hierarchy Token Bucket的缩写。通过在实践基础上的改进，它实现了一个丰富的连接共享类别体系。使用HTB可以很容易地保证每个类别的带宽，虽然它也允许特定的类可以突破带宽上限，占用别的类的带宽。HTB可以通过TBF(Token Bucket Filter)实现带宽限制，也能够划分类别的优先级。\n\n　　**PRIO**\n\n　　PRIO QDisc不能限制带宽，因为属于不同类别的数据包是顺序离队的。使用PRIO QDisc可以很容易对流量进行优先级管理，只有属于高优先级类别的数据包全部发送完毕，才会发送属于低优先级类别的数据包。为了方便管理，需要使用iptables或者ipchains处理数据包的服务类型(Type Of Service,ToS)。\n\n### CLASS(类)       \n\n　　某些QDisc(排队规则)可以包含一些类别，不同的类别中可以包含更深入的QDisc(排队规则)，通过这些细分的QDisc还可以为进入的队列的数据包排队。通过设置各种类别数据包的离队次序，QDisc可以为设置网络数据流量的优先级。\n\n### FILTER(过滤器)      \n\n　　Filter(过滤器)用于为数据包分类，决定它们按照何种QDisc进入队列。无论何时数据包进入一个划分子类的类别中，都需要进行分类。分类的方法可以有多种，使用fileter(过滤器)就是其中之一。使用filter(过滤器)分类时，内核会调用附属于这个类(class)的所有过滤器，直到返回一个判决。如果没有判决返回，就作进一步的处理，而处理方式和QDISC有关。需要注意的是，filter(过滤器)是在QDisc内部，它们不能作为主体。\n\n## 2.3、操作原理\n\n　　类(Class)组成一个树，每个类都只有一个父类，而一个类可以有多个子类。某些QDisc(例如：CBQ和HTB)允许在运行时动态添加类，而其它的QDisc(例如：PRIO)不允许动态建立类。允许动态添加类的QDisc可以有零个或者多个子类，由它们为数据包排队。此外，每个类都有一个叶子QDisc，默认情况下，这个叶子QDisc使用pfifo的方式排队，我们也可以使用其它类型的QDisc代替这个默认的QDisc。而且，这个叶子叶子QDisc有可以分类，不过每个子类只能有一个叶子QDisc。 当一个数据包进入一个分类QDisc，它会被归入某个子类。\n\n　　我们可以使用以下三种方式为数据包归类，不过不是所有的QDisc都能够使用这三种方式：\n\n* tc过滤器(tc filter)\n\n　　如果过滤器附属于一个类，相关的指令就会对它们进行查询。过滤器能够匹配数据包头所有的域，也可以匹配由ipchains或者iptables做的标记。\n\n* 服务类型(Type of Service)\n\n　　某些QDisc有基于服务类型（Type of Service,ToS）的内置的规则为数据包分类。\n\n* skb->priority\n\n　　用户空间的应用程序可以使用SO_PRIORITY选项在skb->priority域设置一个类的ID。\n\n　　树的每个节点都可以有自己的过滤器，但是高层的过滤器也可以直接用于其子类。\n\n　　如果数据包没有被成功归类，就会被排到这个类的叶子QDisc的队中。相关细节在各个QDisc的手册页中。\n\n## 2.4、命名规则\n\n　　所有的QDisc、类和过滤器都有ID。ID可以手工设置，也可以有内核自动分配。ID由一个主序列号和一个从序列号组成，两个数字用一个冒号分开。\n\n　　**QDISC**\n\n　　一个QDisc会被分配一个主序列号，叫做句柄(handle)，然后把从序列号作为类的命名空间。句柄采用象10:一样的表达方式。习惯上，需要为有子类的QDisc显式地分配一个句柄。\n\n　　**类(CLASS)**\n\n　　在同一个QDisc里面的类分享这个QDisc的主序列号，但是每个类都有自己的从序列号，叫做类识别符(classid)。类识别符只与父QDisc有关，和父类无关。类的命名习惯和QDisc的相同。\n\n　　**过滤器(FILTER)**\n\n　　过滤器的ID有三部分，只有在对过滤器进行散列组织才会用到。详情请参考tc-filters手册页。\n\n## 2.5、单位\n\n　　tc命令的所有参数都可以使用浮点数，可能会涉及到以下计数单位。\n\n|带宽或者流速单位：\n|--------------------------------------------|\n|kbps                           |千字节/秒   |\n|mbps                           |兆字节/秒   |\n|kbit                           |KBits/秒    |\n|mbit                           |MBits/秒    |\n|bps或者一个无单位数字          |字节数/秒   |\n\n\n|数据的数量单位：\n|-------------------------------------|\n|kb或者k                        |千字节    |\n|mb或者m                        |兆字节    |\n|mbit                           |兆bit     |\n|kbit                           |千bit     |\n|b或者一个无单位数字            |字节数    |\n\n\n|时间的计量单位：\n|-------------------------------------------|\n|s、sec或者secs                    |秒    |\n|ms、msec或者msecs                 |分钟   |\n|us、usec、usecs或者一个无单位数字 |微秒  |\n\n\n# 三、TC命令\n\n　　tc可以使用以下命令对QDisc、类和过滤器进行操作：\n\n* add\n\n　　在一个节点里加入一个QDisc、类或者过滤器。添加时，需要传递一个祖先作为参数，传递参数时既可以使用ID也可以直接传递设备的根。如果要建立一个QDisc或者过滤器，可以使用句柄(handle)来命名；如果要建立一个类，可以使用类识别符(classid)来命名。\n\n* remove\n\n　　删除有某个句柄(handle)指定的QDisc，根QDisc(root)也可以删除。被删除QDisc上的所有子类以及附属于各个类的过滤器都会被自动删除。\n\n\n* change\n\n　　以替代的方式修改某些条目。除了句柄(handle)和祖先不能修改以外，change命令的语法和add命令相同。换句话说，change命令不能一定节点的位置。\n\n* replace\n\n　　对一个现有节点进行近于原子操作的删除/添加。如果节点不存在，这个命令就会建立节点。\n\n* link\n\n　　只适用于DQisc，替代一个现有的节点。\n\n\n# 四、具体操作\n\n　　Linux流量控制主要分为建立队列、建立分类和建立过滤器三个方面。\n\n## 4.1、基本实现步骤为：\n\n* （1） 针对网络物理设备（如以太网卡eth0）绑定一个队列QDisc；\n* （2） 在该队列上建立分类class；\n* （3） 为每一分类建立一个基于路由的过滤器filter；\n* （4） 最后与过滤器相配合，建立特定的路由表。\n\n## 4.2、环境模拟实例:\n\n　　流量控制器上的以太网卡(eth0) 的IP地址为192.168.1.66，在其上建立一个CBQ队列。假设包的平均大小为1000字节，包间隔发送单元的大小为8字节，可接收冲突的发送最长包数目为20字节。\n\n　　假如有三种类型的流量需要控制: \n\n1. 是发往主机1的，其IP地址为192.168.1.24。其流量带宽控制在8Mbit，优先级为2；\n2. 是发往主机2的，其IP地址为192.168.1.30。其流量带宽控制在1Mbit，优先级为1；\n3. 是发往子网1的，其子网号为192.168.1.0，子网掩码为255.255.255.0。流量带宽控制在1Mbit，优先级为6。\n\n\n### 1. 建立队列\n\n　　一般情况下，针对一个网卡只需建立一个队列。\n\n　　将一个cbq队列绑定到网络物理设备eth0上，其编号为1:0；网络物理设备eth0的实际带宽为10 Mbit，包的平均大小为1000字节；包间隔发送单元的大小为8字节，最小传输包大小为64字节。\n\n```sh\ntc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit avpkt 1000 cell 8 mpu 64\n```\n\n### 2. 建立分类\n\n　　分类建立在队列之上。\n\n　　一般情况下，针对一个队列需建立一个根分类，然后再在其上建立子分类。对于分类，按其分类的编号顺序起作用，编号小的优先；一旦符合某个分类匹配规则，通过该分类发送数据包，则其后的分类不再起作用。\n\n　　**1） 创建根分类1:1；分配带宽为10Mbit，优先级别为8。**\n\n```sh\ntc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate 10Mbit maxburst 20 allot 1514 prio 8 avpkt 1000 cell 8 weight 1Mbit\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为10Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为8，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为1Mbit。\n\n　　**2）创建分类1:2，其父分类为1:1，分配带宽为8Mbit，优先级别为2。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 8Mbit maxburst 20 allot 1514 prio 2 avpkt 1000 cell 8 weight 800Kbit split 1:0 bounded\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为 8Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为1，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为800Kbit，分类的分离点为1:0，且不可借用未使用带宽。\n\n　　**3）创建分类1:3，其父分类为1:1，分配带宽为1Mbit，优先级别为1。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 1 avpkt 1000 cell 8 weight 100Kbit split 1:0\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为 1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为2，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n　　**4）创建分类1:4，其父分类为1:1，分配带宽为1Mbit，优先级别为6。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 6 avpkt 1000 cell 8 weight 100Kbit split 1:0\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为6，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n## 4.3. 建立过滤器 \n\n　　过滤器主要服务于分类。\n\n一般只需针对根分类提供一个过滤器，然后为每个子分类提供路由映射。\n\n**1） 应用路由分类器到cbq队列的根，父分类编号为1:0；过滤协议为ip，优先级别为100，过滤器为基于路由表。**\n\n```sh\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route\n```\n\n**2） 建立路由映射分类1:2, 1:3, 1:4**\n\n```sh\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 2 flowid 1:2\n\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 3 flowid 1:3\n\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 4 flowid 1:4\n```\n\n## 4.4.建立路由\n\n　　该路由是与前面所建立的路由映射一一对应。\n\n　　**1） 发往主机192.168.1.24的数据包通过分类2转发(分类2的速率8Mbit)**\n\n```sh\nip route add 192.168.1.24 dev eth0 via 192.168.1.66 realm 2\n```\n　　**2） 发往主机192.168.1.30的数据包通过分类3转发(分类3的速率1Mbit)**\n\n```sh\nip route add 192.168.1.30 dev eth0 via 192.168.1.66 realm 3\n```\n　　**3）发往子网192.168.1.0/24的数据包通过分类4转发(分类4的速率1Mbit)**\n\n```sh\nip route add 192.168.1.0/24 dev eth0 via 192.168.1.66 realm 4\n```\n\n　　**注**：一般对于流量控制器所直接连接的网段建议使用IP主机地址流量控制限制，不要使用子网流量控制限制。如一定需要对直连子网使用子网流量控制限制，则在建立该子网的路由映射前，需将原先由系统建立的路由删除，才可完成相应步骤。\n\n## 4.5. 监视\n\n　　主要包括对现有队列、分类、过滤器和路由的状况进行监视。\n\n　　**1）显示队列的状况**\n\n　　简单显示指定设备(这里为eth0)的队列状况\n\n```\ntc qdisc ls dev eth0\n\nqdisc cbq 1: rate 10Mbit (bounded,isolated) prio no-transmit\n```\n　　详细显示指定设备(这里为eth0)的队列状况\n\n```\ntc -s qdisc ls dev eth0\n```\n\n　　这里主要显示了通过该队列发送了13232个数据包，数据流量为7646731个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n　　**2）显示分类的状况**\n\n　　简单显示指定设备(这里为eth0)的分类状况\n\n```\ntc class ls dev eth0\n```\n\n　　详细显示指定设备(这里为eth0)的分类状况\n\n```\ntc -s class ls dev eth0\n```\n\n　　这里主要显示了通过不同分类发送的数据包，数据流量，丢弃的包数目，超过速率限制的包数目等等。其中根分类(class cbq 1:0)的状况应与队列的状况类似。\n\n　　例如，分类class cbq 1:4发送了8076个数据包，数据流量为5552879个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n　　**3）显示过滤器的状况**\n\n```\ntc -s filter ls dev eth0\n```\n　　这里flowid 1:2代表分类class cbq 1:2，to 2代表通过路由2发送。\n\n　　**4）显示现有路由的状况**\n\n```\nip route\n```\n\n　　如上所示，结尾包含有realm的显示行是起作用的路由过滤器。\n\n\n# 五、实例脚本\n\n## 5.1 tc限速\n\n```sh\n#! /bin/sh\n\ntouch  /var/lock/subsys/local\n\necho  1  > /proc/sys/net/ipv4/ip_forward （激活转发）\n\nroute add default  gw  10.0.0.0  (这是加入电信网关，如果你已设了不用这条）\n\nDOWNLOAD=640Kbit        (640/8 =80K ,我这里限制下载最高速度只能80K）\nUPLOAD=640Kbit          (640/8 =80K,上传速度也限制在80K）\nINET=192.168.0.         (设置网段，根据你的情况填）\nIPS=1                   (这个意思是从192.168.0.1开始）\nIPE=200                 (我这设置是从IP为192.168.0.1-200这个网段限速，根据自已的需要改）\nServerIP=253            (网关IP）\nIDEV=eth0\nODEV=eth1\n\n/sbin/tc  qdisc  del  dev  $IDEV root handle 10:\n/sbin/tc  qdisc  del  dev  $ODEV  root handle  20:\n/sbin/tc  qdisc  add  dev $IDEV  root  handle  10: cbq  bandwidth  100Mbit avpkt  1000\n/sbin/tc  qdisc  add  dev  $ODEV  root  handle  20: cbq bandwidth  1Mbit  avpkt  1000\n/sbin/tc  class  add  dev $IDEV  parent 10:0  classid  10:1  cbq  bandwidth  100Mbit  rate 100Mbit  allot 1514  weight  1Mbit  prio  8  maxburst  20  avpkt  1000\n/sbin/tc  class  add  dev  $ODEV  parent  20:0  classid  20:1 cbq  bandwidth  1Mbit  rate  1Mbit  allot  1514  weitht  10Kbit  prio  8  maxburst  20  avpkt  1000\n\nCOUNTER=$IPS\nwhile  [  $COUNTER  -le  $IPE  ]\n    do\n/sbin/tc  class  add  dev  $IDEV  parent  10:1  classid  10:1$COUNTER  cbq  banwidth  100Mbit  rate  \n$DOWNLOAD  allot  1514  weight  20Kbit  prio  5  maxburst  20  avpkt  1000  bounded\n/sbin/tc  qdisc  add  dev  $IDEV  parent  10:1$COUNTER  sfq  quantum  1514b  perturb15\n\n/sbin/tc  filter  add  dev  $IDEV  parent  10:0  protocol  ip  prio  100  u32  match  ipdst  $INET$COUNTER  flowid  10:1$COUNTER\n      COUNTER=` expr  $COUNTER  +  1  `\ndone\n\niptables  -t  nat  -A  POSTROUTING  -o  eth1  -s  192.168.0.0/24  -J  MASQUERADE\n```\n\n## 5.2 模型\n\n```sh   \n#!/bin/sh\ntc qdisc del dev eth7 root &> /dev/null\ntc qdisc del dev eth8 root &> /dev/null\n\n#Add qdisc\ntc qdisc add dev eth7 root handle 10: htb default 9998\ntc qdisc add dev eth8 root handle 10: htb default 9998\n\n#Add htb root node\ntc class add dev eth7 parent 10: classid 10:9999 htb rate 1000000kbit ceil 1000000kbit\ntc class add dev eth8 parent 10: classid 10:9999 htb rate 1000000kbit ceil 1000000kbit\n\n#Add htb fake default node here\ntc class add dev eth7 parent 10:9999 classid 10:9998 htb rate 1000000kbit ceil 1000000kbit\ntc class add dev eth8 parent 10:9999 classid 10:9998 htb rate 1000000kbit ceil 1000000kbit\n\n#Add rule node\ntc class add dev eth7 parent 10:9999 classid 10:3 htb rate 1kbit ceil 50kbit\ntc filter add dev eth7 parent 10: protocol ip handle 3 fw classid 10:3\ntc class add dev eth8 parent 10:9999 classid 10:3 htb rate 1kbit ceil 50kbit\ntc filter add dev eth8 parent 10: protocol ip handle 3 fw classid 10:3\n\n#Add htb real default node here\ntc class change dev eth7 classid 10:9998 htb rate 1kbit ceil 1000000kbit\ntc class change dev eth8 classid 10:9998 htb rate 1kbit ceil 1000000kbit\n```\n\n## 5.3 限制一个IP上传下载速度\n\n```sh\n#!/bin/bash\n#\n#  tc uses the following units when passed as a parameter.\n#  kbps: Kilobytes per second\n#  mbps: Megabytes per second\n#  kbit: Kilobits per second\n#  mbit: Megabits per second\n#  bps: Bytes per second\n#       Amounts of data can be specified in:\n#       kb or k: Kilobytes\n#       mb or m: Megabytes\n#       mbit: Megabits\n#       kbit: Kilobits\n#  To get the byte figure from bits, divide the number by 8 bit\n#\n\n#\n# Name of the traffic control command.\nTC=/sbin/tc\n\n# The network interface we're planning on limiting bandwidth.\nIF=em1             # Interface\n\n# Download limit (in mega bits)\nDNLD=80mbit          # DOWNLOAD Limit\n\n# Upload limit (in mega bits)\nUPLD=80mbit          # UPLOAD Limit\n\n# IP address of the machine we are controlling\nIP=125.64.15.21     # Host IP\n\n# Filter options for limiting the intended interface.\nU32=\"$TC filter add dev $IF protocol ip parent 1:0 prio 1 u32\"\n\nstart() {\n\n# We'll use Hierarchical Token Bucket (HTB) to shape bandwidth.\n# For detailed configuration options, please consult Linux man\n# page.\n\n    $TC qdisc add dev $IF root handle 1: htb default 30\n    $TC class add dev $IF parent 1: classid 1:1 htb rate $DNLD\n    $TC class add dev $IF parent 1: classid 1:2 htb rate $UPLD\n    $U32 match ip dst $IP/32 flowid 1:1\n    $U32 match ip src $IP/32 flowid 1:2\n\n# The first line creates the root qdisc, and the next two lines\n# create two child qdisc that are to be used to shape download\n# and upload bandwidth.\n#\n# The 4th and 5th line creates the filter to match the interface.\n# The 'dst' IP address is used to limit download speed, and the\n# 'src' IP address is used to limit upload speed.\n\n}\n\nstop() {\n\n# Stop the bandwidth shaping.\n    $TC qdisc del dev $IF root\n\n}\n\nrestart() {\n\n# Self-explanatory.\n    stop\n    sleep 1\n    start\n\n}\n\nshow() {\n\n# Display status of traffic control status.\n    $TC -s qdisc ls dev $IF\n\n}\n\ncase \"$1\" in\n\n  start)\n\n    echo -n \"Starting bandwidth shaping: \"\n    start\n    echo \"done\"\n    ;;\n\n  stop)\n\n    echo -n \"Stopping bandwidth shaping: \"\n    stop\n    echo \"done\"\n    ;;\n\n  restart)\n\n    echo -n \"Restarting bandwidth shaping: \"\n    restart\n    echo \"done\"\n    ;;\n\n  show)\n\n    echo \"Bandwidth shaping status for $IF:\"\n    show\n    echo \"\"\n    ;;\n\n  *)\n\n    pwd=$(pwd)\n    echo \"Usage: tc.bash {start|stop|restart|show}\"\n    ;;\n\nesac\n\nexit 0\n```\n\n本文原文出处:http://leslie-chu.blog.163.com/blog/static/19986324320125414618221\n\n主要参考（所有权利归原文作者所有）：\n\nhttp://www.cnblogs.com/endsock/archive/2011/12/09/2281519.html\n\nhttp://blog.163.com/ninja_wk/blog/static/989155620084280154811/\n\nhttp://www.chinaunix.net/jh/4/16110.html\n","tags":["tc"],"categories":["service"]},{"title":"Linux上ssd优化","url":"/2017/05/27/system/Linux上ssd优化/","content":"# 一、修改默认的固态硬盘(SSD)柱面大小\n\n　　提升Linux下固态硬盘的使用率，在安装Linux操作系统前就应该做相关工作。系统会先在磁盘上创建分区，通常创建的分区包含固定数量的柱面，而默认情况下，每个柱面由16065512个字节的扇区组成。\n  \n<!-- more -->\n\n　　现在的问题是，当默认柱面空间大小被完全使用后，固态硬盘就不能发挥最佳性能。因为要固态硬盘读这个操作需要使用4KB的字节块，而固态硬盘控制器删除操 作则需要512KB的字节块。问题是，有了通常用于Linux上的默认分区，分区的开始没必要也是一个4KB新分区的开始。结果，一次读取或写入操作也许 需要SSD设备上的两个不同的区块，这也减缓了SSD磁盘的性能。\n\n　　为了避免这种问题，可以采用fdisk方式来创建分区，配置三个选项来指定使用柱面及拍面大小。具体的命令如下：\n\n```sh\nfdisk -H 32 -C 32 –c /dev/sdb\n```\n# 二、配置固态硬盘(SSD)的文件系统\n\n### 1.创建文件系统\n\n　　接着需要关注的就是文件系统。想要优化文件系统删除字节区块的效率，就必须确保小于512K的文件分布在不同的删除字节区块上。要做到这一点，必须确保在创建可扩展文件系统时指定了需要使用的条带的宽度和幅度。这些值在页面中指定，默认大小为4KB。要创建一个最佳的可扩展文件系统，应该使用如下命令：\n\n```sh\nmkfs.ext4 -E stride=128,stripe-width=128 /dev/sda1\n```\n\n　　如果要修改现有的文件系统的参数，可以使用tune2fs实用程序：\n\n```sh\ntune2fs -E stride=128,stripe-width=128 /dev/sda1\n```\n\t\n### 2.文件系统日志\n\n　　关闭日志功能，可以延长SSD寿命，但是突然断电容易造成文件损坏\n\n```sh\ntune2fs -O ^has_journal /dev/sda2  关闭日志；\n```\n\n　　然后执行\n\n```sh\ne2fsck -f /dev/sda2；\n```\n\n　　检查日志是否关闭成功：\n\n```sh\ndmesg | grep EXT4\n```\n\n　　如果显示 “EXT4-fs (sda2): mounted filesystem without journal”  说明关闭日志成功；否则显示 “mounted filesystem with ordered data mode”\n\n\n　　要打开日志\n\n```sh\ntune2fs -O has_journal /dev/sda2   \n```\n\n### 3.设置noatime\n\n　　不记录文件访问时间，该选项保证了文件的访问时间不会因为每次读取而更新，从而降低对文件系统的写入次数。\n\n　　在fstb 中加入noatime　选项\n\n```sh\n/dev/sda1 / ext4 discard,defaults  改为  /dev/sda1 / ext4 noatime,defaults\n```\n\n# 三、配置固态硬盘(SSD)的I/O调度程序\n\n　　优化的第三个部分涉及到I/O调度程序。该模块是一个决定如何处理I/O请求的核心组件。默认情况下就是非常公平的排队，对于普通的磁盘驱动器来说，这是很好的方案，但对于以期限调度为优势的固态硬盘来说，这并不是最好的。\n\n　　如果你想在系统中对所有磁盘采用期限调度，可以在内核加载时把`elevator=deadline`这句话加入到系统引导管理器(GURB)中;如果你只是想针对某一个磁盘，就应该在rc.local文件中加入类似如下实例的一句话，那么每次当系统重启，期限调度就会应用到指定的磁盘。如下实例将会对 /dev/sdb磁盘采用期限调度。\n\n```sh\necho deadline > /sys/block/xvda/queue/scheduler\n```\n　　给IO的算法修改成 noop,操作系统本身不做处理,让 ssd 本身处理.\n\n```sh\necho noop >  /sys/block/sda/queue/scheduler\n```\n\n# 四、清理固态硬盘(SSD)中的数据块\n\n　　最后一个重要的步骤称为“清理”，该操作可以确保在删除文件后相应的数据块真正清空，然后在创建新的文件时才能有可用的数据块。如果没有清理操作，一旦数 据块空间填满，固态硬盘的性能就会下降。如果使用丢弃挂载选项，当文件删除后，数据块也会被相应地清除，这样可以显著提高固态硬盘的性能。2.6.33以 上的内核已经支持清理操作。\n\n　　Linux内核从2.6.33开始提供TRIM支持，所以先运行“uname -a”命令，查看自己的内核版本，如果内核版本低于2.6.33的，请先升级内核。然后运行“hdparm -I /dev/sda”查看自己的硬盘支不支持TRIM技术，如果支持，你会看到\n\n```\n* Data Set Management TRIM supported\n```\n\n　　注意：如果SSD组RAID0后，将失去Trim功能\n\n　　如果上面两个条件都满足了，就可以在fstab中添加discard来开启TRIM功能，如：\n\n```sh\n原始的UUID=2f6be0cf-2f54-4646-b8c6-5fb0aa01ef23 / ext4 defaults,errors=remount-ro 0 1\n改后的UUID=2f6be0cf-2f54-4646-b8c6-5fb0aa01ef23 / ext4 discard,defaults,errors=remount-ro,noatime 0 1\n```\n\n　　在fasab配置文件中完成对文件系统的这些修改后，重启计算机，或者通知文件系统重新读取其配置，然后使用/etc/fstab文件中包含的mount -o remount命令重新安装每个文件系统。\n\n","tags":["调优"],"categories":["system"]},{"title":"rsync安装配置实例","url":"/2017/05/26/service/rsync安装配置实例/","content":"\n本文详细介绍了rsync安装配置实例。\n<!-- more -->\n\n# 一. 安装rsync\n\n```sh\nyum install rsync\n```\n\n# 二. 配置rsync服务器端\n\n### 1、  修改rsync的配置文件\n\n```sh\ncat /etc/xinetd.d/rsync\n\n# default: off\n# description: The rsync server is a good addition to an ftp server, as it \\\n#   allows crc checksumming etc.\nservice rsync\n{\n    disable = yes\n    flags           = IPv6\n    socket_type     = stream\n    wait            = no\n    user            = root\n    server          = /usr/bin/rsync\n    server_args     = --daemon\n    log_on_failure  += USERID\n}\n\n```\n\n　　可以看到rysnc服务是关闭的(disable = yes)，这里把它开启，把disable的值改为no\n\n### 2、  创建rsync服务器配置文件/etc/rsyncd.conf\n\n```sh\nvim /etc/rsyncd.conf\n\nuid = root\ngid = root\nport = 873                                      #　指定运行端口，默认是873，您可以自己指定\nhosts allow = 192.168.0.204, 192.168.1.205      # 允许访问的客户机\n#hosts deny = 0.0.0.0/32                        #　拒绝访问的\nuse chroot = \nmax connections = \ntimeout=\n\n# 下面这些文件是安装完RSYNC服务后自动生成的文件,当然也可以手动配置到指定路径\n\npid file = /var/run/rsyncd.pid      #pid文件的存放\nlock file = /var/run/rsync.lock     #锁文件的存放位置\nlog file = /var/log/rsyncd.log      #日志记录文件的存放\nmotd file = /etc/rsyncd.motd        #欢迎\n\n# 上面这段是全局配置，下面的模块可以有\n\n[test]                                        # 模块名字，自己命名\npath = /home/hyj/workspace/test               # 指定文件目录所在位置，这是必须指定 \ncomment = rsync files                         # 注释\nignore errors                                 # 忽略IO\nread only = yes \nlist = no                                     # 是否把rsync 服务器上提供同步数据的目录显示\nauth users = rsync                            # 同步验证时用的账号，如果没有这项就是匿名同步，client同步时不用用户名也能同步。\nsecrets file = /etc/rsync.passwd              # 指定认证文件\n```\n\n### 3、  创建认证文件：\n\n#### 3.1. 创建认证文件\n```sh\nvim /etc/rsync.passwd\n\nrsync:hyl            # 用户名：密码。注意这个不是系统用户，只是rsync用户。所以不用useradd。\n```\n\n　　名字随便写，只要和上边配置文件里的“auth users”参数一致即可，格式(一行一个用户)账号：密码\n\n\n#### 3.2. 修改认证文件权限\n\n　　把认证文件的权限改成600\n\n```sh\nchmod 600 /etc/rsync.passwd          ## 只能所有者可读，否则报错\n```\n\n### 4、 欢迎信息\n\n　　如果在配置文件中指定了欢迎信息，在/etc下创建rsyncd.motd，设置欢迎信息：\n\n```sh\nvim /etc/rsyncd.motd\n\n      Welcome the rsync services!\n```\n\n# 三. 启动rsync\n\n### 1、 在server端将rsync启动：\n\n#### 1.1 启动rsync服务端（以守护进程形式，独立启动）\n\n```sh\n/usr/bin/rsync --daemon\n```\n\n#### 1.2 启动rsync服务端 （以xinetd超级进程启动）\n\n```sh\n/etc/rc.d/init.d/xinetd reload(reload是网上的说法，但是我试了一下报错，start可以)\n```\n\n### 2、 防火墙设置：\n\n　　如果服务器上装有防火墙，需在服务器中设置iptables将837端口开放。\n\n```sh\niptables -A INPUT -p tcp --dport 873 -j ACCEPT\n```\n\n# 四. 配置rsync客户端\n\n### 1、用安装服务器端的方式安装rsync。\n\n　　启动rsync，如果报如下错误，是因为在etc下没有rsyncd.conf配置文件：\n\n```sh\nrsync --daemon\nFailed to parse config file: /etc/rsyncd.conf\n```\n\n　　创建配置文件 `/etc/rsyncd.conf` 文件内容为空就行。然后启动rsync，可以启动\n\n### 2、Rsync的命令格式可以为以下六种：\n\n```sh\n　　rsync [OPTION]... SRC DEST\n　　rsync [OPTION]... SRC [USER@]HOST:DEST\n　　rsync [OPTION]... [USER@]HOST:SRC DEST\n　　rsync [OPTION]... [USER@]HOST::SRC DEST\n　　rsync [OPTION]... SRC [USER@]HOST::DEST\n　　rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n```\n\n　　常用为以下两种：\n\n#### 第一种：\n\n```sh\nrsync [OPTION]... [USER@]HOST::SRC   DEST\n```\n\n　　从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含\"::\"分隔符时启动该模式。\n\n```sh\n如：rsync -av root@172.16.78.192::www /databack\n```\n\n#### 第二种：\n\n```sh\nrsync [OPTION]... SRC   [USER@]HOST::DEST\n```\n\n　　从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含\"::\"分隔符时启动该模式。\n\n```sh\n如：rsync -av /databack root@172.16.78.192::www\n```\n\n### 3、下面为实例：\n\n　　服务器ip为192.168.8.126，客户端ip为192.168.8.122\n\n　　(1)、把服务器上的/home/hyj/workspace/test文件夹中的内容备份到客户端的/usr/local/share/rsync_backup中:\n\n```sh\n/usr/bin/rsync -vzrtopg --delete  --progress rsync@192.168.8.126::test /usr/local/share/rsync_backup\n```\n\n　　`/etc/rsyncd.conf` 中模块的内容：\n\n```sh\n[test]\npath = /home/hyj/workspace/test\ncomment = rsync files\nignore errors\nread only = yes\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n```\n\n　　上面这个命令行中-vzrtopg里的v是verbose，z是压缩，r是recursive，topg都是保持文件原有属性如属主、时间的参数（也可以用直接用a来代替rtopg， a为 --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD）。--progress是指显示出详细的进度情况，--delete是指如果服务器端删除了这一文件，那么客户端也相应把文件删除，保持真正的一致。\n\n　　（2）、上面的命令需要在备份的时候需要输入密码，可以在客户端建立一个密码文件，在命令中把密码文件作为参数带入：\n\n```sh\nvim /etc/rsync.passwd\n\nhyl\n```\n\n　　密码文件中不用输入用户名，只需输入密码即可。\n\n\n　　这份密码文件权限属性要设得只有root可读，不然会报错，修改属性：\n\n```sh\nchmod 600 /etc/rsync.passwd\n```\n\n　　用下面这条命令，可以不输入密码：\n\n```sh\n/usr/bin/rsync -vzrtopg --delete  --progress --password-file=/etc/rsync.passwd rsync@192.168.8.126::test /usr/local/share/rsync_backup \n```\n　　(3)、 带exclude 参数\n\n　　把服务器上的/home/hyj/workspace/test文件夹中的内容备份到客户端的/usr/local/share/rsync_backup中，但不包括:res目录和default.properties文件：\n\n```sh\n/usr/bin/rsync -vzrtopg --delete --exclude \"res/\" --exclude \"default.properties\" --progress --password-file=/etc/rsync.passwd rsync@192.168.8.126::test /usr/local/share/rsync_backup \n```\n\n** exclude/include规则实例 **\n\n```sh\nHere are some exclude/include examples:\n --exclude \"*.o\"   would exclude all filenames matching *.o\n --exclude \"/foo\"  would exclude a file in the base directory called foo\n --exclude \"foo/\"  would exclude any directory called foo.\n --exclude \"/foobar\" would exclude any file called bar two or more levels below a base directory called foo.\n --include \"*/\" --include \"*.c\" --exclude \"*\" would include all directories and C source files\n--include \"foo/\" --include \"foo/bar.c\" --exclude \"*\" would include only foo/bar.c\n (the foo/ directory must be explicitly included or it would be excluded by the \"*\")\n\n```\n　　(4)、 把客户端上的/home/hyj/vitest文件夹中的内容备份到服务器的/usr/local/share/rsync_backup中，在客户端执行如下命令:\n\n```sh\n   /usr/bin/rsync -vzrtopg --delete --progress --password-file=/etc/rsync.passwd /home/hyj/vitest rsync@192.168.8.126::clientdata\n```\n\n　　此时服务器的配置文件/etc/rsyncd.conf内容为:\n\n```sh\nuid = root\ngid = root\nhosts allow = 192.168.8.122, 192.168.8.123\n#hosts deny = 0.0.0.0/32\nuse chroot = no\nmax connections = 10\npid file = /var/run/rsyncd.pid\nlock file = /var/run/rsync.lock\nlog file = /var/log/rsyncd.log\ntimeout=600\n\n[test]\npath = /home/hyj/workspace/test\ncomment = rsync files\nignore errors\nread only = yes\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n\n # 上面的命令中，客户端的数据备份到clientdata模块中，备份到/usr/local/share/rsync_backup文件夹下，read only改为no，# # 否则会报 `ERROR: module is read only` 的错误\n\n[clientdata]\npath = /usr/local/share/rsync_backup\ncomment = rsync files\nignore errors\nread only = no\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n```\n\n\n# FAQ\n\n### 1、我需要在防火墙上开放哪些端口以适应rsync？\n\n　　视情况而定\n\n　　rsync可以直接通过873端口的tcp连接传文件，也可以通过22端口的ssh来进行文件传递，但你也可以通过下列命令改变它的端口：\n\n```sh\nrsync --port 8730 otherhost::\n或者\nrsync -e 'ssh -p 2002' otherhost:\n```\n\n### 2、 我如何通过rsync只复制目录结构，忽略掉文件呢？\n\n```sh\nrsync -av --include '*/' --exclude '*' source-dir dest-dir\n```\n\n# 常见错误\n\n```sh\nrsync: failed to connect to 218.107.243.2: No route to host (113) \nrsync error: error in socket IO (code 10) at clientserver.c(104) [receiver=2.6.9]\n```\n　　解决：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能。关闭防火墙，其实就是把tcp udp 的873端口打开：\n\n---\n\n```sh\npassword file must not be other-accessible \ncontinuing without password file \nPassword: \n```\n\n　　解决：这是因为rsyncd.pwd rsyncd.sec的权限不对，应该设置为600。如：`chmod 600 rsyncd.pwd`\n\n---\n\n```sh\n@ERROR: auth failed on module xxxxx \nrsync: connection unexpectedly closed (90 bytes read so far) \nrsync error: error in rsync protocol data stream (code 12) at io.c(150) \n```\n\n　　解决：这是因为密码设置错了，无法登入成功，检查一下rsync.pwd，看客服是否匹配。还有服务器端没启动rsync 服务也会出现这种情况。 \n\n---\n\n```sh\n@ERROR: chroot failed \nrsync: connection unexpectedly closed (75 bytes read so far) \nrsync error: error in rsync protocol data stream (code 12) at io.c(150) \n```\n\n　　解决：这是因为你在 rsync.conf 中设置的 path 路径不存在，要新建目录才能开启同步。 \n\n---\n\n```sh\n[root@hyj rsync_backup]# /usr/bin/rsync -vzrtopg --delete --exclude \"res/\" --exclude \"default.properties\" --progress rsync@192.168.8.126::test /usr/local/share/rsync_backup --password-file=/etc/rsync.pass\n\n@ERROR: chdir failed\n\nrsync error: error starting client-server protocol (code 5) at main.c(1516) [Receiver=3.0.9]\n```\n\n　　原因及解决办法：SELinux；（下面这条命令在服务器端执行）\n```sh\nsetsebool -P rsync_disable_trans on\n```\n\n---\n\n```sh\nERROR: module is read only\nrsync: read error: Software caused connection abort (113)\nrsync error: error in rsync protocol data stream (code 12) at io.c(769) [sender=3.0.8]\n```\n\n　　解决：这是因为服务器端配置文件rsyncd.conf中read only = yes，为只读，即不允许客户端上传文件，改成no就可以了。\n","tags":["rsync"],"categories":["service"]},{"title":"pdflush进程详解与优化","url":"/2017/05/25/system/pdflush进程详解与优化/","content":"# 一、简介\n\n　　由于页高速缓存的缓存作用，写操作实际上会被延迟。当页高速缓存中的数据比后台存储的数据更新时，那么该数据就被称做脏数据。在内存中累积起来的脏页最终必须被写回磁盘。\n\n<!-- more -->\n\n在以下两种情况发生时，脏页被写回磁盘：\n\n* 当空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。\n* 当脏页在内存中驻留时间超过一个特定的阈值时，内核必须将超时的脏页写回磁盘，以确保脏页不会无限期地驻留在内存中。\n\n　　上面两种工作的目的完全不同。实际上，在老内核中，这是由两个独立的内核线程分别完成的。但是在2.6内核中，由一群内核线程—pdflush后台回写例程—统一执行两种工作。\n\n　　我们来看看这两个目标是如何具体实现的。首先，当系统中的空闲内存低于一个特定的阈值时，pdflush线程将脏页刷新回磁盘。该后台回写例程的目的在于在可用物理内存过低时，释放脏页以重新获得内存。特定的内存阈值可以通过`dirty_background_ratio`参数设置。当空闲内存比阈值`dirty_ background_ratio`还低时，内核便会调用函数`wakeup_bdflush()`唤醒一个pdflush线程，随后pdflush线程进一步调用函数`background_writeout()`开始将脏页写回磁盘。函数`background_ writeout()`需要一个长整型参数，该参数指定试图回写的页面数目。\n\n　　函数`background_writeout()`会连续地写出数据，直到满足以下两个条件：\n\n* 已经有指定的最小数目的页被写出到磁盘。\n* 空闲内存数已经回升，超过了阈值dirty_background_ratio。\n\n　　上述条件确保了pdflush操作可以减轻系统中内存不足的压力。回写操作不会在达到这两个条件前停止，除非pdflush写回了所有的脏页，没有剩下的脏页可再被写回了。\n\n　　要满足第二个目标，pdflush后台例程会被周期性唤醒（和空闲内存是否过低无关），将那些在内存中驻留时间过长的脏页写出，确保内存中不会有长期存在的脏页。假如系统发生崩溃，则内存会处于混乱之中，而那些在内存中还没来得及写回磁盘的脏页就会丢失，所以周期性同步回写非常重要。\n\n　　在系统启动时，内核初始化一个定时器，让它周期地唤醒pdflush线程，随后使其运行函数`wb_kupdate()`。该函数将把所有驻留时间超过百分之`dirty_expire_centisecs`秒的脏页写回。然后定时器将再次被初始化为百分之`dirty_expire_ centisecs`秒后唤醒pdflush线程。\n\n　　总而言之，pdflush线程周期地被唤醒并且把超过特定期限的脏页写回磁盘。\n\n# 二、proc下的相关控制参数\n\n　　系统管理员可以在/proc/sys/vm中设置回写相关的参数，也可以通过sysctl系统调用设置它们。\n\n* /proc/sys/vm/dirty_ratio\n\n　　这个参数控制一个进程在文件系统中的文件系统写缓冲区的大小，单位是百分比，表示系统内存的百分比，表示当一个进程中写缓冲使用到系统内存多少的时候，再有磁盘写操作时开始向磁盘写出数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是 40。设置方法如下：\n\n```sh\necho 30 >/proc/sys/vm/dirty_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_background_ratio\n\n　　这个参数控制文件系统的pdflush进程，在何时刷新磁盘。单位是百分比，表示系统总内存的百分比，意思是当磁盘的脏数据缓冲到系统内存多少的时候，pdflush开始把脏数据刷新到磁盘。增大会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是10。设置方法如下：\n\n```sh\necho 8 >/proc/sys/vm/dirty_background_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_writeback_centisecs\n\n　　Pdflush写后台进程每隔多久被唤醒并执行把脏数据写出到硬盘。单位是 1/100 秒。如果你的系统是持续地写入动作，那么实际上还是降低这个数值比较好，这样可以把尖峰的写操作削平成多次写操作。缺省数值是500，也就是 5 秒。设置方法如下：\n\n```sh\necho 200 >/proc/sys/vm/dirty_writeback_centisecs\n```\n\n---\n\n* /proc/sys/vm/dirty_expire_centisecs\n\n　　这个参数声明Linux内核写缓冲区里面的脏数据多“旧”了之后，pdflush 进程就开始考虑写到磁盘中去。单位是 1/100秒。对于特别重载的写操作来说，这个值适当缩小也是好的，但也不能缩小太多，因为缩小太多也会导致IO提高太快。缺省是 30000，也就是 30 秒的数据就算旧了，将会刷新磁盘。建议设置为 1500，也就是15秒算旧。设置方法如下：\n\n```sh\necho 1500 >/proc/sys/vm/dirty_expire_centisecs\n```\n\n---\n\n# 三、内核参数修改后的生效\n\n　　Linux在系统运行时修改内核参数(/proc/sys与/etc/sysctl.conf)，而不需要重新引导系统，这个功能是通过/proc虚拟文件系统实现的。\n\n　　在/proc/sys目录下存放着大多数的内核参数，并且设计成可以在系统运行的同时进行更改,可以通过更改/proc/sys中内核参数对应的文件达到修改内核参数的目的(修改过后，保存配置文件就马上自动生效)，不过重新启动机器后之前修改的参数值会失效，所以只能是一种临时参数变更方案。(适合调试内核参数优化值的时候使用，如果设置值有问题，重启服务器还原原来的设置参数值了。简单方便。)\n\n　　但是如果调试内核参数优化值结束后，需要永久保存参数值，就要通过修改/etc/sysctl.conf内的内核参数来永久保存更改。但只是修改sysctl文件内的参数值，确认保存修改文件后，设定的参数值并不会马上生效，如果想使参数值修改马上生效，并且不重启服务器，可以执行下面的命令：\n\n```sh\nsysctl –p\n```\n\n---\n\n　　下面介绍一下/proc/sys下内核文件与配置文件sysctl.conf中变量的对应关系：\n\n　　由于可以修改的内核参数都在/proc/sys目录下，所以sysctl.conf的变量名省略了目录的前面部分（/proc/sys）。即将/proc/sys中的文件转换成sysctl中的变量依据下面两个简单的规则：\n\n1. 去掉前面部分/proc/sys\n2. 将文件名中的斜杠变为点\n\n　　这两条规则可以将/proc/sys中的任一文件名转换成sysctl中的变量名。\n\n　　例如：\n\n```sh\n/proc/sys/net/ipv4/ip_forward => net.ipv4.ip_forward\n/proc/sys/kernel/hostname =>  kernel.hostname\n```\n\n　　可以使用下面命令查询所有可修改的变量名\n\n```sh\nsysctl –a\n```\n","tags":["调优"],"categories":["system"]},{"title":"MongoDB归档及压缩工具","url":"/2017/05/25/database/MongoDB归档及压缩工具/","content":"　　原文地址：http://t.dbdao.com/archives/archiving-and-compression-in-mongodb-tools.html\n\n\n# 介绍\n\n　　我在MongoDB World 2015做的演讲“Putting the Go in MongoDB”，重点是关于MongoDB工具的重写，从C ++到Go，这在可用性以及性能方面得到了一些改进，但是这里我只简要的说两个方面的新功能，(planned for the 3.2 release) – 归档和压缩。\n\n　　在本文中，我将对mongodump和mongorestore提供更详细的归档和压缩特性说明，并探索使用这些特性的可行用例。\n\n\n<!-- more -->\n\n# 概述\n\n　　一个通常目的的归档一般由一个或多个文件组成。这样例子如磁带归档格式(tar)，其中包含按顺序组成的一个或多个文件。归档在执行进程间通信的应用程序中尤其有用，例如，你可以通过远程服务器进行目录的tarball压缩，然后通过SSH，传送到到本机上进行解压：\n\n```ssh\nssh source.server.com tar c sourceDirectory | tar x\n```\n\n　　由于归档以顺序的方式创建，接收端将能按顺序接收到发送端按顺序发来的数据。\n\n　　在3.0中，我们增加了在MongoDB中并发执行备份和恢复多个集合的能力，这可以让你执行备份时，更加充分地利用磁盘I / O。 结果，写入mongodump的备份并不一定以顺序的方式接收。 同样，mongorestore同时读取还原操作集合，它的读取指令也并非是序列性的。\n\n　　通用归档格式，如tar，只支持连续的文件归档打包。mongodump和mongorestore利用这些备份格式，将得到一个不可接受的性能退化， 由于所有集合的数据将不得不被按顺序写入和读出。为了支持这些工具的并发行为，我们研发了一个特殊的通用备份格式，支持非并发文件的写入。 这个新的归档特性极大了提高了备份和还原操作的效率。\n\n# 背景\n\n　　为了按上下文情况进行备份，我们考虑一下你们通常是如何创建备份的。比如，假设你有一个“country”的数据库，其中含有两个集合： “nigeria” and “austria”， 你可能会这样操作：\n\n```sh\t\nmongodump --db country\n```\n\n　　上面的指令读取“country”数据库的所有集合， 然后将其写入“dump”目录。 上面的指令就会产生以下的目录列表：\n\n```sh\ndump/\n└── [4.3M]  country\n    ├── [2.1M]  austria.bson\n    ├── [  87]  austria.metadata.json\n    ├── [2.1M]  nigeria.bson\n    ├── [  87]  nigeria.metadata.json\n    └── [ 140]  system.indexes.bson\n \n1 directory, 5 files\n```\n\n　　你也可以备份整个服务器-这里的服务器包含两个数据库(country 和product)。\n\n```sh\nmongodump\n```\n\n```sh\n├── [5.4M]  dump\n│   ├── [4.03M]  country\n│   │   ├── [2.1M]  austria.bson\n│   │   ├── [  87]  austria.metadata.json\n│   │   ├── [2.1M]  nigeria.bson\n│   │   ├── [  87]  nigeria.metadata.json\n│   │   └── [ 140]  system.indexes.bson\n│   └── [1.1M]  product\n│       ├── [1.0M]  mongodump.bson\n│       ├── [  89]  mongodump.metadata.json\n│       └── [  72]  system.indexes.bson\n2 directories, 8 files\n```\n\n　　或选择备份单个集合到标准输出，而不是一个目录：\n\n```sh\t\nmongodump --db country --collection nigeria --out -\n```\n\n# 归档支持\n\n　　在3.2中，我们引入了创建备份的一个附加模式 －－ “归档”模式，写入所有转储数据，甚至从不同的数据库和集合到单一的输出文件。 使用mongodump创建归档是极为简单的 – 只需要一个附加选项：\n\n```sh\nmongodump --db country --archive=country.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 4.2M Jun 29 11:12 country.archive\n```\n\n　　上面的指令将在“country.archive”文件中创建“country”的数据库归档。默认情况下，归档被写入到标准输出。不同于目录模式的执行备份，创建目录树，默认归档模式下备份结果就是一个单一的文件， 包含“country”数据库的所有数据-所有集合，索引等。\n\n　　你也可以备份一个单一的集合或整个服务器的内容：\n\n　　**单一集合：**\n\n```sh\t\nmongodump --db country --collection nigeria --archive=nga.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 2.1M Jun 29 11:15 nga.archive\n```\n\n　　**整个服务器：**\n\n```sh\nmongodump --archive=server.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 5.3M Jun 29 11:26 server.archive\n```\n\n　　在mongodump的这种情况下，归档模式允许多个集合以非连续的方式打包在归档文件内。在mongorestore中，它允许多个集合进行并行恢复。这样，你可以在网络上执行数据迁移，降低磁盘I/O所占空间，享受到充分利用工具和底层存储引擎的并发所带来的好处。\n\n# 数据迁移\n\n　　一个新的备份改善的例子， 是mongodump和mongorestore之间的进程间通信 – 特别是能够将数据从一个传到另一个。在以前的版本中，这种支持有限 – 一个时间只能传输一个集合。现在，使用归档就没有这样的限制。这种方式对于数据库服务器出于安全考虑而安装有防火墙的情况下很有用。在这种情况下，一个通常的设计是允许一个或多个服务器方访问数据库。使用归档功能，在SSH上进行数据转移数据，就轻而易举了：\n\n```sh\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive  | ssh wisdom@target.server.com mongorestore --archive\n```\n\n　　上面的指令使用SSH方式连接到代理主机（proxy.server.com），访问源服务器（source.server.com），在代理服务器上运行mongodump，为了最终的恢复，将源服务器的发送内容（通过SSH）到目标服务器（target.server.com）。\n\n　　如果没有归档，通过mongodump完成这些操作的唯一办法就是，先执行备份到磁盘，在将文件复制到目标服务器，然后运行mongorestore。通过备份，一个指令就可以完成- 无需任何附加磁盘I/O的开销。\n\n# 压缩支持\n\n　　除了备份，我们还使用gzip进行压缩。这是通过在mongodump和mongorestore中引入一个新的指令行选项 “--gzip” 实现的。 压缩可用于目录以及归档模型下创建的备份，压缩还可以减少磁盘空间使用。\n\n```sh\nmongodump --db country --gzip\n```\n\n　　生成：\n\n```sh\ndump/\n└── [568K]  country\n    ├── [254K]  austria.bson.gz\n    ├── [ 100]  austria.metadata.json.gz\n    ├── [254K]  nigeria.bson.gz\n    ├── [ 100]  nigeria.metadata.json.gz\n    └── [  91]  system.indexes.bson.gz\n \n1 directory, 5 files\n```\n\n　　注意,目录模型的归档备份大小-568KB-比没有压缩的备份要小很多-4.3MB.\n\n　　**压缩归档：**\n\n```sh\nmongodump --db country --gzip --archive=country.archive\n\n-rw-rw-r-- 1 wisdom wisdom 509K Jun 29 11:23 country.archive\n```\n\n　　对于归档来说，数据在写入归档之前需要先压缩。\n\n　　恢复压缩目录模式备份，你应该运行：\n\n```sh\t\nmongorestore --gzip\n```\n\n　　类似用来恢复归档模式下的压缩备份的命令：\n\n```sh\t\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive --gzip  | ssh wisdom@target.server.com mongorestore --archive --gzip\n```\n\n　　数据迁移不会产生任何磁盘I / O开销，由于压缩，将会使用更少的网络带宽。\n\n# 总结\n\n　　归档和压缩特性产生了许多用于进行备份和恢复操作的例子。如果你们正在使用MongoDB工具和其它类型的应用程序，我们也乐于倾听你们的经验及用例。 尽管目前最新版本工具还不文档，不过希望大家先对这些特性体验起来。\n\n　　**注：** 作为提供共享集群的集群范围快照的唯一备份解决方案，MongoDB Ops Manager和MongoDB Cloud Mannager被推荐用于较大的MongoDB部署。\n","tags":["mongodb"],"categories":["database"]},{"title":"Linux下清空或删除大文件内容的5种方法","url":"/2017/05/25/system/Linux下清空或删除大文件内容的5种方法/","content":"\n\n编译自：http://www.tecmint.com/empty-delete-file-content-linux/ 作者： Aaron Kili\n\n原创：LCTT https://linux.cn/article-8024-1.html 译者： FSSlc \n\n在 Linux 终端下处理文件时，有时我们想直接清空文件的内容但又不必使用任何 Linux 命令行编辑器 去打开这些文件。那怎样才能达到这个目的呢？在这篇文章中，我们将介绍几种借助一些实用的命令来清空文件内容的方法。\n\n**注意：** 在我们进一步深入了解这些方法之前，请记住: 由于在 Linux 中一切皆文件，你需要时刻注意，确保你将要清空的文件不是重要的用户文件或者系统文件。清空重要的系统文件或者配置文件可能会引发严重的应用失败或者系统错误。\n\n前面已经说道，下面的这些方法都是从命令行中达到清空文件的目的。\n\n**提示：** 在下面的示例中，我们将使用名为 access.log 的文件来作为示例样本。\n<!-- more -->\n\n# 1. 通过重定向到 Null 来清空文件内容\n\n清空或者让一个文件成为空白的最简单方式，是像下面那样，通过 shell 重定向 `null` （不存在的事物）到该文件：\n\n```sh\n> access.log\n```\n\n```sh\n[root@localhost logs]# du -sh catalina.out \n9.7G\tcatalina.out\n[root@localhost logs]# > catalina.out \n[root@localhost logs]# du -sh catalina.out \n0\tcatalina.out\n```\n\n在 Linux 下使用 Null 重定向来清空大文件\n\n# 2. 使用 `true` 命令重定向来清空文件\n\n下面我们将使用 : 符号，它是 shell 的一个内置命令，等同于 true 命令，它可被用来作为一个 no-op（即不进行任何操作）。\n\n另一种清空文件的方法是将 : 或者 true 内置命令的输出重定向到文件中，具体如下：\n\n```sh\n: > access.log\n```\n 或\n```sh\ntrue > access.log\n```\n\n使用 Linux 命令清空大文件\n\n# 3. 使用 cat/cp/dd 实用工具及 /dev/null 设备来清空文件\n\n在 Linux 中， null 设备基本上被用来丢弃某个进程不再需要的输出流，或者作为某个输入流的空白文件，这些通常可以利用重定向机制来达到。\n\n所以 /dev/null 设备文件是一个特殊的文件，它将清空送到它这里来的所有输入，而它的输出则可被视为一个空文件。\n\n另外，你可以通过使用 cat 命令 显示 /dev/null 的内容然后重定向输出到某个文件，以此来达到清空该文件的目的。\n\n```sh\ncat /dev/null > access.log\n```\n\n使用 cat 命令来清空文件\n\n下面，我们将使用 cp 命令 复制 /dev/null 的内容到某个文件来达到清空该文件的目的，具体如下所示：\n\n```sh\ncp /dev/null access.log\n```\n\n\n使用 cp 命令来清空文件\n\n而下面的命令中， if 代表输入文件，of 代表输出文件。\n\n```sh\ndd if=/dev/null of=access.log\n```\n\n\n使用 dd 命令来清空文件内容\n\n# 4. 使用 echo 命令清空文件\n\n在这里，你可以使用 echo 命令 将空字符串的内容重定向到文件中，具体如下：\n\n```sh\necho \"\" > access.log\n```\n或者\n ```sh\n echo > access.log\n```\n\n使用 echo 命令来清空文件\n\n**注意：**你应该记住空字符串并不等同于 null 。字符串表明它是一个具体的事物，只不过它的内容可能是空的，但 null 则意味着某个事物并不存在。\n\n基于这个原因，当你将 echo 命令 的输出作为输入重定向到文件后，使用 cat 命令 来查看该文件的内容时，你将看到一个空白行（即一个空字符串）。\n\n要将 null 做为输出输入到文件中，你应该使用 -n 选项，这个选项将告诉 echo 不再像上面的那个命令那样输出结尾的那个新行。\n\n```sh\necho -n \"\" > access.log\n```\n\n使用 Null 重定向来清空文件\n\n# 5. 使用 truncate 命令来清空文件内容\n\ntruncate 可被用来将一个文件缩小或者扩展到某个给定的大小。\n\n你可以利用它和 -s 参数来特别指定文件的大小。要清空文件的内容，则在下面的命令中将文件的大小设定为 0:\n\n```sh\ntruncate -s 0 access.log\n```\n\n在 Linux 中截断文件内容\n\n我要介绍的就是这么多了。在本文中，我们介绍了几种通过使用一些简单的命令行工具和 shell 重定向机制来清除或清空文件内容的方法。\n\n上面介绍的这些可能并不是达到清空文件内容这个目的的所有可行的实践方法，所以你也可以通过下面的评论栏告诉我们本文中尚未提及的其他方法。\n\n\n---\n\nvia: http://www.tecmint.com/empty-delete-file-content-linux/\n\n作者：Aaron Kili 译者：FSSlc 校对：jasminepeng\n\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","tags":["bash"],"categories":["system"]},{"title":"redis模糊删除key","url":"/2017/05/25/database/redis模糊删除key/","content":"\nRedis keys命令支持模式匹配，但是del命令不支持模式匹配，有时候需要根据一定的模式来模糊删除key，这时只能结合shell命令来完成了。 具体命令是：\n\n<!-- more -->\n\n```sh\nredis-cli KEYS \"pattern\" | xargs redis-cli DEL\n```\n\n其中pattern是keys命令支持的模式，这样就可以模糊删除key了。服务器上测试删除150万条数据的效率也是很高的。\n\n所有的Redis命令可以在这里找到：http://redis.io/commands\n\nKEYS命令：http://redis.io/commands/keys\n\nDEL命令: http://redis.io/commands/del\n\n**my demo:**\n\nprefix_: 需要删除key的匹配的前缀名\n```sh\nredis-cli KEYS \"prefix_\" | xargs redis-cli DEL \n```\n","tags":["redis"],"categories":["database"]},{"title":"Linux查看文件编码格式及文件编码转换","url":"/2017/05/25/system/Linux查看文件编码格式及文件编码转换/","content":"\n如果你需要在Linux 中操作windows下的文件，那么你可能会经常遇到文件编码转换的问题。Windows中默认的文件格式是GBK(gb2312)，而Linux一般都是UTF-8。下面介绍一下，在Linux中如何查看文件的编码及如何进行对文件进行编码转换。\n\n<!-- more -->\n\n# 查看文件编码\n\n在Linux中查看文件编码可以通过以下几种方式：\n\n### 1.在Vim 中可以直接查看文件编码\n\n```sh\n    :set fileencoding  \n```\n\n即可显示文件编码格式。\n\n如果你只是想查看其它编码格式的文件或者想解决用Vim查看文件乱码的问题，那么你可以在 `~/.vimrc` 文件中添加以下内容：\n\n```sh\n    set encoding=utf-8 fileencodings=ucs-bom,utf-8,cp936\n```\n\n这样，就可以让vim自动识别文件编码（可以自动识别UTF-8或者GBK编码的文件），其实就是依照 fileencodings提供的编码列表尝试，如果没有找到合适的编码，就用latin-1(ASCII)编码打开。\n\n### 2. enca (如果你的系统中没有安装这个命令，可以用sudo yum install -y enca 安装 )查看文件编码\n\n```sh\n$ enca filename\nfilename: Universal transformation format 8 bits; UTF-8\nCRLF line terminators\n```\n\n需要说明一点的是，enca对某些GBK编码的文件识别的不是很好，识别时会出现：\n\n```\nUnrecognized encoding\n```\n\n# 文件编码转换\n\n### 1.在Vim中直接进行转换文件编码,比如将一个文件转换成utf-8格式\n\n```sh\n    :set fileencoding=utf-8  \n```\n\n### 2. enconv 转换文件编码，比如要将一个GBK编码的文件转换成UTF-8编码，操作如下\n\n```sh\nenconv -L zh_CN -x UTF-8 filename\n```\n\n### 3. iconv 转换，iconv的命令格式如下：\n\n```sh\niconv -f encoding -t encoding inputfile\n```\n\n比如将一个UTF-8 编码的文件转换成GBK编码\n\n```sh\niconv -f GBK -t UTF-8 file1 -o file2\n```\n","tags":["字符集"],"categories":["system"]},{"title":"Bash历史中执行过的每一项命令设置时间和日期.md","url":"/2017/05/25/system/Bash历史中执行过的每一项命令设置时间和日期/","content":"\n在默认情况下，所有通过 Bash 在命令行中执行过的命令都被存储在历史缓存区或者一个叫做 ` ~/.bash_history` 的文件里。这意味着系统管理员可以看到系统上用户执行过的命令清单，或者用户可以通过像 `history` 命令这样的选项来看他或她自己的命令历史。\n<!-- more -->\n\n```sh\n[root@l-webdb-docker-dev ~]# history \n    1  vim /gotwo_data/scripts/cronjob/sync_mysql_online.sh\n    2  exit\n    3  ps -ef | grep 4004\n    4  exit\n    5  mysql\n    6  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n    7  vim /tmp/db_ad.sql \n    8  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n```\n\n从上面` history `命令的输出可知，命令被执行的日期和时间并没有显示出来。基本上所有的 Linux 发行版的默认设置都是这样的。\n\n在这篇文章里，我们将解释当在 Bash 中执行` history `命令显示每个命令时，如何配置显示时间戳信息。\n\n每个命令相关的日期和时间可以记录到历史文件中，用 `HISTTIMEFORMAT` 环境变量的设置作为命令历史的备注记录。\n\n这里有两种可行的方式来达到目的：一种是暂时的效果，一种是永久的效果。\n\n要临时设置 `HISTTIMEFORMAT `环境变量，在命令行这样输出它：\n```sh\n $ export HISTTIMEFORMAT='%F %T '\n```\n\n在上面的输出命令当中，时间戳格式如下：\n\n1. `％F`－展开为完整日期，即` ％Y-％m-％d`（年-月-日）。\n\n2. `％T`－展开为时间，即` ％H:％M:％S`（时:分:秒）。\n\n通读 date 命令的 man 手册来获得更多使用说明：\n\n```sh\nman date\n```\n\n（LCTT 译注：注意：这个功能只能用在当 HISTTIMEFORMAT 这个环境变量被设置之后，之后的那些新执行的 bash 命令才会被打上正确的时间戳。在此之前的所有命令，都将会显示成设置 HISTTIMEFORMAT 变量的时间。）\n\n然而，如果你想永久地配置该变量，用你最喜欢的编辑器打开文件 ` ~/.bashrc`\n\n```sh\n    $ vi ~/.bashrc\n```\n    \n然后在下方添加（用注释将其标记为你自己的配置）：\n  \n```sh\n# 我的配置\nexport HISTTIMEFORMAT='%F %T '\n```\n\n保存文件并退出，然后，运行下面的命令以便改动当即生效：\n\n```sh\nsource ~/.bashrc\n```\n","tags":["bash"],"categories":["system"]}]