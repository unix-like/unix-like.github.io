[{"title":"Linux服务器iptables配置","url":"/2017/06/07/service/Linux服务器iptables配置/","content":"\n一些工作中用到的防火墙规则样例。\n\n<!-- more -->\n\n# 防火墙规则示例脚本\n\n```sh\n#!/bin/bash\n\nIPTABLES=/sbin/iptables\nMODPROBE=/sbin/modprobe\n\n# IP4\necho \"[+] Flushing existing $IPTABLES rules...\"\n$IPTABLES -F\n$IPTABLES -F -t nat\n$IPTABLES -X\n$IPTABLES -t filter -P INPUT DROP\n$IPTABLES -t filter -P OUTPUT DROP\n$IPTABLES -t filter -P FORWARD DROP\n\n# load connection-tracking modules\necho \"[+] Modprode iptables modle...\"\n$MODPROBE ip_conntrack\n$MODPROBE iptable_nat\n$MODPROBE ip_conntrack_ftp\n$MODPROBE ip_nat_ftp\n\n# IP4\necho \"[+] Setting up OUTPUT chain...\"\n$IPTABLES -t filter -A INPUT -i lo -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -o lo -j ACCEPT\n\n# ping limit\n$IPTABLES -t filter -A INPUT -p icmp  -m state --state NEW,ESTABLISHED,RELATED  -m icmp --icmp-type echo-request    -m limit --limit 10/second  -j ACCEPT\n$IPTABLES -t filter -A INPUT -p icmp  -m state --state NEW,ESTABLISHED,RELATED  -m icmp --icmp-type echo-reply    -m limit --limit 10/second  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p icmp -m state --state NEW,ESTABLISHED,RELATED    -j ACCEPT\n\n# SSH PORT\n$IPTABLES -t filter -A INPUT -p tcp  --dport 60021 -m state --state NEW,ESTABLISHED  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp  --sport 60021 -m state --state ESTABLISHED -j ACCEPT\n\n#QQ MAIL SMTP PORT\n\n$IPTABLES -t filter -A INPUT -p tcp  --dport 465 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp  --dport 465 -j ACCEPT\n$IPTABLES -t filter -A INPUT -p tcp  --sport 25  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp  --dport 25 -j ACCEPT\n\n#database ip\n$IPTABLES -t filter -A INPUT  -p tcp  -s 192.168.1.2 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp  -d 192.168.1.2 -j ACCEPT\n\n#TAOBAO api\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 122.199.160.211 -m state --state NEW,ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 122.199.160.211 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n#zabbix\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 119.119.119.119 --dport 10050 -m state --state NEW,ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 119.119.119.119 --sport 10050 -m state --state ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A INPUT  -p tcp -m tcp -s 119.119.119.119 --sport 10051 -m state --state ESTABLISHED -j ACCEPT\n$IPTABLES -t filter -A OUTPUT  -p tcp -m tcp -d 119.119.119.119 --dport 10051 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n#web port\n$IPTABLES -t filter -A INPUT -p tcp -m state --state NEW,ESTABLISHED -m multiport --destination-port  80,443 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p tcp -m state --state ESTABLISHED -m multiport --source-port  80,443 -j ACCEPT\n\n\n$IPTABLES -t filter -A OUTPUT -p tcp -m state --state NEW,ESTABLISHED -m multiport --destination-port  80,443 -j ACCEPT\n$IPTABLES -t filter -A INPUT -p tcp -m state --state ESTABLISHED -m multiport --source-port  80,443 -j ACCEPT\n\n#DNS \n$IPTABLES -t filter -A INPUT -p udp -m state --state ESTABLISHED  --sport 53 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p udp -m state --state NEW,ESTABLISHED --dport 53 -j ACCEPT\n\n\n#NTP TIME SYNC\n$IPTABLES -t filter -A INPUT  -p udp -m state --state ESTABLISHED --sport 123  -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p udp -m state --state NEW,ESTABLISHED --dport 123  -j ACCEPT\n\n#limit syn foold\n$IPTABLES -t filter  -A INPUT -p tcp --syn -m limit --limit 2048/s -j ACCEPT\n\n\n##############Iptables save and restart\necho \"Iptables save and restart ...\"\n/etc/init.d/iptables  save\n/etc/init.d/iptables restart\n\n```\n\n# 防火墙debug脚本\n\n```sh\nIPTABLES=/sbin/iptables\nMODPROBE=/sbin/modprobe\n\n####IP4\necho \"[+] Flushing existing $IPTABLES rules...\"\n$IPTABLES -F\n$IPTABLES -F -t nat\n$IPTABLES -X\n$IPTABLES -t filter -P INPUT ACCEPT\n$IPTABLES -t filter -P OUTPUT ACCEPT\n$IPTABLES -t filter -P FORWARD ACCEPT\n$IPTABLES -t filter -A INPUT -p udp -m state --state ESTABLISHED  --sport 53 -j ACCEPT\n$IPTABLES -t filter -A OUTPUT -p udp -m state --state NEW,ESTABLISHED --dport 53 -j ACCEPT\n\n##############Iptables save and restart\necho \"Iptables save and restart ...\"\n/etc/init.d/iptables   save\n/etc/init.d/iptables  restart\n```\n","tags":["iptables"],"categories":["service"]},{"title":"Ubuntu 15.04 上配置 OpenVPN 服务器和客户端","url":"/2017/06/06/service/在Ubuntu15.04上配置OpenVPN服务器和客户端/","content":"\n　　虚拟专用网（VPN）常指几种通过其它网络建立连接技术。它之所以被称为“虚拟”，是因为各个节点间的连接不是通过物理线路实现的，而“专用”是指如果没有网络所有者的正确授权是不能被公开访问到。\n\n<!-- more -->\n\n　　OpenVPN软件借助TUN/TAP驱动使用TCP和UDP协议来传输数据。UDP协议和TUN驱动允许NAT后的用户建立到OpenVPN服务器的连接。此外，OpenVPN允许指定自定义端口。它提供了更多的灵活配置，可以帮助你避免防火墙限制。\n\n　　OpenVPN中，由OpenSSL库和传输层安全协议（TLS）提供了安全和加密。TLS是SSL协议的一个改进版本。\n\n　　OpenSSL提供了两种加密方法：对称和非对称。下面，我们展示了如何配置OpenVPN的服务器端，以及如何配置使用带有公共密钥基础结构（PKI）的非对称加密和TLS协议。\n\n# 服务器端配置\n\n　　首先，我们必须安装OpenVPN软件。在Ubuntu 15.04和其它带有‘apt’包管理器的Unix系统中，可以通过如下命令安装：\n\n```sh\nsudo apt-get install openvpn\n```\n\n　　然后，我们必须配置一个密钥对，这可以通过默认的“openssl”工具完成。但是，这种方式十分难。这也是我们使用“easy-rsa”来实现此目的的原因。接下来的命令会将“easy-rsa”安装到系统中。\n\n```sh\nsudo apt-get install easy-rsa\n```\n\n　　**注意**： 所有接下来的命令要以超级用户权限执行，如在使用`sudo -i`命令后执行，或者你可以使用`sudo -E`作为接下来所有命令的前缀。\n\n　　开始之前，我们需要拷贝“easy-rsa”到openvpn文件夹。\n\n```sh\nmkdir /etc/openvpn/easy-rsa\ncp -r /usr/share/easy-rsa /etc/openvpn/easy-rsa\nmv /etc/openvpn/easy-rsa/easy-rsa /etc/openvpn/easy-rsa/2.0\n```\n\n　　然后进入到该目录\n  \n```sh\ncd /etc/openvpn/easy-rsa/2.0\n```\n\n　　这里，我们开始密钥生成进程。\n\n　　首先，我们编辑一个“vars”文件。为了简化生成过程，我们需要在里面指定数据。这里是“vars”文件的一个样例：\n\n```sh\nexport KEY_COUNTRY=\"CN\"\nexport KEY_PROVINCE=\"BJ\"\nexport KEY_CITY=\"Beijing\"\nexport KEY_ORG=\"Linux.CN\"\nexport KEY_EMAIL=\"open@vpn.linux.cn\"\nexport KEY_OU=server\n```\n\n　　希望这些字段名称对你而言已经很清楚，不需要进一步说明了。\n\n　　其次，我们需要拷贝openssl配置。另外一个版本已经有现成的配置文件，如果你没有特定要求，你可以使用它的上一个版本。这里是1.0.0版本。\n\n```sh\ncp openssl-1.0.0.cnf openssl.cnf\n```\n\n　　第三，我们需要加载环境变量，这些变量已经在前面一步中编辑好了。\n\n```sh\nsource ./vars\n```\n\n　　生成密钥的最后一步准备工作是清空旧的证书和密钥，以及生成新密钥的序列号和索引文件。可以通过以下命令完成。\n\n```sh\n./clean-all\n```\n\n　　现在，我们完成了准备工作，准备好启动生成进程了。让我们先来生成证书。\n\n```sh\n./build-ca\n```\n\n　　在对话中，我们可以看到默认的变量，这些变量是我们先前在“vars”中指定的。我们可以检查一下，如有必要进行编辑，然后按回车几次。对话如下\n\n```sh\nGenerating a 2048 bit RSA private key\n.............................................+++\n...................................................................................................+++\nwriting new private key to 'ca.key'\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [CN]:\nState or Province Name (full name) [BJ]:\nLocality Name (eg, city) [Beijing]:\nOrganization Name (eg, company) [Linux.CN]:\nOrganizational Unit Name (eg, section) [Tech]:\nCommon Name (eg, your name or your server's hostname) [Linux.CN CA]:\nName [EasyRSA]:\nEmail Address [open@vpn.linux.cn]:\n```\n\n　　接下来，我们需要生成一个服务器密钥\n\n```sh\n./build-key-server server\n```\n\n　　该命令的对话如下：\n\n```sh\nGenerating a 2048 bit RSA private key\n........................................................................+++\n............................+++\nwriting new private key to 'server.key'\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [CN]:\nState or Province Name (full name) [BJ]:\nLocality Name (eg, city) [Beijing]:\nOrganization Name (eg, company) [Linux.CN]:\nOrganizational Unit Name (eg, section) [Tech]:\nCommon Name (eg, your name or your server's hostname) [Linux.CN server]:\nName [EasyRSA]:\nEmail Address [open@vpn.linux.cn]:\nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\nUsing configuration from /etc/openvpn/easy-rsa/2.0/openssl-1.0.0.cnf\nCheck that the request matches the signature\nSignature ok\nThe Subject's Distinguished Name is as follows\ncountryName :PRINTABLE:'CN'\nstateOrProvinceName :PRINTABLE:'BJ'\nlocalityName :PRINTABLE:'Beijing'\norganizationName :PRINTABLE:'Linux.CN'\norganizationalUnitName:PRINTABLE:'Tech'\ncommonName :PRINTABLE:'Linux.CN server'\nname :PRINTABLE:'EasyRSA'\nemailAddress :IA5STRING:'open@vpn.linux.cn'\nCertificate is to be certified until May 22 19:00:25 2025 GMT (3650 days)\nSign the certificate? [y/n]:y\n1 out of 1 certificate requests certified, commit? [y/n]y\nWrite out database with 1 new entries\nData Base Updated\n```\n\n　　这里，最后两个关于“签署证书”和“提交”的问题，我们必须回答“yes”。\n\n　　现在，我们已经有了证书和服务器密钥。下一步，就是去省城Diffie-Hellman密钥。执行以下命令，耐心等待。在接下来的几分钟内，我们将看到许多点和加号。\n\n```sh\n./build-dh\n```\n\n　　该命令的输出样例如下\n\n```sh\nGenerating DH parameters, 2048 bit long safe prime, generator 2\nThis is going to take a long time\n................................+................<许多的点>\n```\n\n　　在漫长的等待之后，我们可以继续生成最后的密钥了，该密钥用于TLS验证。命令如下：\n\n```sh\nopenvpn --genkey --secret keys/ta.key\n```\n\n　　现在，生成完毕，我们可以移动所有生成的文件到最后的位置中。\n\n```sh\ncp -r /etc/openvpn/easy-rsa/2.0/keys/ /etc/openvpn/\n```\n\n　　最后，我们来创建OpenVPN配置文件。让我们从样例中拷贝过来吧：\n\n```sh\ncp /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz /etc/openvpn/\ncd /etc/openvpn\ngunzip -d /etc/openvpn/server.conf.gz\n```\n\n　　然后编辑\n\n```sh\nvim /etc/openvpn/server.conf\n```\n\n　　我们需要指定密钥的自定义路径\n\n```sh\nca /etc/openvpn/keys/ca.crt\ncert /etc/openvpn/keys/server.crt\nkey /etc/openvpn/keys/server.key # This file should be kept secret\ndh /etc/openvpn/keys/dh2048.pem\n```\n\n　　一切就绪。在重启OpenVPN后，服务器端配置就完成了。\n\n```sh\nservice openvpn restart\n```\n\n# Unix的客户端配置\n\n　　假定我们有一台装有类Unix操作系统的设备，比如Ubuntu 15.04，并安装有OpenVPN。我们想要连接到前面建立的OpenVPN服务器。首先，我们需要为客户端生成密钥。为了生成该密钥，请转到服务器上的对应目录中：\n\n```sh\ncd /etc/openvpn/easy-rsa/2.0\n```\n\n　　加载环境变量\n\n```sh\nsource vars\n```\n\n　　然后创建客户端密钥\n\n```sh\n./build-key client\n```\n\n　　我们将看到一个与先前关于服务器密钥生成部分的章节描述一样的对话，填入客户端的实际信息。\n\n　　如果需要密码保护密钥，你需要运行另外一个命令，命令如下\n\n```sh\n./build-key-pass client\n```\n\n　　在此种情况下，在建立VPN连接时，会提示你输入密码。\n\n　　现在，我们需要将以下文件从服务器拷贝到客户端/etc/openvpn/keys/文件夹。\n\n　　服务器文件列表：\n\n- ca.crt,\n- dh2048.pem,\n- client.crt,\n- client.key,\n- ta.key.\n\n　　在此之后，我们转到客户端，准备配置文件。配置文件位于/etc/openvpn/client.conf，内容如下\n\n```sh\ndev tun\nproto udp\n\n# 远程 OpenVPN 服务器的 IP 和 端口号\nremote 111.222.333.444 1194\n\nresolv-retry infinite\n\nca /etc/openvpn/keys/ca.crt\ncert /etc/openvpn/keys/client.crt\nkey /etc/openvpn/keys/client.key\ntls-client\ntls-auth /etc/openvpn/keys/ta.key 1\nauth SHA1\ncipher BF-CBC\nremote-cert-tls server\ncomp-lzo\npersist-key\npersist-tun\n\nstatus openvpn-status.log\nlog /var/log/openvpn.log\nverb 3\nmute 20\n```\n\n　　在此之后，我们需要重启OpenVPN以接受新配置。\n\n```sh\nservice openvpn restart\n```\n\n　　好了，客户端配置完成。\n\n#安卓客户端配置\n\n　　安卓设备上的OpenVPN配置和Unix系统上的十分类似，我们需要一个含有配置文件、密钥和证书的包。文件列表如下：\n\n\n- 配置文件 (扩展名 .ovpn),\n- ca.crt,\n- dh2048.pem,\n- client.crt,\n- client.key.\n\n　　客户端密钥生成方式和先前章节所述的一样。\n\n　　配置文件内容如下\n\n```sh\nclient tls-client\ndev tun\nproto udp\n\n# 远程 OpenVPN 服务器的 IP 和 端口号\nremote 111.222.333.444 1194\n\nresolv-retry infinite\nnobind\nca ca.crt\ncert client.crt\nkey client.key\ndh dh2048.pem\npersist-tun\npersist-key\n\nverb 3\nmute 20\n```\n\n　　所有这些文件我们必须移动我们设备的SD卡上。\n\n　　然后，我们需要安装一个OpenVPN Connect 应用。\n\n　　接下来，配置过程很是简单：\n\n- 打开 OpenVPN 并选择“Import”选项\n- 选择“Import Profile from SD card”\n- 在打开的窗口中导航到我们放置好文件的目录，并选择那个 .ovpn 文件\n- 应用会要求我们创建一个新的配置文件\n- 点击“Connect”按钮并稍等一下\n\n　　搞定。现在，我们的安卓设备已经通过安全的VPN连接连接到我们的专用网。\n\n# 尾声\n\n　　虽然OpenVPN初始配置花费不少时间，但是简易的客户端配置为我们弥补了时间上的损失，也提供了从任何设备连接的能力。此外，OpenVPN提供了一个很高的安全等级，以及从不同地方连接的能力，包括位于NAT后面的客户端。因此，OpenVPN可以同时在家和企业中使用。\n","tags":["openvpn"],"categories":["service"]},{"title":"Ubuntu下OpenVPN客户端配置","url":"/2017/06/06/service/Ubuntu下OpenVPN客户端配置/","content":"\n# 安装OpenVPN\n\n　　首先需要安装OpenVPN客户端。一般来说直接使用apt-get即可。执行如下命令安装：\n\n```sh\n[root@www ~]# apt-get install openvpn\n```\n\n　　稍等片刻将自动安装好openvpn需要的软件包。安装完成后，应该出现 `/etc/openvpn/` 文件夹。 \n  \n<!-- more -->\n\n# 配置OpenVPN\n\n　　作为客户端，OpenVPN并没有特定的配置文件，而是由服务器提供方给出一个配置文件。对于认证，OpenVPN提供了两种认证方法：基于用户名/密码的认证与SSL证书认证。用户名/密码的认证方法无法（或较难）限制一个账号同时连接多个客户端，而采用证书，则可保证同一证书同一时间只能有一个 客户端连接。当然，这些都是由服务器端决定的，不需要客户端进行选择。\n\n　　首先将OpenVPN服务器提供商发给你的配置文件解压，并将所有文件都复制到 /etc/openvpn/中。\n\n这些文件中至少包含一个.ovpn文件，需要手动创建该文件，如：client.ovpn；如果服务器需要证书认证，则应该还存在另外三个证书文件。\n\n　　看懂OpenVPN配置格式。下面是一个.ovpn配置示例：\n\n```sh\nclient\ndev tap\nproto tcp-client\nremote 192.168.135.75 1194\nresolv-retry infinite\nnobind\nmute-replay-warnings\nredirect-gateway\nca /etc/openvpn/ca.crt\ncert /etc/openvpn/client.crt\nkey /etc/openvpn/client.key\ncomp-lzo\nverb 4\n```\n\n　　一般来说，ca.crt，client.crt，client.key可能需要你进行修改。将内容修改成这三个文件的实际位置。然后保存即可。 \n\n# 连接OpenVPN\n\n　　在配置好.ovpn文件后，执行\n\n```sh\nopenvpn /etc/openvpn/client.ovpn\n```\n　　即可连接服务器了（注意该目录下对应文件的权限）。注意，上面的参数应该换成你的配置文件实际位置。\n\n　　此时，终端会回显很多连接日志。如果连接不成功，则可以通过这些日志来确定出错位置。如果要断开，只需要通过Ctrl+C强制终止即可。\n\n　　上面的命令在实际中并不方便，因为它要占用一个独立的终端。在测试成功后，使用以下命令即可在后台连接OpenVPN：\n\n```sh\nopenvpn /etc/openvpn/client.ovpn > /dev/null &\n```\n\n　　值得称赞的是，openvpn非常智能，在连接异常中断、无法连接服务器、断网的情况下，它会自动重连。因此，如果希望开机即自动连接OpenVPN，或者是VPN常年在线，则可将上述命令行加入 `/etc/rc.local` 中。注意，命令末尾的&符号不能省略，否则将可能阻塞系统的正常启动。\n","tags":["openvpn"],"categories":["service"]},{"title":"kvm部署及虚拟机安装","url":"/2017/06/04/service/KVM部署及虚拟机安装/","content":"\n# 一. KVM安装\n\n## 1. 查看硬件是否支持虚拟化\n\n　　KVM需要CPU支持虚拟化，执行以下命令查看是否支持虚拟化：\n\n```sh\negrep '(vmx|svm)' --color=always /proc/cpuinfo\n```\n\n　　如果含有vmx或者svm字样，则表示支持CPU虚拟化，\n\n　　Intel是vmx，AMD是svm。\n\n<!-- more -->\n\n## 2. 安装KVM\n\n```sh\nyum install qemu-kvm qemu-img libvirt libvirt-python libguestfs-tools virt-install\n```\n\n　　**qemu-kvm** 是一个开源的虚拟机程序，为 KVM 虚拟机监视器提供硬件仿真，而 qemu-img 则提供了一个操纵磁盘镜像的命令行工具。\n\n　　**libvirt** 包含与操作系统的虚拟化功能交互的工具。\n\n　　**libvirt-python** 包含一个模块，它允许用 Python 写的应用来使用由 libvirt 提供的接口。\n\n　　**libguestfs-tools** 包含各式各样的针对虚拟机的系统管理员命令行工具。\n\n　　**virt-install** 包含针对虚拟机管理的其他命令行工具。\n\n\n### 2.1. 启动并开启了 libvirtd 服务\n\n```sh\n/etc/init.d/libvirtd start\n\nchkconfig libvirtd on\n```\n\n### 2.2. 配置转发\n\n　　文件/etc/sysctl.conf 中设置：\n\n```sh\nnet.ipv4.ip_forward = 1\n```\n\n### 2.3. 关闭网桥上的Netfilter(提高性能)\n\n```sh\nvim /etc/sysctl.conf:\n\n    net.bridge.bridge-nf-call-ip6tables = 0\n\n    net.bridge.bridge-nf-call-iptables = 0\n\n    net.bridge.bridge-nf-call-arptables = 0\n```\n\n### 2.4. 加载更改到当前的内核配置中：\n\n```sh\nsysctl -p\n```\n\n## 3. KVM网络配置\n\n### 3.1. 创建桥接器\n\n```sh\nvim /etc/sysconfig/network-scripts/ifcfg-br0\n\n    DEVICE=br0\n    NAME=br0\n    NM_CONTROLLED=no\n    TYPE=Bridge     # 注意Bridge大小写\n    ONBOOT=yes\n    BOOTPROTO=none\n    BROADCAST=192.168.2.255\n    IPADDR=192.168.2.7\n    NETMASK=255.255.255.0\n    NETWORK=192.168.2.0\n    GATEWAY=192.168.2.1\n```\n\n### 3.2. 将物理接口桥接到桥接器\n\n　　修改eth0的内容（本服务器是用eth0上网的），去掉其IP相关信息，加上“BRIDGE=br0”，将其桥接到br0上；如果是双网卡或是多网卡，照此过程修改：\n\n```sh\nvim /etc/sysconfig/network-scripts/ifcfg-eth0\n\n    DEVICE=eth0\n    NAME=eth0\n    TYPE=Ethernet\n    NM_CONTROLLED=no\n    ONBOOT=yes\n    BRIDGE=br0\n```\n\n### 3.3. 重启网络\n\n```sh\n/etc/init.d/network restart\n```\n\n# 二. 安装并配置VNC服务\n\n## 1. 安装VNC\n\n```sh\nyum install tigervnc tigervnc-server\n```\n\n## 2. 配置VNC\n\n```sh\nvim /etc/sysconfig/vncservers\n\n    VNCSERVERS=\"1:root\"\n    VNCSERVERARGS[2]=\"-geometry 800x600 -nolisten tcp -localhost\"\n```\n\n## 3.设置vnc密码\n\n```sh\nvncpasswd\n```\n\n## 4.启动服务\n\n```sh\n/etc/init.d/vncserver start\n\nchkconfig vncserver on\n```\n\n## 5. 配置QEMU\n\n```sh\nvim /etc/libvirt/qemu.conf\n\n    vnc_listen = \"0.0.0.0\"\n\n    vnc_password = \"xxxxx\"\n```\n\n## 6.重启服务\n\n```sh\n/etc/init.d/libvirtd restart\n```\n\n# 三. 创建虚拟机\n\n## 1. 创建centos虚拟机\n\n```sh\nvirt-install --network bridge=br0 --name=test_centos --ram=2048 --vcpus=2 --disk path=/var/lib/libvirt/images/test_centos.img,size=200 --cdrom /usr/local/src/CentOS-6.7-x86_64-minimal.iso --vnc --vncport=5910 --hvm\n```\n\n　　执行上面命令后通过VNC 连接安装系统\n\n## 2.创建windows虚拟机\n\n```sh\nvirt-install --network bridge=br0 --name=test_xp --ram=2048 --vcpus=2 --disk path=/var/lib/libvirt/images/test_xp.img,size=200 --cdrom /usr/local/src/Deepin-LiteXP-5.10.iso --vnc --vncport=5920 --os-type=Windows\n```\n　　执行上面命令后通过VNC 连接安装系统\n","tags":["kvm"],"categories":["service"]},{"title":"使用命令行生成高强度密码","url":"/2017/06/02/system/使用命令行生成高强度密码/","content":"\n设置一个高强度的密码是非常重要的，这样才能够很好的保护自己的账号或者服务器以及确保自己的数据的安全。通常来说，一个高强度密码至少有 14 个字符，包括大小写字母、数字和特殊字符，并且要牢记永远不用那些字典中的单词。使用长密码比短密码要来的安全，因为密码越长越难猜测。在本文中，我将给你介绍几个不同方法，让你可以在 Linux 命令行下生成一个高强度密码。\n\n<!-- more -->\n\n# 使用 openssl 生成高强度密码\n\n这里使用 openssl 的 rand 方法，它会生成一个 14 位字符的随机字符：\n\n    openssl rand -base64 14\n\n# 使用 urandom 生成高强度密码\n\n这里我们将使用 tr 条件来过滤 /dev/urandom 的输出，从而删掉那些不想要的字符，并打印出第一个出现的 14 位字符。\n\n    < /dev/urandom tr -dc A-Za-z0-9 | head -c14; echo\n\n# 使用 pwgen 生成高强度密码\n\npwgen 是一个生成随机、无特殊含义但可以正常拼读的密码。\n\n安装 pwgen，运行：\n\n    sudo apt-get install pwgen\n\n安装好之后，使用以下命令来生成一个 14 位随机字符：\n\n    pwgen 14 1\n\n你也可以使用以下标记：\n\n* -c 或 --capitalize 生成的密码中至少包含一个大写字母\n* -A 或 --no-capitalize 生成的密码中不含大写字母\n* -n 或 --numerals 生成的密码中至少包含一个数字\n* -0 或 --no-numerals 生成的密码中不含数字\n* -y 或 --symbols 生成的密码中至少包含一个特殊字符\n* -s 或 --secure 生成一个完全随机的密码\n* -B 或 --ambiguous 生成的密码中不含易混淆字符\n* -h 或 --help 输出帮助信息\n* -H 或 --sha1=path/to/file[#seed] 使用指定文件的 sha1 哈希值作为随机生成器\n* -C 按列输出生成的密码\n* -1 不按列输出生成的密码\n* -v 或 --no-vowels 不使用任何元音，以免意外生成让人讨厌的单词\n\n# 使用 gpg 生成高强度密码\n\n我们也可以使用 gpg 工具来生成一个 14 位字符的密码：\n\n    gpg --gen-random --armor 1 14\n\n# 其它方法\n\n当然，可能还有很多方法可以生成一个高强度密码。比方说，你可以添加以下 bash shell 方法到 ~/.bashrc 文件：\n\n```sh\ngenpasswd() { \n    strings /dev/urandom | grep -o '[[:alnum:]]' | head -n 14 | tr -d '\\n'; echo\n}\n```\n当你想要生成一个高强度的随机密码时，运行`genpasswd`就好了。\n","tags":["shell"],"categories":["system"]},{"title":"LINUX下解决netstat查看TIME_WAIT状态过多问题","url":"/2017/05/31/system/LINUX下解决netstat查看TIME-WAIT状态过多问题/","content":"\n\n```sh\n# netstat -an|awk '/tcp/ {print $6}'|sort|uniq -c\n     16 CLOSING\n    130 ESTABLISHED\n    298 FIN_WAIT1\n     13 FIN_WAIT2\n      9 LAST_ACK\n      7 LISTEN\n    103 SYN_RECV\n   5204 TIME_WAIT\n\n状态：描述\nCLOSED：无连接是活动的或正在进行\nLISTEN：服务器在等待进入呼叫\nSYN_RECV：一个连接请求已经到达，等待确认\nSYN_SENT：应用已经开始，打开一个连接\nESTABLISHED：正常数据传输状态\nFIN_WAIT1：应用说它已经完成\nFIN_WAIT2：另一边已同意释放\nITMED_WAIT：等待所有分组死掉\nCLOSING：两边同时尝试关闭\nTIME_WAIT：另一边已初始化一个释放\nLAST_ACK：等待所有分组死掉\n```\n\n<!-- more -->\n \n如发现系统存在大量TIME_WAIT状态的连接，通过调整内核参数解决，\n\n```sh\nvim /etc/sysctl.conf\n```\n\n编辑文件，加入以下内容：\n```sh\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_tw_recycle = 1\nnet.ipv4.tcp_fin_timeout = 30\n```\n\n然后执行 `/sbin/sysctl -p` 让参数生效。\n \nnet.ipv4.tcp_syncookies = 1 表示开启SYN cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；\n \nnet.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；\n \nnet.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。\n \nnet.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间\n \n下面附上TIME_WAIT状态的意义：\n \n客户端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口\n \n状态为TIME_WAIT\n \n是不是所有执行主动关闭的socket都会进入TIME_WAIT状态呢？\n \n有没有什么情况使主动关闭的socket直接进入CLOSED状态呢？\n \n主动关闭的一方在发送最后一个 ack 后就会进入 TIME_WAIT 状态 停留2MSL（max segment lifetime）时间这个是TCP/IP必不可少的，也就是“解决”不了的。\n \n也就是TCP/IP设计者本来是这么设计的\n \n主要有两个原因\n \n1。防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）\n \n2。可靠的关闭TCP连接\n \n在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。\n \nTIME_WAIT 并不会占用很大资源的，除非受到攻击。\n \n还有，如果一方 send 或 recv 超时，就会直接进入 CLOSED 状态\n","tags":["调优"],"categories":["system"]},{"title":"logrotate切割日志nginx和php配置","url":"/2017/05/31/service/logrotate切割日志nginx和php配置/","content":"\n\n# nginx配置\n\n```sh\n/gotwo_data/logs/nginx/2mm.cn/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 644 nginx nginx\n        sharedscripts\n        postrotate\n                [ -f /gotwo_data/logs/nginx/nginx.pid ] && kill -USR1 `cat /gotwo_data/logs/nginx/nginx.pid`\n        endscript\n}\n```\n\n<!-- more -->\n\n# php配置\n\n```sh\n/gotwo_data/logs/php/*.log {\n        daily\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 666 nobody nobody\n        sharedscripts\n        postrotate\n                [ -f /gotwo_data/Application/php/var/run/php-fpm.pid ] && kill -USR1 `cat /gotwo_data/Application/php/var/run/php-fpm.pid`\n        endscript\n}\n```\n","tags":["logrotate"],"categories":["service"]},{"title":"nginx常见问题","url":"/2017/05/31/service/nginx常见问题/","content":"\n# 1.错误日志：warn：an upstream response is buffered to a temporary file\n\n```sh\n解决办法：增加fastcgi_buffers 8 4K;     fastcgi_buffer_size 4K;\n```\n<!-- more -->\n\n# 2. a client request body is buffered to a temporary file\n\n```sh\n解决办法：增加client_max_body_size 2050m;     client_body_buffer_size 1024k;\n```\n\n## Nginx 的 buffer 机制：\n\n对于来自 FastCGI Server 的 Response，Nginx 将其缓冲到内存中，然后依次发送到客户端浏览器。缓冲区的大小由 fastcgi_buffers 和 fastcgi_buffer_size 两个值控制。\n\n比如如下配置：\n\n```sh\nfastcgi_buffers      8 4K;\nfastcgi_buffer_size  4K;\n```\n\nfastcgi_buffers 控制 nginx 最多创建 8 个大小为 4K 的缓冲区，而 fastcgi_buffer_size 则是处理 Response 时第一个缓冲区的大小，不包含在前者中。所以总计能创建的最大内存缓冲区大小是 8*4K+4K = 36k。而这些缓冲区是根据实际的 Response 大小动态生成的，并不是一次性创建的。比如一个 8K 的页面，Nginx 会创建 2*4K 共 2 个 buffers。\n\n当 Response 小于等于 36k 时，所有数据当然全部在内存中处理。如果 Response 大于 36k 呢？fastcgi_temp 的作用就在于此。多出来的数据会被临时写入到文件中，放在这个目录下面。同时你会在 error.log 中看到一条类似 warning：\n\n```\n2010/03/13 03:42:22 [warn] 3994#0: *1 an upstream response is buffered to a temporary file\n/usr/local/nginx/fastcgi_temp/1/00/0000000001 while reading upstream, \nclient: 192.168.1.111,\nserver: www.xxx.cn,\nrequest: \"POST /test.php HTTP/1.1\",\nupstream: \"fastcgi://127.0.0.1:9000\", \nhost: \"xxx.cn\",\nreferrer: \"http://xxx.cn/test.php\"\n```\n\n显然，缓冲区设置的太小的话，Nginx 会频繁读写硬盘，对性能有很大的影响，但也不是越大越好，没意义. \n","tags":["nginx"],"categories":["service"]},{"title":"恢复linux被误删文件","url":"/2017/05/30/system/恢复linux被误删文件/","content":"\n# 一、首先我们先来了解下文件删除原理：\n* 1）linux是通过link的数量来控制文件删除的，只有当一个文件不存在任何link的时候，这个文件才会被删除。一般来说，每个文件都有2个link计数器：i_count和i_nlink。\n* 2）当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。\n* 3）当你发现你误删除了文件后，要做的第一件事是马上卸载被误删除文件所在的分区，或者以只读的方式来挂载该分区。原因大家都很清楚，文件被删除后，文件中的数据还存在磁盘上，除非存放这些数据的数据块又被操作系统分配出去了。我们这一步就是尽量降低数据块中数据被覆盖的风险，以提高恢复数据成功的比率。\n\n<!-- more -->\n\n# 二、了解完后，实战演练\n\n---\n\n## 方案 1）现在我向大家介绍使用extundelete恢复文件（适合rhel6.X系统的ext4)\n\n### 1.编译安装extundelete-0.2.4\n\n```sh\ntar -jxvf  extundelete-0.2.4.tar.bz2\ncd extundelete-0.2.4\n./configure （这步出现错误，请看下文）\nmount /dev/cdrom /mnt\nrpm -ivh  /mnt/Packages/e2fsprogs-devel-1.41.12-18.el6.x86_64.rpm  （必须安装否则，前面./configure报错）\n./configure （成功）\nmake && make install\n```\n\n### 2.软件安装完毕，下面我们来恢复文件吧\n\n```sh\nmkdir recover\ncd recover\nextundelete  /dev/sda4 --inode  2  （看到你所删除的文件）\nextundelete  /dev/sda4 -restore-inode 15 （按对应的节点来恢复文件）\nextundelete  /dev/sda4 -restore-file  a.txt   （按对应文件名来恢复文件）\nextundelete  /dev/sda4 -restore-dirctory etc  （按对应的目录，这里我以etc目录）\nextundelete  /dev/sda4 -restore-all （全部恢复）\n```\n\n---\n\n## 方案2）使用lsof自带一个的神秘功能\n\n　　原理：大多数与 lsof 相关的信息都存储于以进程的 PID命名的目录中,假如由于误操作将/var/log/messages文件删除掉了，那么这时要将/var/log/messages文件恢复的方法如下：\n\n　　首先使用lsof来查看当前是否有进程打开/var/logmessages文件，如下：\n\n```sh\nlsof |grep /var/log/messages\n\nsyslogd 1283 root 2w REG 3,3 5381017 1773647 /var/log/messages (deleted)\n```\n\n　　从上面的信息可以看到 PID 1283（syslogd）打开文件的文件描述符为 2。同时还可以看到/var/log/messages已经标记被删除了。因此我们可以在 /proc/1283/fd/2 （fd下的每个以数字命名的文件表示进程对应的文件描述符）中查看相应的信息，如下：\n\n```sh\nhead -n 10 /proc/1283/fd/2\n\nAug 4 13:50:15 holmes86 syslogd 1.4.1: restart.\nAug 4 13:50:15 holmes86 kernel: klogd 1.4.1, log source = /proc/kmsg started.\nAug 4 13:50:15 holmes86 kernel: Linux version 2.6.22.1-8 (root@everestbuilder.linux-ren.org)\n(gcc version 4.2.0) #1 SMP Wed Jul 18 11:18:32 EDT 2007 Aug 4 13:50:15 holmes86 kernel:\nBIOS-provided physical RAM map: Aug 4 13:50:15 holmes86 kernel: BIOS-e820:\n0000000000000000 - 000000000009f000 (usable) Aug 4 13:50:15 holmes86 kernel: BIOS-e820:\n000000000009f000 - 00000000000a0000 (reserved) Aug 4 13:50:15 holmes86 kernel:\nBIOS-e820: 0000000000100000 - 000000001f7d3800 (usable) Aug 4 13:50:15 holmes86 kernel:\nBIOS-e820: 000000001f7d3800 - 0000000020000000 (reserved) Aug 4 13:50:15 holmes86\nkernel: BIOS-e820: 00000000e0000000 - 00000000f0007000 (reserved) Aug 4 13:50:15\nholmes86 kernel: BIOS-e820: 00000000f0008000 - 00000000f000c000 (reserved)\n```\n\n　　从上面的信息可以看出，查看 /proc/8663/fd/15 就可以得到所要恢复的数据。如果可以通过文件描述符查看相应的数据，那么就可以使用 I/O 重定向将其复制到文件中，如:cat /proc/1283/fd/2 > /var/log/messages对于许多应用程序，尤其是日志文件和数据库，这种恢复删除文件的方法非常有用。\n\n---\n\n## 方案3）使用ext3grep恢复文件（适合rhel5.X系统的ext3)\n\n### 1. 编译安装ext3grep-0.10.1\n\n```sh\ntar -jxvf  ext3grep-0.10.1.tar.gz\ncd ext3grep-0.10.1\n./configure\nmake && make install\n```\n\n### 2. 软件安装完毕，下面我们来恢复文件吧\n\n```sh\nmkdir recover\ncd recover\next3grep /dev/your-device --restore-filepath/to/your/file/filename\n```\n\n　　需要注意的是，上面的文件路径，是在该分区上文件路径。假设我们要恢复/dev/sda3分区上文件，这个分区原来的安装点是/home，现在想恢复文件/home/easwy/vi/tips.xml，那么输入的命令应该是：\n\n```sh\next3grep /dev/sda3--restore-file easwy/vi/tips.xml\n```\n\n　　所有恢复的文件都会放在当前目下在`RESTORED_FILES`目录下，大小也一样，这里`RESTORED_FILES`目录是执行ext3grep的当前目录下\n\n　　如果你忘记了文件名，或者你误删除的是一个目录而你无法记全该目录中的文件，你可以先用下面的命令查询一下文件名：\n\n```sh\next3grep /dev/sda3 --dump-names | tee filename.txt\n```\n\n　　上面的命令把ext3grep命令的输出记录到文件filename.txt中，你可以慢慢查看，或者使用grep命令过滤出你需要的信息。\n\n　　当你知道了目录/文件的信息后，就可以用上面说的命令进行恢复了。\n\n　　复所有文件和目录，但是目录的话，如果删除时间较长，不一定能完全恢复，压缩文件一般都能恢复\n\n```sh\next3grep /termite/cc-disk --restore-all\next3grep /dev/sda3  --ls --inode 2 创建扫描分区文件：sda5.ext3grep.stage1和sda5.ext3grep.stage2\n```\n\n　　如果想要重新生成可以删除这个两个文件，再次执行这条命令。另外当第一次执行ext3grep /dev/sda3 --restore-file test/a.txt进行还原时也会自动生成扫描分区文件。\n","tags":["数据恢复"],"categories":["system"]},{"title":"修改PHP上传文件大小限制","url":"/2017/05/30/service/修改PHP上传文件大小限制/","content":"\n# 一.配置php.ini文件 （以上传500M以下大小的文件为例）\n\n　　查找以下选项并修改:\n\n```sh\nfile_uploads = On ;打开文件上传选项\nupload_max_filesize = 500M ;上传文件上限\n```\n\n<!-- more -->\n\n　　如果要上传比较大的文件，仅仅以上两条还不够，必须把服务器缓存上限调大，把脚本最大执行时间变长\n\n```sh\npost_max_size = 500M ;post上限\nmax_execution_time = 1800 ; Maximum execution time of each script, in seconds脚本最大执行时间\nmax_input_time = 1800 ; Maximum amount of time each script may spend parsing request data\nmemory_limit = 128M ; Maximum amount of memory a script may consume (128MB)内存上限\n```\n\n# 二.修改nginx配置\n\n　　需要在对应的虚拟主机配置中修改　`client_max_body_size` 参数的值\n\n```sh\nclient_max_body_size 500m;\n```\n","tags":["php"],"categories":["service"]},{"title":"Windows与Linux共享文件夹互相访问","url":"/2017/05/29/service/ Windows与Linux共享文件夹互相访问 /","content":"\n# 首先安装并配置软件samba\n\n```sh\nsudo yum install samba samba-client  \nvim /etc/samba/smb.conf  \n      \n找到security这行并将#注释符号去掉改成  \nsecurity = share     #共享模式  \n      \n添加如下代码：  \n      \n[share]  \ncomment = share  \npath = /home/test          #设置共享文件夹目录  \nbrowseable = yes  \nguest ok = yes  \nwritable = yes  \n\nservice smb start  \nservice smbd start   (ubuntu)  \n```\n<!-- more -->\n\n## （1）在windows下访问Linux共享：\n\n直接在windows运行里输入\\\\192.168.16.128即可访问linux共享资源，并且不需要密码。\n\n## （2）在linux下访问windows共享：\n```sh\nsmbclient -L 192.168.16.1 -U xiaoxing   # 查看共享了那些目录，由此知道主机名为XIAOXING-PC\n\nsmbclient //192.168.16.1/Users -U xiaoxing     输入windows密码即可进入\n```\n\n直接挂载windows共享目录\n\n```sh\nsudo mount -t smbfs -o username=xiaoxing,password=123456   //XIAOXING-PC/system /mnt/win/\n或者：\nsudo mount -t smbfs -o username=xiaoxing,password=123456   //192.168.16.1/system /mnt/win/\n或者：\nsudo mount -t smbfs -o username=xiaoxing,password=123456,ip=192.168.16.1 //XIAOXING-PC/system /mnt/win/\n```\n\n注意：\n\n如果出现如下错误：\n\n```sh\nmount: unknown filesystem type ’smbfs’\n```\n说明系统已经不能识别smbfs文件系统了，查资料说RHE5的kernel已经不再支持smbfs，而改用Common Internet File Systemcifs(cifs)取代了原有的smbfs，所以命令就改为:\n\n```sh\nsudo mount -t cifs -o username=xiaoxing,password=123456   //192.168.16.1/system /mnt/win/\n```\n解开挂载\n\n断开刚才挂载在linux /mnt/win/路径上的winodws共享文件夹。\n```sh\nsudo umount /mnt/win/\n```\n","tags":["samba"],"categories":["service"]},{"title":"系统运维工程师装逼完全指南","url":"/2017/05/28/life/系统运维工程师装逼完全指南/","content":"\n\n\n1、全球化的认证有助于提升逼格，什么OCM、CCIE、RHCA、CISSP等等能考都考，再不济，也要有一张系统架构设计师或者网络规划设计师的信产部认证。每过一个认证，逼格提升一档。\n\n<!-- more -->\n\n2、TCP/IP协议、Linux内核深入研究、ORACLE大全等等之类的超过1千页大本头的书能有效提升B格，一定要放手边。不懂不要紧，别人能看见就行了。真有人跟你谈这些，也别担心装B失败，谈网络就从TCP的实现谈起，谈Linux就从内存的管理谈起，谈数据库就从各数据库SQL语句的源码实现谈起。如果有人跟你谈MS的东西也不要紧，就说自己之前有多年的微软的工作经历，外包的也算。反正也不会有查。有人非要跟你谈硬件，最次也要从计算机部件分类谈起吧。\n\n3、大众化的东西要少用。能用ATS，就别用squid；能用postgresql，就别用MySQL；坚信什么nginx、lighty这种webserver要比apache好一万倍，而且apache能实现的功能，这些都能实现，不行就自己写模块、写扩展。实在要用apache，也别用高版本，抱死1.3的系统。有人要是问起，就说这是基于1.3的版是自己深度二次开发版本。实在要找不到的话也不要紧，没事在sf、oschina上看看什么下载量少的项目，背背项目简介啥的。不得不说，这两个网站太贴心，分类都给你做好了。总之，小众的东西能很有效的提升你的装逼级别。\n\n4、写脚本的话，别用grep、sort 、uniq、管道这类命令。使用纯粹的awk、sed的实现，长度不要紧，阅读性、性能也不是问题。功能实现了，别人都还不懂这就是关键。如果真有人来请教，也要装出一副很简单的表情。切记不要摇头尾巴晃。就算是你是从《sed和awk》这种书上抄你自己也不一定能看懂的代码。\n\n5、虽然会shell，但也要少用shell。初级装逼者，系统管理会首选perl、python、php这类3p的工具，而且要对shell这种语言有一种不屑。把什么性能、移植性、面向对象要常挂嘴边。如果还能再写几行什么erlang、ruby、lua这类语言做系统管理，绝对是装B神器，也是中级装逼的标准。高级装逼者会有Haskell这类函数式语言进行系统管理，这绝对是装B的B2轰炸机呀。当然，资深装逼者会返璞归真，使用面向对象进行shell编程。对，你没看错，是使用OO进行shell编程。\n\n6、当谈到Redhat、ubuntu这类大众发行版本时，就回复一个字“切！”LFS、Gentoo这类系统绝对是装逼的首选。不为什么，就为在无穷尽的编译中找到属于自己的快感。如果非装大众发行版，也要从开机画面、登陆提示等等地方打自己上深刻的烙印。装逼的寂寞岂是一般人能懂的。\n\n7、对什么checkpoint，juniper等表示不屑。必须天天把iptabes的链和表都挂在嘴边，尤其是mangle表。原则上对商用产品的一律不屑一顾，什么f5，radware一律自己开发实现。至于意外的将自己关在外面的事情一定要严格遵守各自公司的保密协议。\n\n8、对于操作终端呢，像SecureCRT、xshell这种绝对是不用的，一定要用最原始的，什么黑屏绿字只是初级装逼者的水平，中高级则是Alpha半透明终端，桌面背景在设置个全球internet流量趋势图。让你根本就不知道他天天对着屏幕在敲什么东西。有事没事编译一些大型软件，看着翻滚的屏幕做思考状。\n\n9、名片的title一定要是系统架构师，没有名片也不要紧，什么QQ签名、人人状态、微博简介上，有人看的地方一定要写上。这些都是提升B格的好地方。\n\n10、初级装逼谈流量、PV、自动化；中级装逼谈流程、谈规范，什么ITIL、ITSM要常挂嘴边；高级装逼谈架构、谈模式；资深装逼则谈合同、谈成本。\n\n11、混圈子对装逼来非常有必要的。什么XX沙龙、XX架构师大会、XX优化大会之类必要是常客，露个B脸就行。基本原则就是跟搞系统谈网络，跟搞网络的谈数据库，跟搞数据库的谈安全……对方不懂什么就谈什么对就了\n\n12、最后，骨灰级早就超出三界外，不在五行中，他们注定有着传奇的色彩。他们正忙于对装逼者们进行职业发展规划。装逼助理、初级装逼、高级装逼、资深装逼、装逼总监直至CBO。如果发展了到了CBO，那么你一定是一位惊天地、泣鬼神的一代B神，一统江湖的教主，供万千iBer敬仰。darling，我很看好你哟！","tags":["职业"],"categories":["life"]},{"title":"运维人装逼指南大全","url":"/2017/05/28/life/运维人装逼指南大全/","content":"\n\n曾经有一首诗是这么写的\n\n> 装逼，是一种态度??\n\n> 装逼的人生不可限量\n\n> 装逼如煲汤\n\n> 遇到烹制的高手，逼格立马飙升\n\n<!-- more -->\n\n装逼，已被业界大神誉为当代职场人的基本素养\n\n可是\n\n网上流传的装逼指南一大把\n\n唯独缺少咱运维人的这一发\n\n今天线哥就帮大家来扒一扒\n\n咱们一起把这装逼宝典传承下\n\n\n　　话说，运维人拥有天然装逼优势，面对无数迭代升级的软硬件，数都数不过来的各类技术，互联网、云计算、大数据的热潮，跑断腿的各类行业大会……这些都为我们营造了极好的客观条件。\n\n　　可以说，在全民都看你的时代，你不装逼，不仅浪费了你这一身好手段，而且辜负了天恩浩荡呀！\n\n　　线哥虽是运营人，但长期浸淫在运维大咖身边，韬光养晦，苦练内功，总结了历来大神的装逼心得，并且通过实战检验，可谓天下无双，故取名曰《装逼宝典》，以补《葵花宝典》千年缺配。\n\n　　现在很多运维人逼格不高，主要是因其来路不正，“小米+步枪”的时代远去，来路不正永远低人一等。所以一张权威的架构师认证就显得无比重要了，国内比较权威的系统架构设计师或者网络规划设计师的认证要考，国际的什么OCM、CCIE、RHCA、CISSP等等更要考，有了这些证件决定你在哪一个层次装逼，当然了，逼格的飙升也有赖于部分努力。\n\n　　你会发现一些资深装逼手边永远摆着几本大部头的书，看着都瘆人。何谓大部头，什么？几百页的书你也好意思提，至少得上千页，才配称得上大部头。像什么TCP/IP协议、Linux内核研究、ORACLE大全等等。书一定要摆在显眼位置，你不用担心万一有人问起装逼遭遇滑铁卢。如果有人问硬件，你可以从计算机硬件基础谈起，有人问MS的内容，你那几年微软外包工作经历正好派上用场，现在数据库比较热，你可以从SQL语句的源码开聊，网络就谈TCP，Linux就谈内存管理。聊着聊着，你自己都被自己感动了，征服了。\n\n# 跟菜鸟划开界限\n\n　　菜鸟在管理系统上经常选用perl、python、php这些3p工具，你要避开这些工具，另外shell也要少用，当菜鸟问起，你要表现出不屑来。如果做系统管理你要会写几行erlang、ruby、lua这类语言，如果你胆儿够大，可以整一整Haskell这类函数式语言。我敢说，懂一点这个，你绝对把逼装大了。\n\n# 避开大众化路线\n\n　　当别人问你用squid吗？你说你用ATS；当别人问你用MySQL吗？你说你用postgresql；当别人为你用apache吗？你说你用nginx、lighty。如果你发现当别人也在学习这些技术了，你就到sf、oschina网站上看看那些下载量小的项目，多背背项目简介，当他们在你面前炫耀新技术时，你跟他们聊一聊这些项目，这时你发现他们只剩下长大了的嘴。你要记住，越小众的东西越显得高逼格，小众意味着高端，这是历史反复验证的。\n\n# 为自己代言\n\n　　不装逼的人永远不懂装逼人的寂寞，装逼到极致是高冷的，曲高和寡。比如当大家还在谈Redhat、ubuntu这类大众发行版本时，你总是有意无意间避开，别人问你看法的时候，你对此不置一词，反而大谈特谈LFS、Gentoo。因为大众的东西是别人的，扒到属于自己的东西才显得更有张力，会带来不一样的快感呦。\n\n　　很多人写脚本都爱用grep、sort 、uniq这类命令，这类命令的功能比较复杂，而你术业有专攻，使用最纯粹的awk、sed来实现，最关键的是当你用它们实现某些功能，别人都看不懂。别人不懂就会问，而这时你却表现出一副轻描淡写的表情。而这些对于他们来说，就算抄书也不一定真能看懂。\n\n# 设置屏幕放大招\n\n　　操作终端一定要大肆显摆，那种黑屏绿字好莱坞大片式简直弱爆了，你用的是什么，是Alpha半透明终端，最好在桌面设置一个全球internet流量走势图，偶尔对着翻滚的屏幕做深入思考状，谁也不知道你在琢磨什么惊天地泣鬼神的东西。\n\n# 处处留情\n\n　　软硬件都解决了，这时候作为运维人的装逼基础已经够完美了，可是距离互联网大神级别还有距离。这时候你要抓住一切手段营销自己。不要让“网管”这个词在你耳朵边出现，你要时刻在明面暗面提示别人，我是架构师或规划师，把所有能展示自己title的地方都写上，什么名片啊、微信啊、QQ签名、脉脉、拉勾网等等，当然如果你愿意加上”首都在线“的前缀，可能效果会出奇不意。\n\n# 混精英圈子\n\n　　混圈子对于装逼是极为重要的。现在各种大会很多，鱼龙混杂，像什么GMIC、ChinaJoy之类的大会很难找到自己定位，而一般的XX架构师大会、XX优化大会、XX沙龙最多混个脸熟就好了。主要瞄准几个特定场合可获得四两拨千斤的效果，比如什么青年计算机学会论坛，统计之都论坛，以及蝴蝶沙龙，尤其蝴蝶沙龙是一个比较纯粹的架构师聚会，多去混这种场子，争取能演讲，那么你在这个圈子就很接近大神级人物了。\n\n# 精通云计算\n\n　　一般而言，骨灰级的大神被当作信仰一样崇拜，这些人物大都具有传奇色彩，据线哥多年观察，这些人物的思考域比较广，他思考问题具有生态图谱效应，比如做架构师，你一定要多思考云计算，了解SAAS，熟悉PAAS，精通IAAS。尤其关注当前IAAS战略趋势以及差异化发展。当前的经济趋势是企业出海，不管是电商、游戏还是视频企业，都在向海外拓展业务，在倡导全球云计算布局领域中，国内首要关注首都在线，因为这是首家全球一体化云计算服务商，拥有全球私网GPN，通过它能够高效稳定安全连接世界。\n\n　　最后不得不说，装逼是个系统工程，从装逼助理、装逼专员、高级装逼、资深装逼、装逼总监直至CBO。取经之路漫长，你在哪个层级不重要，重要的是，装逼精神不弃，奋斗之路不止。送给万千参透“人生如戏”的职场运维人士们！","tags":["职业"],"categories":["life"]},{"title":"tc命令——Linux基于IP进行流量限速","url":"/2017/05/28/service/tc命令Linux基于IP进行流量限速/","content":"\n# 一、TC原理\n\n　　Linux操作系统中的流量控制器TC（Traffic Control）用于Linux内核的流量控制，主要是通过在输出端口处建立一个队列来实现流量控制。\n\n<!-- more -->\n\n　　接收包从输入接口进来后，经过流量限制丢弃不符合规定的数据包，由输入多路分配器进行判断选择：\n\n* 如果接收包的目的主机是本主机，那么将该包送给上层处理，否则需要进行转发，将接收包交到转发块（Forwarding Block）处理。\n* 转发块同时也接收本主机上层(TCP、UDP等)产生的包，通过查看路由表，决定所处理包的下一跳。\n* 然后，对包进行排列以便将它们送到输出接口。\n\n　　一般只能限制网卡发送的数据包，不能限制网卡接收的数据包，所以可以通过改变发送次序靠控制传输速率。Linux流量控制主要是在输出接口排列时进行处理和实现的。\n\n# 二、TC规则\n\n## 2.1、流量控制方式\n\n　　流量控制包括以下几种方式：\n\n* SHAPING(限制) \n\n　　当流量被限制，它的传输速率就被控制在某个值以下。限制值可以大大小于有效带宽，这样可以平滑突发数据流量，使网络更为稳定。shaping（限制）只适用于向外的流量。\n\n* SCHEDULING(调度)      \n\n　　通过调度数据包的传输，可以在带宽范围内，按照优先级分配带宽。SCHEDULING(调度)也只适于向外的流量。\n\n* POLICING(策略)      \n\n　　SHAPING用于处理向外的流量，而POLICIING(策略)用于处理接收到的数据。\n\n* DROPPING(丢弃)      \n\n　　如果流量超过某个设定的带宽，就丢弃数据包，不管是向内还是向外。\n\n## 2.2、流量控制处理对象\n\n　　流量的处理由三种对象控制，它们是：\n\n* qdisc(排队规则)\n* class(类别)\n* filter(过滤器)\n\n###  QDISC(排队规则)\n\n　　QDisc(排队规则)是queueing discipline的简写，它是理解流量控制(traffic control)的基础。**无论何时，内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的qdisc(排队规则)把数据包加入队列。** 然后，内核会尽可能多地从qdisc里面取出数据包，把它们交给网络适配器驱动模块。最简单的QDisc是pfifo它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。不过，它会保存网络接口一时无法处理的数据包。\n\n　　QDISC的类别如下：\n\n#### （1）、CLASSLESS QDisc(不可分类QDisc)\n\n##### 1. 无类别QDISC包括：\n\n　　**[p|b]fifo**\n\n　　使用最简单的qdisc，纯粹的先进先出。只有一个参数：limit，用来设置队列的长度,pfifo是以数据包的个数为单位；bfifo是以字节数为单位。\n\n　　**pfifo_fast**\n\n　　在编译内核时，如果打开了高级路由器(Advanced Router)编译选项，pfifo_fast就是系统的标准QDISC。它的队列包括三个波段(band)。在每个波段里面，使用先进先出规则。而三个波段(band)的优先级也不相同，band 0的优先级最高，band 2的最低。如果band里面有数据包，系统就不会处理band 1里面的数据包，band 1和band 2之间也是一样。数据包是按照服务类型(Type of Service,TOS)被分配多三个波段(band)里面的。\n\n　　**red**\n\n　　red是Random Early Detection(随机早期探测)的简写。如果使用这种QDISC，当带宽的占用接近于规定的带宽时，系统会随机地丢弃一些数据包。它非常适合高带宽应用。\n\n　　**sfq**\n\n　　sfq是Stochastic Fairness Queueing的简写。它按照会话(session--对应于每个TCP连接或者UDP流)为流量进行排序，然后循环发送每个会话的数据包。\n\n　　**tbf**\n\n　　tbf是Token Bucket Filter的简写，适合于把流速降低到某个值。\n\n##### 2. 不可分类QDisc的配置\n\n　　如果没有可分类QDisc，不可分类QDisc只能附属于设备的根。它们的用法如下：\n\n```sh\ntc qdisc add dev DEV root QDISC QDISC-PARAMETERS\n```\n\n　　要删除一个不可分类QDisc，需要使用如下命令：\n\n```sh\ntc qdisc del dev DEV root\n```\n\n　　一个网络接口上如果没有设置QDisc，pfifo_fast就作为缺省的QDisc。\n\n#### （2）、CLASSFUL QDISC(分类QDisc)\n\n##### 可分类的QDisc包括：\n\n　　**CBQ**\n\n　　CBQ是Class Based Queueing(基于类别排队)的缩写。它实现了一个丰富的连接共享类别结构，既有限制(shaping)带宽的能力，也具有带宽优先级管理的能力。带宽限制是通过计算连接的空闲时间完成的。空闲时间的计算标准是数据包离队事件的频率和下层连接(数据链路层)的带宽。\n\n　　**HTB**\n\n　　HTB是Hierarchy Token Bucket的缩写。通过在实践基础上的改进，它实现了一个丰富的连接共享类别体系。使用HTB可以很容易地保证每个类别的带宽，虽然它也允许特定的类可以突破带宽上限，占用别的类的带宽。HTB可以通过TBF(Token Bucket Filter)实现带宽限制，也能够划分类别的优先级。\n\n　　**PRIO**\n\n　　PRIO QDisc不能限制带宽，因为属于不同类别的数据包是顺序离队的。使用PRIO QDisc可以很容易对流量进行优先级管理，只有属于高优先级类别的数据包全部发送完毕，才会发送属于低优先级类别的数据包。为了方便管理，需要使用iptables或者ipchains处理数据包的服务类型(Type Of Service,ToS)。\n\n### CLASS(类)       \n\n　　某些QDisc(排队规则)可以包含一些类别，不同的类别中可以包含更深入的QDisc(排队规则)，通过这些细分的QDisc还可以为进入的队列的数据包排队。通过设置各种类别数据包的离队次序，QDisc可以为设置网络数据流量的优先级。\n\n### FILTER(过滤器)      \n\n　　Filter(过滤器)用于为数据包分类，决定它们按照何种QDisc进入队列。无论何时数据包进入一个划分子类的类别中，都需要进行分类。分类的方法可以有多种，使用fileter(过滤器)就是其中之一。使用filter(过滤器)分类时，内核会调用附属于这个类(class)的所有过滤器，直到返回一个判决。如果没有判决返回，就作进一步的处理，而处理方式和QDISC有关。需要注意的是，filter(过滤器)是在QDisc内部，它们不能作为主体。\n\n## 2.3、操作原理\n\n　　类(Class)组成一个树，每个类都只有一个父类，而一个类可以有多个子类。某些QDisc(例如：CBQ和HTB)允许在运行时动态添加类，而其它的QDisc(例如：PRIO)不允许动态建立类。允许动态添加类的QDisc可以有零个或者多个子类，由它们为数据包排队。此外，每个类都有一个叶子QDisc，默认情况下，这个叶子QDisc使用pfifo的方式排队，我们也可以使用其它类型的QDisc代替这个默认的QDisc。而且，这个叶子叶子QDisc有可以分类，不过每个子类只能有一个叶子QDisc。 当一个数据包进入一个分类QDisc，它会被归入某个子类。\n\n　　我们可以使用以下三种方式为数据包归类，不过不是所有的QDisc都能够使用这三种方式：\n\n* tc过滤器(tc filter)\n\n　　如果过滤器附属于一个类，相关的指令就会对它们进行查询。过滤器能够匹配数据包头所有的域，也可以匹配由ipchains或者iptables做的标记。\n\n* 服务类型(Type of Service)\n\n　　某些QDisc有基于服务类型（Type of Service,ToS）的内置的规则为数据包分类。\n\n* skb->priority\n\n　　用户空间的应用程序可以使用SO_PRIORITY选项在skb->priority域设置一个类的ID。\n\n　　树的每个节点都可以有自己的过滤器，但是高层的过滤器也可以直接用于其子类。\n\n　　如果数据包没有被成功归类，就会被排到这个类的叶子QDisc的队中。相关细节在各个QDisc的手册页中。\n\n## 2.4、命名规则\n\n　　所有的QDisc、类和过滤器都有ID。ID可以手工设置，也可以有内核自动分配。ID由一个主序列号和一个从序列号组成，两个数字用一个冒号分开。\n\n　　**QDISC**\n\n　　一个QDisc会被分配一个主序列号，叫做句柄(handle)，然后把从序列号作为类的命名空间。句柄采用象10:一样的表达方式。习惯上，需要为有子类的QDisc显式地分配一个句柄。\n\n　　**类(CLASS)**\n\n　　在同一个QDisc里面的类分享这个QDisc的主序列号，但是每个类都有自己的从序列号，叫做类识别符(classid)。类识别符只与父QDisc有关，和父类无关。类的命名习惯和QDisc的相同。\n\n　　**过滤器(FILTER)**\n\n　　过滤器的ID有三部分，只有在对过滤器进行散列组织才会用到。详情请参考tc-filters手册页。\n\n## 2.5、单位\n\n　　tc命令的所有参数都可以使用浮点数，可能会涉及到以下计数单位。\n\n|带宽或者流速单位：\n|--------------------------------------------|\n|kbps                           |千字节/秒   |\n|mbps                           |兆字节/秒   |\n|kbit                           |KBits/秒    |\n|mbit                           |MBits/秒    |\n|bps或者一个无单位数字          |字节数/秒   |\n\n\n|数据的数量单位：\n|-------------------------------------|\n|kb或者k                        |千字节    |\n|mb或者m                        |兆字节    |\n|mbit                           |兆bit     |\n|kbit                           |千bit     |\n|b或者一个无单位数字            |字节数    |\n\n\n|时间的计量单位：\n|-------------------------------------------|\n|s、sec或者secs                    |秒    |\n|ms、msec或者msecs                 |分钟   |\n|us、usec、usecs或者一个无单位数字 |微秒  |\n\n\n# 三、TC命令\n\n　　tc可以使用以下命令对QDisc、类和过滤器进行操作：\n\n* add\n\n　　在一个节点里加入一个QDisc、类或者过滤器。添加时，需要传递一个祖先作为参数，传递参数时既可以使用ID也可以直接传递设备的根。如果要建立一个QDisc或者过滤器，可以使用句柄(handle)来命名；如果要建立一个类，可以使用类识别符(classid)来命名。\n\n* remove\n\n　　删除有某个句柄(handle)指定的QDisc，根QDisc(root)也可以删除。被删除QDisc上的所有子类以及附属于各个类的过滤器都会被自动删除。\n\n\n* change\n\n　　以替代的方式修改某些条目。除了句柄(handle)和祖先不能修改以外，change命令的语法和add命令相同。换句话说，change命令不能一定节点的位置。\n\n* replace\n\n　　对一个现有节点进行近于原子操作的删除/添加。如果节点不存在，这个命令就会建立节点。\n\n* link\n\n　　只适用于DQisc，替代一个现有的节点。\n\n\n# 四、具体操作\n\n　　Linux流量控制主要分为建立队列、建立分类和建立过滤器三个方面。\n\n## 4.1、基本实现步骤为：\n\n* （1） 针对网络物理设备（如以太网卡eth0）绑定一个队列QDisc；\n* （2） 在该队列上建立分类class；\n* （3） 为每一分类建立一个基于路由的过滤器filter；\n* （4） 最后与过滤器相配合，建立特定的路由表。\n\n## 4.2、环境模拟实例:\n\n　　流量控制器上的以太网卡(eth0) 的IP地址为192.168.1.66，在其上建立一个CBQ队列。假设包的平均大小为1000字节，包间隔发送单元的大小为8字节，可接收冲突的发送最长包数目为20字节。\n\n　　假如有三种类型的流量需要控制: \n\n1. 是发往主机1的，其IP地址为192.168.1.24。其流量带宽控制在8Mbit，优先级为2；\n2. 是发往主机2的，其IP地址为192.168.1.30。其流量带宽控制在1Mbit，优先级为1；\n3. 是发往子网1的，其子网号为192.168.1.0，子网掩码为255.255.255.0。流量带宽控制在1Mbit，优先级为6。\n\n\n### 1. 建立队列\n\n　　一般情况下，针对一个网卡只需建立一个队列。\n\n　　将一个cbq队列绑定到网络物理设备eth0上，其编号为1:0；网络物理设备eth0的实际带宽为10 Mbit，包的平均大小为1000字节；包间隔发送单元的大小为8字节，最小传输包大小为64字节。\n\n```sh\ntc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit avpkt 1000 cell 8 mpu 64\n```\n\n### 2. 建立分类\n\n　　分类建立在队列之上。\n\n　　一般情况下，针对一个队列需建立一个根分类，然后再在其上建立子分类。对于分类，按其分类的编号顺序起作用，编号小的优先；一旦符合某个分类匹配规则，通过该分类发送数据包，则其后的分类不再起作用。\n\n　　**1） 创建根分类1:1；分配带宽为10Mbit，优先级别为8。**\n\n```sh\ntc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate 10Mbit maxburst 20 allot 1514 prio 8 avpkt 1000 cell 8 weight 1Mbit\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为10Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为8，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为1Mbit。\n\n　　**2）创建分类1:2，其父分类为1:1，分配带宽为8Mbit，优先级别为2。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 8Mbit maxburst 20 allot 1514 prio 2 avpkt 1000 cell 8 weight 800Kbit split 1:0 bounded\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为 8Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为1，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为800Kbit，分类的分离点为1:0，且不可借用未使用带宽。\n\n　　**3）创建分类1:3，其父分类为1:1，分配带宽为1Mbit，优先级别为1。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 1 avpkt 1000 cell 8 weight 100Kbit split 1:0\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为 1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为2，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n　　**4）创建分类1:4，其父分类为1:1，分配带宽为1Mbit，优先级别为6。**\n\n```sh\ntc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 6 avpkt 1000 cell 8 weight 100Kbit split 1:0\n```\n\n　　该队列的最大可用带宽为10Mbit，实际分配的带宽为1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为6，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n## 4.3. 建立过滤器 \n\n　　过滤器主要服务于分类。\n\n一般只需针对根分类提供一个过滤器，然后为每个子分类提供路由映射。\n\n**1） 应用路由分类器到cbq队列的根，父分类编号为1:0；过滤协议为ip，优先级别为100，过滤器为基于路由表。**\n\n```sh\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route\n```\n\n**2） 建立路由映射分类1:2, 1:3, 1:4**\n\n```sh\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 2 flowid 1:2\n\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 3 flowid 1:3\n\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 4 flowid 1:4\n```\n\n## 4.4.建立路由\n\n　　该路由是与前面所建立的路由映射一一对应。\n\n　　**1） 发往主机192.168.1.24的数据包通过分类2转发(分类2的速率8Mbit)**\n\n```sh\nip route add 192.168.1.24 dev eth0 via 192.168.1.66 realm 2\n```\n　　**2） 发往主机192.168.1.30的数据包通过分类3转发(分类3的速率1Mbit)**\n\n```sh\nip route add 192.168.1.30 dev eth0 via 192.168.1.66 realm 3\n```\n　　**3）发往子网192.168.1.0/24的数据包通过分类4转发(分类4的速率1Mbit)**\n\n```sh\nip route add 192.168.1.0/24 dev eth0 via 192.168.1.66 realm 4\n```\n\n　　**注**：一般对于流量控制器所直接连接的网段建议使用IP主机地址流量控制限制，不要使用子网流量控制限制。如一定需要对直连子网使用子网流量控制限制，则在建立该子网的路由映射前，需将原先由系统建立的路由删除，才可完成相应步骤。\n\n## 4.5. 监视\n\n　　主要包括对现有队列、分类、过滤器和路由的状况进行监视。\n\n　　**1）显示队列的状况**\n\n　　简单显示指定设备(这里为eth0)的队列状况\n\n```\ntc qdisc ls dev eth0\n\nqdisc cbq 1: rate 10Mbit (bounded,isolated) prio no-transmit\n```\n　　详细显示指定设备(这里为eth0)的队列状况\n\n```\ntc -s qdisc ls dev eth0\n```\n\n　　这里主要显示了通过该队列发送了13232个数据包，数据流量为7646731个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n　　**2）显示分类的状况**\n\n　　简单显示指定设备(这里为eth0)的分类状况\n\n```\ntc class ls dev eth0\n```\n\n　　详细显示指定设备(这里为eth0)的分类状况\n\n```\ntc -s class ls dev eth0\n```\n\n　　这里主要显示了通过不同分类发送的数据包，数据流量，丢弃的包数目，超过速率限制的包数目等等。其中根分类(class cbq 1:0)的状况应与队列的状况类似。\n\n　　例如，分类class cbq 1:4发送了8076个数据包，数据流量为5552879个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n　　**3）显示过滤器的状况**\n\n```\ntc -s filter ls dev eth0\n```\n　　这里flowid 1:2代表分类class cbq 1:2，to 2代表通过路由2发送。\n\n　　**4）显示现有路由的状况**\n\n```\nip route\n```\n\n　　如上所示，结尾包含有realm的显示行是起作用的路由过滤器。\n\n\n# 五、实例脚本\n\n## 5.1 tc限速\n\n```sh\n#! /bin/sh\n\ntouch  /var/lock/subsys/local\n\necho  1  > /proc/sys/net/ipv4/ip_forward （激活转发）\n\nroute add default  gw  10.0.0.0  (这是加入电信网关，如果你已设了不用这条）\n\nDOWNLOAD=640Kbit        (640/8 =80K ,我这里限制下载最高速度只能80K）\nUPLOAD=640Kbit          (640/8 =80K,上传速度也限制在80K）\nINET=192.168.0.         (设置网段，根据你的情况填）\nIPS=1                   (这个意思是从192.168.0.1开始）\nIPE=200                 (我这设置是从IP为192.168.0.1-200这个网段限速，根据自已的需要改）\nServerIP=253            (网关IP）\nIDEV=eth0\nODEV=eth1\n\n/sbin/tc  qdisc  del  dev  $IDEV root handle 10:\n/sbin/tc  qdisc  del  dev  $ODEV  root handle  20:\n/sbin/tc  qdisc  add  dev $IDEV  root  handle  10: cbq  bandwidth  100Mbit avpkt  1000\n/sbin/tc  qdisc  add  dev  $ODEV  root  handle  20: cbq bandwidth  1Mbit  avpkt  1000\n/sbin/tc  class  add  dev $IDEV  parent 10:0  classid  10:1  cbq  bandwidth  100Mbit  rate 100Mbit  allot 1514  weight  1Mbit  prio  8  maxburst  20  avpkt  1000\n/sbin/tc  class  add  dev  $ODEV  parent  20:0  classid  20:1 cbq  bandwidth  1Mbit  rate  1Mbit  allot  1514  weitht  10Kbit  prio  8  maxburst  20  avpkt  1000\n\nCOUNTER=$IPS\nwhile  [  $COUNTER  -le  $IPE  ]\n    do\n/sbin/tc  class  add  dev  $IDEV  parent  10:1  classid  10:1$COUNTER  cbq  banwidth  100Mbit  rate  \n$DOWNLOAD  allot  1514  weight  20Kbit  prio  5  maxburst  20  avpkt  1000  bounded\n/sbin/tc  qdisc  add  dev  $IDEV  parent  10:1$COUNTER  sfq  quantum  1514b  perturb15\n\n/sbin/tc  filter  add  dev  $IDEV  parent  10:0  protocol  ip  prio  100  u32  match  ipdst  $INET$COUNTER  flowid  10:1$COUNTER\n      COUNTER=` expr  $COUNTER  +  1  `\ndone\n\niptables  -t  nat  -A  POSTROUTING  -o  eth1  -s  192.168.0.0/24  -J  MASQUERADE\n```\n\n## 5.2 模型\n\n```sh   \n#!/bin/sh\ntc qdisc del dev eth7 root &> /dev/null\ntc qdisc del dev eth8 root &> /dev/null\n\n#Add qdisc\ntc qdisc add dev eth7 root handle 10: htb default 9998\ntc qdisc add dev eth8 root handle 10: htb default 9998\n\n#Add htb root node\ntc class add dev eth7 parent 10: classid 10:9999 htb rate 1000000kbit ceil 1000000kbit\ntc class add dev eth8 parent 10: classid 10:9999 htb rate 1000000kbit ceil 1000000kbit\n\n#Add htb fake default node here\ntc class add dev eth7 parent 10:9999 classid 10:9998 htb rate 1000000kbit ceil 1000000kbit\ntc class add dev eth8 parent 10:9999 classid 10:9998 htb rate 1000000kbit ceil 1000000kbit\n\n#Add rule node\ntc class add dev eth7 parent 10:9999 classid 10:3 htb rate 1kbit ceil 50kbit\ntc filter add dev eth7 parent 10: protocol ip handle 3 fw classid 10:3\ntc class add dev eth8 parent 10:9999 classid 10:3 htb rate 1kbit ceil 50kbit\ntc filter add dev eth8 parent 10: protocol ip handle 3 fw classid 10:3\n\n#Add htb real default node here\ntc class change dev eth7 classid 10:9998 htb rate 1kbit ceil 1000000kbit\ntc class change dev eth8 classid 10:9998 htb rate 1kbit ceil 1000000kbit\n```\n\n## 5.3 限制一个IP上传下载速度\n\n```sh\n#!/bin/bash\n#\n#  tc uses the following units when passed as a parameter.\n#  kbps: Kilobytes per second\n#  mbps: Megabytes per second\n#  kbit: Kilobits per second\n#  mbit: Megabits per second\n#  bps: Bytes per second\n#       Amounts of data can be specified in:\n#       kb or k: Kilobytes\n#       mb or m: Megabytes\n#       mbit: Megabits\n#       kbit: Kilobits\n#  To get the byte figure from bits, divide the number by 8 bit\n#\n\n#\n# Name of the traffic control command.\nTC=/sbin/tc\n\n# The network interface we're planning on limiting bandwidth.\nIF=em1             # Interface\n\n# Download limit (in mega bits)\nDNLD=80mbit          # DOWNLOAD Limit\n\n# Upload limit (in mega bits)\nUPLD=80mbit          # UPLOAD Limit\n\n# IP address of the machine we are controlling\nIP=125.64.15.21     # Host IP\n\n# Filter options for limiting the intended interface.\nU32=\"$TC filter add dev $IF protocol ip parent 1:0 prio 1 u32\"\n\nstart() {\n\n# We'll use Hierarchical Token Bucket (HTB) to shape bandwidth.\n# For detailed configuration options, please consult Linux man\n# page.\n\n    $TC qdisc add dev $IF root handle 1: htb default 30\n    $TC class add dev $IF parent 1: classid 1:1 htb rate $DNLD\n    $TC class add dev $IF parent 1: classid 1:2 htb rate $UPLD\n    $U32 match ip dst $IP/32 flowid 1:1\n    $U32 match ip src $IP/32 flowid 1:2\n\n# The first line creates the root qdisc, and the next two lines\n# create two child qdisc that are to be used to shape download\n# and upload bandwidth.\n#\n# The 4th and 5th line creates the filter to match the interface.\n# The 'dst' IP address is used to limit download speed, and the\n# 'src' IP address is used to limit upload speed.\n\n}\n\nstop() {\n\n# Stop the bandwidth shaping.\n    $TC qdisc del dev $IF root\n\n}\n\nrestart() {\n\n# Self-explanatory.\n    stop\n    sleep 1\n    start\n\n}\n\nshow() {\n\n# Display status of traffic control status.\n    $TC -s qdisc ls dev $IF\n\n}\n\ncase \"$1\" in\n\n  start)\n\n    echo -n \"Starting bandwidth shaping: \"\n    start\n    echo \"done\"\n    ;;\n\n  stop)\n\n    echo -n \"Stopping bandwidth shaping: \"\n    stop\n    echo \"done\"\n    ;;\n\n  restart)\n\n    echo -n \"Restarting bandwidth shaping: \"\n    restart\n    echo \"done\"\n    ;;\n\n  show)\n\n    echo \"Bandwidth shaping status for $IF:\"\n    show\n    echo \"\"\n    ;;\n\n  *)\n\n    pwd=$(pwd)\n    echo \"Usage: tc.bash {start|stop|restart|show}\"\n    ;;\n\nesac\n\nexit 0\n```\n\n本文原文出处:http://leslie-chu.blog.163.com/blog/static/19986324320125414618221\n\n主要参考（所有权利归原文作者所有）：\n\nhttp://www.cnblogs.com/endsock/archive/2011/12/09/2281519.html\n\nhttp://blog.163.com/ninja_wk/blog/static/989155620084280154811/\n\nhttp://www.chinaunix.net/jh/4/16110.html\n","tags":["tc"],"categories":["service"]},{"title":"Linux上ssd优化","url":"/2017/05/27/system/Linux上ssd优化/","content":"# 一、修改默认的固态硬盘(SSD)柱面大小\n\n　　提升Linux下固态硬盘的使用率，在安装Linux操作系统前就应该做相关工作。系统会先在磁盘上创建分区，通常创建的分区包含固定数量的柱面，而默认情况下，每个柱面由16065512个字节的扇区组成。\n  \n<!-- more -->\n\n　　现在的问题是，当默认柱面空间大小被完全使用后，固态硬盘就不能发挥最佳性能。因为要固态硬盘读这个操作需要使用4KB的字节块，而固态硬盘控制器删除操 作则需要512KB的字节块。问题是，有了通常用于Linux上的默认分区，分区的开始没必要也是一个4KB新分区的开始。结果，一次读取或写入操作也许 需要SSD设备上的两个不同的区块，这也减缓了SSD磁盘的性能。\n\n　　为了避免这种问题，可以采用fdisk方式来创建分区，配置三个选项来指定使用柱面及拍面大小。具体的命令如下：\n\n```sh\nfdisk -H 32 -C 32 –c /dev/sdb\n```\n# 二、配置固态硬盘(SSD)的文件系统\n\n### 1.创建文件系统\n\n　　接着需要关注的就是文件系统。想要优化文件系统删除字节区块的效率，就必须确保小于512K的文件分布在不同的删除字节区块上。要做到这一点，必须确保在创建可扩展文件系统时指定了需要使用的条带的宽度和幅度。这些值在页面中指定，默认大小为4KB。要创建一个最佳的可扩展文件系统，应该使用如下命令：\n\n```sh\nmkfs.ext4 -E stride=128,stripe-width=128 /dev/sda1\n```\n\n　　如果要修改现有的文件系统的参数，可以使用tune2fs实用程序：\n\n```sh\ntune2fs -E stride=128,stripe-width=128 /dev/sda1\n```\n\t\n### 2.文件系统日志\n\n　　关闭日志功能，可以延长SSD寿命，但是突然断电容易造成文件损坏\n\n```sh\ntune2fs -O ^has_journal /dev/sda2  关闭日志；\n```\n\n　　然后执行\n\n```sh\ne2fsck -f /dev/sda2；\n```\n\n　　检查日志是否关闭成功：\n\n```sh\ndmesg | grep EXT4\n```\n\n　　如果显示 “EXT4-fs (sda2): mounted filesystem without journal”  说明关闭日志成功；否则显示 “mounted filesystem with ordered data mode”\n\n\n　　要打开日志\n\n```sh\ntune2fs -O has_journal /dev/sda2   \n```\n\n### 3.设置noatime\n\n　　不记录文件访问时间，该选项保证了文件的访问时间不会因为每次读取而更新，从而降低对文件系统的写入次数。\n\n　　在fstb 中加入noatime　选项\n\n```sh\n/dev/sda1 / ext4 discard,defaults  改为  /dev/sda1 / ext4 noatime,defaults\n```\n\n# 三、配置固态硬盘(SSD)的I/O调度程序\n\n　　优化的第三个部分涉及到I/O调度程序。该模块是一个决定如何处理I/O请求的核心组件。默认情况下就是非常公平的排队，对于普通的磁盘驱动器来说，这是很好的方案，但对于以期限调度为优势的固态硬盘来说，这并不是最好的。\n\n　　如果你想在系统中对所有磁盘采用期限调度，可以在内核加载时把`elevator=deadline`这句话加入到系统引导管理器(GURB)中;如果你只是想针对某一个磁盘，就应该在rc.local文件中加入类似如下实例的一句话，那么每次当系统重启，期限调度就会应用到指定的磁盘。如下实例将会对 /dev/sdb磁盘采用期限调度。\n\n```sh\necho deadline > /sys/block/xvda/queue/scheduler\n```\n　　给IO的算法修改成 noop,操作系统本身不做处理,让 ssd 本身处理.\n\n```sh\necho noop >  /sys/block/sda/queue/scheduler\n```\n\n# 四、清理固态硬盘(SSD)中的数据块\n\n　　最后一个重要的步骤称为“清理”，该操作可以确保在删除文件后相应的数据块真正清空，然后在创建新的文件时才能有可用的数据块。如果没有清理操作，一旦数 据块空间填满，固态硬盘的性能就会下降。如果使用丢弃挂载选项，当文件删除后，数据块也会被相应地清除，这样可以显著提高固态硬盘的性能。2.6.33以 上的内核已经支持清理操作。\n\n　　Linux内核从2.6.33开始提供TRIM支持，所以先运行“uname -a”命令，查看自己的内核版本，如果内核版本低于2.6.33的，请先升级内核。然后运行“hdparm -I /dev/sda”查看自己的硬盘支不支持TRIM技术，如果支持，你会看到\n\n```\n* Data Set Management TRIM supported\n```\n\n　　注意：如果SSD组RAID0后，将失去Trim功能\n\n　　如果上面两个条件都满足了，就可以在fstab中添加discard来开启TRIM功能，如：\n\n```sh\n原始的UUID=2f6be0cf-2f54-4646-b8c6-5fb0aa01ef23 / ext4 defaults,errors=remount-ro 0 1\n改后的UUID=2f6be0cf-2f54-4646-b8c6-5fb0aa01ef23 / ext4 discard,defaults,errors=remount-ro,noatime 0 1\n```\n\n　　在fasab配置文件中完成对文件系统的这些修改后，重启计算机，或者通知文件系统重新读取其配置，然后使用/etc/fstab文件中包含的mount -o remount命令重新安装每个文件系统。\n\n","tags":["调优"],"categories":["system"]},{"title":"rsync安装配置实例","url":"/2017/05/26/service/rsync安装配置实例/","content":"\n本文详细介绍了rsync安装配置实例。\n<!-- more -->\n\n# 一. 安装rsync\n\n```sh\nyum install rsync\n```\n\n# 二. 配置rsync服务器端\n\n### 1、  修改rsync的配置文件\n\n```sh\ncat /etc/xinetd.d/rsync\n\n# default: off\n# description: The rsync server is a good addition to an ftp server, as it \\\n#   allows crc checksumming etc.\nservice rsync\n{\n    disable = yes\n    flags           = IPv6\n    socket_type     = stream\n    wait            = no\n    user            = root\n    server          = /usr/bin/rsync\n    server_args     = --daemon\n    log_on_failure  += USERID\n}\n\n```\n\n　　可以看到rysnc服务是关闭的(disable = yes)，这里把它开启，把disable的值改为no\n\n### 2、  创建rsync服务器配置文件/etc/rsyncd.conf\n\n```sh\nvim /etc/rsyncd.conf\n\nuid = root\ngid = root\nport = 873                                      #　指定运行端口，默认是873，您可以自己指定\nhosts allow = 192.168.0.204, 192.168.1.205      # 允许访问的客户机\n#hosts deny = 0.0.0.0/32                        #　拒绝访问的\nuse chroot = \nmax connections = \ntimeout=\n\n# 下面这些文件是安装完RSYNC服务后自动生成的文件,当然也可以手动配置到指定路径\n\npid file = /var/run/rsyncd.pid      #pid文件的存放\nlock file = /var/run/rsync.lock     #锁文件的存放位置\nlog file = /var/log/rsyncd.log      #日志记录文件的存放\nmotd file = /etc/rsyncd.motd        #欢迎\n\n# 上面这段是全局配置，下面的模块可以有\n\n[test]                                        # 模块名字，自己命名\npath = /home/hyj/workspace/test               # 指定文件目录所在位置，这是必须指定 \ncomment = rsync files                         # 注释\nignore errors                                 # 忽略IO\nread only = yes \nlist = no                                     # 是否把rsync 服务器上提供同步数据的目录显示\nauth users = rsync                            # 同步验证时用的账号，如果没有这项就是匿名同步，client同步时不用用户名也能同步。\nsecrets file = /etc/rsync.passwd              # 指定认证文件\n```\n\n### 3、  创建认证文件：\n\n#### 3.1. 创建认证文件\n```sh\nvim /etc/rsync.passwd\n\nrsync:hyl            # 用户名：密码。注意这个不是系统用户，只是rsync用户。所以不用useradd。\n```\n\n　　名字随便写，只要和上边配置文件里的“auth users”参数一致即可，格式(一行一个用户)账号：密码\n\n\n#### 3.2. 修改认证文件权限\n\n　　把认证文件的权限改成600\n\n```sh\nchmod 600 /etc/rsync.passwd          ## 只能所有者可读，否则报错\n```\n\n### 4、 欢迎信息\n\n　　如果在配置文件中指定了欢迎信息，在/etc下创建rsyncd.motd，设置欢迎信息：\n\n```sh\nvim /etc/rsyncd.motd\n\n      Welcome the rsync services!\n```\n\n# 三. 启动rsync\n\n### 1、 在server端将rsync启动：\n\n#### 1.1 启动rsync服务端（以守护进程形式，独立启动）\n\n```sh\n/usr/bin/rsync --daemon\n```\n\n#### 1.2 启动rsync服务端 （以xinetd超级进程启动）\n\n```sh\n/etc/rc.d/init.d/xinetd reload(reload是网上的说法，但是我试了一下报错，start可以)\n```\n\n### 2、 防火墙设置：\n\n　　如果服务器上装有防火墙，需在服务器中设置iptables将837端口开放。\n\n```sh\niptables -A INPUT -p tcp --dport 873 -j ACCEPT\n```\n\n# 四. 配置rsync客户端\n\n### 1、用安装服务器端的方式安装rsync。\n\n　　启动rsync，如果报如下错误，是因为在etc下没有rsyncd.conf配置文件：\n\n```sh\nrsync --daemon\nFailed to parse config file: /etc/rsyncd.conf\n```\n\n　　创建配置文件 `/etc/rsyncd.conf` 文件内容为空就行。然后启动rsync，可以启动\n\n### 2、Rsync的命令格式可以为以下六种：\n\n```sh\n　　rsync [OPTION]... SRC DEST\n　　rsync [OPTION]... SRC [USER@]HOST:DEST\n　　rsync [OPTION]... [USER@]HOST:SRC DEST\n　　rsync [OPTION]... [USER@]HOST::SRC DEST\n　　rsync [OPTION]... SRC [USER@]HOST::DEST\n　　rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n```\n\n　　常用为以下两种：\n\n#### 第一种：\n\n```sh\nrsync [OPTION]... [USER@]HOST::SRC   DEST\n```\n\n　　从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含\"::\"分隔符时启动该模式。\n\n```sh\n如：rsync -av root@172.16.78.192::www /databack\n```\n\n#### 第二种：\n\n```sh\nrsync [OPTION]... SRC   [USER@]HOST::DEST\n```\n\n　　从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含\"::\"分隔符时启动该模式。\n\n```sh\n如：rsync -av /databack root@172.16.78.192::www\n```\n\n### 3、下面为实例：\n\n　　服务器ip为192.168.8.126，客户端ip为192.168.8.122\n\n　　(1)、把服务器上的/home/hyj/workspace/test文件夹中的内容备份到客户端的/usr/local/share/rsync_backup中:\n\n```sh\n/usr/bin/rsync -vzrtopg --delete  --progress rsync@192.168.8.126::test /usr/local/share/rsync_backup\n```\n\n　　`/etc/rsyncd.conf` 中模块的内容：\n\n```sh\n[test]\npath = /home/hyj/workspace/test\ncomment = rsync files\nignore errors\nread only = yes\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n```\n\n　　上面这个命令行中-vzrtopg里的v是verbose，z是压缩，r是recursive，topg都是保持文件原有属性如属主、时间的参数（也可以用直接用a来代替rtopg， a为 --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD）。--progress是指显示出详细的进度情况，--delete是指如果服务器端删除了这一文件，那么客户端也相应把文件删除，保持真正的一致。\n\n　　（2）、上面的命令需要在备份的时候需要输入密码，可以在客户端建立一个密码文件，在命令中把密码文件作为参数带入：\n\n```sh\nvim /etc/rsync.passwd\n\nhyl\n```\n\n　　密码文件中不用输入用户名，只需输入密码即可。\n\n\n　　这份密码文件权限属性要设得只有root可读，不然会报错，修改属性：\n\n```sh\nchmod 600 /etc/rsync.passwd\n```\n\n　　用下面这条命令，可以不输入密码：\n\n```sh\n/usr/bin/rsync -vzrtopg --delete  --progress --password-file=/etc/rsync.passwd rsync@192.168.8.126::test /usr/local/share/rsync_backup \n```\n　　(3)、 带exclude 参数\n\n　　把服务器上的/home/hyj/workspace/test文件夹中的内容备份到客户端的/usr/local/share/rsync_backup中，但不包括:res目录和default.properties文件：\n\n```sh\n/usr/bin/rsync -vzrtopg --delete --exclude \"res/\" --exclude \"default.properties\" --progress --password-file=/etc/rsync.passwd rsync@192.168.8.126::test /usr/local/share/rsync_backup \n```\n\n** exclude/include规则实例 **\n\n```sh\nHere are some exclude/include examples:\n --exclude \"*.o\"   would exclude all filenames matching *.o\n --exclude \"/foo\"  would exclude a file in the base directory called foo\n --exclude \"foo/\"  would exclude any directory called foo.\n --exclude \"/foobar\" would exclude any file called bar two or more levels below a base directory called foo.\n --include \"*/\" --include \"*.c\" --exclude \"*\" would include all directories and C source files\n--include \"foo/\" --include \"foo/bar.c\" --exclude \"*\" would include only foo/bar.c\n (the foo/ directory must be explicitly included or it would be excluded by the \"*\")\n\n```\n　　(4)、 把客户端上的/home/hyj/vitest文件夹中的内容备份到服务器的/usr/local/share/rsync_backup中，在客户端执行如下命令:\n\n```sh\n   /usr/bin/rsync -vzrtopg --delete --progress --password-file=/etc/rsync.passwd /home/hyj/vitest rsync@192.168.8.126::clientdata\n```\n\n　　此时服务器的配置文件/etc/rsyncd.conf内容为:\n\n```sh\nuid = root\ngid = root\nhosts allow = 192.168.8.122, 192.168.8.123\n#hosts deny = 0.0.0.0/32\nuse chroot = no\nmax connections = 10\npid file = /var/run/rsyncd.pid\nlock file = /var/run/rsync.lock\nlog file = /var/log/rsyncd.log\ntimeout=600\n\n[test]\npath = /home/hyj/workspace/test\ncomment = rsync files\nignore errors\nread only = yes\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n\n # 上面的命令中，客户端的数据备份到clientdata模块中，备份到/usr/local/share/rsync_backup文件夹下，read only改为no，# # 否则会报 `ERROR: module is read only` 的错误\n\n[clientdata]\npath = /usr/local/share/rsync_backup\ncomment = rsync files\nignore errors\nread only = no\nlist = no\nauth users = rsync\nsecrets file = /etc/rsync.passwd\n```\n\n\n# FAQ\n\n### 1、我需要在防火墙上开放哪些端口以适应rsync？\n\n　　视情况而定\n\n　　rsync可以直接通过873端口的tcp连接传文件，也可以通过22端口的ssh来进行文件传递，但你也可以通过下列命令改变它的端口：\n\n```sh\nrsync --port 8730 otherhost::\n或者\nrsync -e 'ssh -p 2002' otherhost:\n```\n\n### 2、 我如何通过rsync只复制目录结构，忽略掉文件呢？\n\n```sh\nrsync -av --include '*/' --exclude '*' source-dir dest-dir\n```\n\n# 常见错误\n\n```sh\nrsync: failed to connect to 218.107.243.2: No route to host (113) \nrsync error: error in socket IO (code 10) at clientserver.c(104) [receiver=2.6.9]\n```\n　　解决：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能。关闭防火墙，其实就是把tcp udp 的873端口打开：\n\n---\n\n```sh\npassword file must not be other-accessible \ncontinuing without password file \nPassword: \n```\n\n　　解决：这是因为rsyncd.pwd rsyncd.sec的权限不对，应该设置为600。如：`chmod 600 rsyncd.pwd`\n\n---\n\n```sh\n@ERROR: auth failed on module xxxxx \nrsync: connection unexpectedly closed (90 bytes read so far) \nrsync error: error in rsync protocol data stream (code 12) at io.c(150) \n```\n\n　　解决：这是因为密码设置错了，无法登入成功，检查一下rsync.pwd，看客服是否匹配。还有服务器端没启动rsync 服务也会出现这种情况。 \n\n---\n\n```sh\n@ERROR: chroot failed \nrsync: connection unexpectedly closed (75 bytes read so far) \nrsync error: error in rsync protocol data stream (code 12) at io.c(150) \n```\n\n　　解决：这是因为你在 rsync.conf 中设置的 path 路径不存在，要新建目录才能开启同步。 \n\n---\n\n```sh\n[root@hyj rsync_backup]# /usr/bin/rsync -vzrtopg --delete --exclude \"res/\" --exclude \"default.properties\" --progress rsync@192.168.8.126::test /usr/local/share/rsync_backup --password-file=/etc/rsync.pass\n\n@ERROR: chdir failed\n\nrsync error: error starting client-server protocol (code 5) at main.c(1516) [Receiver=3.0.9]\n```\n\n　　原因及解决办法：SELinux；（下面这条命令在服务器端执行）\n```sh\nsetsebool -P rsync_disable_trans on\n```\n\n---\n\n```sh\nERROR: module is read only\nrsync: read error: Software caused connection abort (113)\nrsync error: error in rsync protocol data stream (code 12) at io.c(769) [sender=3.0.8]\n```\n\n　　解决：这是因为服务器端配置文件rsyncd.conf中read only = yes，为只读，即不允许客户端上传文件，改成no就可以了。\n","tags":["rsync"],"categories":["service"]},{"title":"pdflush进程详解与优化","url":"/2017/05/25/system/pdflush进程详解与优化/","content":"# 一、简介\n\n　　由于页高速缓存的缓存作用，写操作实际上会被延迟。当页高速缓存中的数据比后台存储的数据更新时，那么该数据就被称做脏数据。在内存中累积起来的脏页最终必须被写回磁盘。\n\n<!-- more -->\n\n在以下两种情况发生时，脏页被写回磁盘：\n\n* 当空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。\n* 当脏页在内存中驻留时间超过一个特定的阈值时，内核必须将超时的脏页写回磁盘，以确保脏页不会无限期地驻留在内存中。\n\n　　上面两种工作的目的完全不同。实际上，在老内核中，这是由两个独立的内核线程分别完成的。但是在2.6内核中，由一群内核线程—pdflush后台回写例程—统一执行两种工作。\n\n　　我们来看看这两个目标是如何具体实现的。首先，当系统中的空闲内存低于一个特定的阈值时，pdflush线程将脏页刷新回磁盘。该后台回写例程的目的在于在可用物理内存过低时，释放脏页以重新获得内存。特定的内存阈值可以通过`dirty_background_ratio`参数设置。当空闲内存比阈值`dirty_ background_ratio`还低时，内核便会调用函数`wakeup_bdflush()`唤醒一个pdflush线程，随后pdflush线程进一步调用函数`background_writeout()`开始将脏页写回磁盘。函数`background_ writeout()`需要一个长整型参数，该参数指定试图回写的页面数目。\n\n　　函数`background_writeout()`会连续地写出数据，直到满足以下两个条件：\n\n* 已经有指定的最小数目的页被写出到磁盘。\n* 空闲内存数已经回升，超过了阈值dirty_background_ratio。\n\n　　上述条件确保了pdflush操作可以减轻系统中内存不足的压力。回写操作不会在达到这两个条件前停止，除非pdflush写回了所有的脏页，没有剩下的脏页可再被写回了。\n\n　　要满足第二个目标，pdflush后台例程会被周期性唤醒（和空闲内存是否过低无关），将那些在内存中驻留时间过长的脏页写出，确保内存中不会有长期存在的脏页。假如系统发生崩溃，则内存会处于混乱之中，而那些在内存中还没来得及写回磁盘的脏页就会丢失，所以周期性同步回写非常重要。\n\n　　在系统启动时，内核初始化一个定时器，让它周期地唤醒pdflush线程，随后使其运行函数`wb_kupdate()`。该函数将把所有驻留时间超过百分之`dirty_expire_centisecs`秒的脏页写回。然后定时器将再次被初始化为百分之`dirty_expire_ centisecs`秒后唤醒pdflush线程。\n\n　　总而言之，pdflush线程周期地被唤醒并且把超过特定期限的脏页写回磁盘。\n\n# 二、proc下的相关控制参数\n\n　　系统管理员可以在/proc/sys/vm中设置回写相关的参数，也可以通过sysctl系统调用设置它们。\n\n* /proc/sys/vm/dirty_ratio\n\n　　这个参数控制一个进程在文件系统中的文件系统写缓冲区的大小，单位是百分比，表示系统内存的百分比，表示当一个进程中写缓冲使用到系统内存多少的时候，再有磁盘写操作时开始向磁盘写出数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是 40。设置方法如下：\n\n```sh\necho 30 >/proc/sys/vm/dirty_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_background_ratio\n\n　　这个参数控制文件系统的pdflush进程，在何时刷新磁盘。单位是百分比，表示系统总内存的百分比，意思是当磁盘的脏数据缓冲到系统内存多少的时候，pdflush开始把脏数据刷新到磁盘。增大会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是10。设置方法如下：\n\n```sh\necho 8 >/proc/sys/vm/dirty_background_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_writeback_centisecs\n\n　　Pdflush写后台进程每隔多久被唤醒并执行把脏数据写出到硬盘。单位是 1/100 秒。如果你的系统是持续地写入动作，那么实际上还是降低这个数值比较好，这样可以把尖峰的写操作削平成多次写操作。缺省数值是500，也就是 5 秒。设置方法如下：\n\n```sh\necho 200 >/proc/sys/vm/dirty_writeback_centisecs\n```\n\n---\n\n* /proc/sys/vm/dirty_expire_centisecs\n\n　　这个参数声明Linux内核写缓冲区里面的脏数据多“旧”了之后，pdflush 进程就开始考虑写到磁盘中去。单位是 1/100秒。对于特别重载的写操作来说，这个值适当缩小也是好的，但也不能缩小太多，因为缩小太多也会导致IO提高太快。缺省是 30000，也就是 30 秒的数据就算旧了，将会刷新磁盘。建议设置为 1500，也就是15秒算旧。设置方法如下：\n\n```sh\necho 1500 >/proc/sys/vm/dirty_expire_centisecs\n```\n\n---\n\n# 三、内核参数修改后的生效\n\n　　Linux在系统运行时修改内核参数(/proc/sys与/etc/sysctl.conf)，而不需要重新引导系统，这个功能是通过/proc虚拟文件系统实现的。\n\n　　在/proc/sys目录下存放着大多数的内核参数，并且设计成可以在系统运行的同时进行更改,可以通过更改/proc/sys中内核参数对应的文件达到修改内核参数的目的(修改过后，保存配置文件就马上自动生效)，不过重新启动机器后之前修改的参数值会失效，所以只能是一种临时参数变更方案。(适合调试内核参数优化值的时候使用，如果设置值有问题，重启服务器还原原来的设置参数值了。简单方便。)\n\n　　但是如果调试内核参数优化值结束后，需要永久保存参数值，就要通过修改/etc/sysctl.conf内的内核参数来永久保存更改。但只是修改sysctl文件内的参数值，确认保存修改文件后，设定的参数值并不会马上生效，如果想使参数值修改马上生效，并且不重启服务器，可以执行下面的命令：\n\n```sh\nsysctl –p\n```\n\n---\n\n　　下面介绍一下/proc/sys下内核文件与配置文件sysctl.conf中变量的对应关系：\n\n　　由于可以修改的内核参数都在/proc/sys目录下，所以sysctl.conf的变量名省略了目录的前面部分（/proc/sys）。即将/proc/sys中的文件转换成sysctl中的变量依据下面两个简单的规则：\n\n1. 去掉前面部分/proc/sys\n2. 将文件名中的斜杠变为点\n\n　　这两条规则可以将/proc/sys中的任一文件名转换成sysctl中的变量名。\n\n　　例如：\n\n```sh\n/proc/sys/net/ipv4/ip_forward => net.ipv4.ip_forward\n/proc/sys/kernel/hostname =>  kernel.hostname\n```\n\n　　可以使用下面命令查询所有可修改的变量名\n\n```sh\nsysctl –a\n```\n","tags":["调优"],"categories":["system"]},{"title":"MongoDB归档及压缩工具","url":"/2017/05/25/database/MongoDB归档及压缩工具/","content":"　　原文地址：http://t.dbdao.com/archives/archiving-and-compression-in-mongodb-tools.html\n\n\n# 介绍\n\n　　我在MongoDB World 2015做的演讲“Putting the Go in MongoDB”，重点是关于MongoDB工具的重写，从C ++到Go，这在可用性以及性能方面得到了一些改进，但是这里我只简要的说两个方面的新功能，(planned for the 3.2 release) – 归档和压缩。\n\n　　在本文中，我将对mongodump和mongorestore提供更详细的归档和压缩特性说明，并探索使用这些特性的可行用例。\n\n\n<!-- more -->\n\n# 概述\n\n　　一个通常目的的归档一般由一个或多个文件组成。这样例子如磁带归档格式(tar)，其中包含按顺序组成的一个或多个文件。归档在执行进程间通信的应用程序中尤其有用，例如，你可以通过远程服务器进行目录的tarball压缩，然后通过SSH，传送到到本机上进行解压：\n\n```ssh\nssh source.server.com tar c sourceDirectory | tar x\n```\n\n　　由于归档以顺序的方式创建，接收端将能按顺序接收到发送端按顺序发来的数据。\n\n　　在3.0中，我们增加了在MongoDB中并发执行备份和恢复多个集合的能力，这可以让你执行备份时，更加充分地利用磁盘I / O。 结果，写入mongodump的备份并不一定以顺序的方式接收。 同样，mongorestore同时读取还原操作集合，它的读取指令也并非是序列性的。\n\n　　通用归档格式，如tar，只支持连续的文件归档打包。mongodump和mongorestore利用这些备份格式，将得到一个不可接受的性能退化， 由于所有集合的数据将不得不被按顺序写入和读出。为了支持这些工具的并发行为，我们研发了一个特殊的通用备份格式，支持非并发文件的写入。 这个新的归档特性极大了提高了备份和还原操作的效率。\n\n# 背景\n\n　　为了按上下文情况进行备份，我们考虑一下你们通常是如何创建备份的。比如，假设你有一个“country”的数据库，其中含有两个集合： “nigeria” and “austria”， 你可能会这样操作：\n\n```sh\t\nmongodump --db country\n```\n\n　　上面的指令读取“country”数据库的所有集合， 然后将其写入“dump”目录。 上面的指令就会产生以下的目录列表：\n\n```sh\ndump/\n└── [4.3M]  country\n    ├── [2.1M]  austria.bson\n    ├── [  87]  austria.metadata.json\n    ├── [2.1M]  nigeria.bson\n    ├── [  87]  nigeria.metadata.json\n    └── [ 140]  system.indexes.bson\n \n1 directory, 5 files\n```\n\n　　你也可以备份整个服务器-这里的服务器包含两个数据库(country 和product)。\n\n```sh\nmongodump\n```\n\n```sh\n├── [5.4M]  dump\n│   ├── [4.03M]  country\n│   │   ├── [2.1M]  austria.bson\n│   │   ├── [  87]  austria.metadata.json\n│   │   ├── [2.1M]  nigeria.bson\n│   │   ├── [  87]  nigeria.metadata.json\n│   │   └── [ 140]  system.indexes.bson\n│   └── [1.1M]  product\n│       ├── [1.0M]  mongodump.bson\n│       ├── [  89]  mongodump.metadata.json\n│       └── [  72]  system.indexes.bson\n2 directories, 8 files\n```\n\n　　或选择备份单个集合到标准输出，而不是一个目录：\n\n```sh\t\nmongodump --db country --collection nigeria --out -\n```\n\n# 归档支持\n\n　　在3.2中，我们引入了创建备份的一个附加模式 －－ “归档”模式，写入所有转储数据，甚至从不同的数据库和集合到单一的输出文件。 使用mongodump创建归档是极为简单的 – 只需要一个附加选项：\n\n```sh\nmongodump --db country --archive=country.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 4.2M Jun 29 11:12 country.archive\n```\n\n　　上面的指令将在“country.archive”文件中创建“country”的数据库归档。默认情况下，归档被写入到标准输出。不同于目录模式的执行备份，创建目录树，默认归档模式下备份结果就是一个单一的文件， 包含“country”数据库的所有数据-所有集合，索引等。\n\n　　你也可以备份一个单一的集合或整个服务器的内容：\n\n　　**单一集合：**\n\n```sh\t\nmongodump --db country --collection nigeria --archive=nga.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 2.1M Jun 29 11:15 nga.archive\n```\n\n　　**整个服务器：**\n\n```sh\nmongodump --archive=server.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 5.3M Jun 29 11:26 server.archive\n```\n\n　　在mongodump的这种情况下，归档模式允许多个集合以非连续的方式打包在归档文件内。在mongorestore中，它允许多个集合进行并行恢复。这样，你可以在网络上执行数据迁移，降低磁盘I/O所占空间，享受到充分利用工具和底层存储引擎的并发所带来的好处。\n\n# 数据迁移\n\n　　一个新的备份改善的例子， 是mongodump和mongorestore之间的进程间通信 – 特别是能够将数据从一个传到另一个。在以前的版本中，这种支持有限 – 一个时间只能传输一个集合。现在，使用归档就没有这样的限制。这种方式对于数据库服务器出于安全考虑而安装有防火墙的情况下很有用。在这种情况下，一个通常的设计是允许一个或多个服务器方访问数据库。使用归档功能，在SSH上进行数据转移数据，就轻而易举了：\n\n```sh\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive  | ssh wisdom@target.server.com mongorestore --archive\n```\n\n　　上面的指令使用SSH方式连接到代理主机（proxy.server.com），访问源服务器（source.server.com），在代理服务器上运行mongodump，为了最终的恢复，将源服务器的发送内容（通过SSH）到目标服务器（target.server.com）。\n\n　　如果没有归档，通过mongodump完成这些操作的唯一办法就是，先执行备份到磁盘，在将文件复制到目标服务器，然后运行mongorestore。通过备份，一个指令就可以完成- 无需任何附加磁盘I/O的开销。\n\n# 压缩支持\n\n　　除了备份，我们还使用gzip进行压缩。这是通过在mongodump和mongorestore中引入一个新的指令行选项 “--gzip” 实现的。 压缩可用于目录以及归档模型下创建的备份，压缩还可以减少磁盘空间使用。\n\n```sh\nmongodump --db country --gzip\n```\n\n　　生成：\n\n```sh\ndump/\n└── [568K]  country\n    ├── [254K]  austria.bson.gz\n    ├── [ 100]  austria.metadata.json.gz\n    ├── [254K]  nigeria.bson.gz\n    ├── [ 100]  nigeria.metadata.json.gz\n    └── [  91]  system.indexes.bson.gz\n \n1 directory, 5 files\n```\n\n　　注意,目录模型的归档备份大小-568KB-比没有压缩的备份要小很多-4.3MB.\n\n　　**压缩归档：**\n\n```sh\nmongodump --db country --gzip --archive=country.archive\n\n-rw-rw-r-- 1 wisdom wisdom 509K Jun 29 11:23 country.archive\n```\n\n　　对于归档来说，数据在写入归档之前需要先压缩。\n\n　　恢复压缩目录模式备份，你应该运行：\n\n```sh\t\nmongorestore --gzip\n```\n\n　　类似用来恢复归档模式下的压缩备份的命令：\n\n```sh\t\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive --gzip  | ssh wisdom@target.server.com mongorestore --archive --gzip\n```\n\n　　数据迁移不会产生任何磁盘I / O开销，由于压缩，将会使用更少的网络带宽。\n\n# 总结\n\n　　归档和压缩特性产生了许多用于进行备份和恢复操作的例子。如果你们正在使用MongoDB工具和其它类型的应用程序，我们也乐于倾听你们的经验及用例。 尽管目前最新版本工具还不文档，不过希望大家先对这些特性体验起来。\n\n　　**注：** 作为提供共享集群的集群范围快照的唯一备份解决方案，MongoDB Ops Manager和MongoDB Cloud Mannager被推荐用于较大的MongoDB部署。\n","tags":["mongodb"],"categories":["database"]},{"title":"Linux下清空或删除大文件内容的5种方法","url":"/2017/05/25/system/Linux下清空或删除大文件内容的5种方法/","content":"\n\n编译自：http://www.tecmint.com/empty-delete-file-content-linux/ 作者： Aaron Kili\n\n原创：LCTT https://linux.cn/article-8024-1.html 译者： FSSlc \n\n在 Linux 终端下处理文件时，有时我们想直接清空文件的内容但又不必使用任何 Linux 命令行编辑器 去打开这些文件。那怎样才能达到这个目的呢？在这篇文章中，我们将介绍几种借助一些实用的命令来清空文件内容的方法。\n\n**注意：** 在我们进一步深入了解这些方法之前，请记住: 由于在 Linux 中一切皆文件，你需要时刻注意，确保你将要清空的文件不是重要的用户文件或者系统文件。清空重要的系统文件或者配置文件可能会引发严重的应用失败或者系统错误。\n\n前面已经说道，下面的这些方法都是从命令行中达到清空文件的目的。\n\n**提示：** 在下面的示例中，我们将使用名为 access.log 的文件来作为示例样本。\n<!-- more -->\n\n# 1. 通过重定向到 Null 来清空文件内容\n\n清空或者让一个文件成为空白的最简单方式，是像下面那样，通过 shell 重定向 `null` （不存在的事物）到该文件：\n\n```sh\n> access.log\n```\n\n```sh\n[root@localhost logs]# du -sh catalina.out \n9.7G\tcatalina.out\n[root@localhost logs]# > catalina.out \n[root@localhost logs]# du -sh catalina.out \n0\tcatalina.out\n```\n\n在 Linux 下使用 Null 重定向来清空大文件\n\n# 2. 使用 `true` 命令重定向来清空文件\n\n下面我们将使用 : 符号，它是 shell 的一个内置命令，等同于 true 命令，它可被用来作为一个 no-op（即不进行任何操作）。\n\n另一种清空文件的方法是将 : 或者 true 内置命令的输出重定向到文件中，具体如下：\n\n```sh\n: > access.log\n```\n 或\n```sh\ntrue > access.log\n```\n\n使用 Linux 命令清空大文件\n\n# 3. 使用 cat/cp/dd 实用工具及 /dev/null 设备来清空文件\n\n在 Linux 中， null 设备基本上被用来丢弃某个进程不再需要的输出流，或者作为某个输入流的空白文件，这些通常可以利用重定向机制来达到。\n\n所以 /dev/null 设备文件是一个特殊的文件，它将清空送到它这里来的所有输入，而它的输出则可被视为一个空文件。\n\n另外，你可以通过使用 cat 命令 显示 /dev/null 的内容然后重定向输出到某个文件，以此来达到清空该文件的目的。\n\n```sh\ncat /dev/null > access.log\n```\n\n使用 cat 命令来清空文件\n\n下面，我们将使用 cp 命令 复制 /dev/null 的内容到某个文件来达到清空该文件的目的，具体如下所示：\n\n```sh\ncp /dev/null access.log\n```\n\n\n使用 cp 命令来清空文件\n\n而下面的命令中， if 代表输入文件，of 代表输出文件。\n\n```sh\ndd if=/dev/null of=access.log\n```\n\n\n使用 dd 命令来清空文件内容\n\n# 4. 使用 echo 命令清空文件\n\n在这里，你可以使用 echo 命令 将空字符串的内容重定向到文件中，具体如下：\n\n```sh\necho \"\" > access.log\n```\n或者\n ```sh\n echo > access.log\n```\n\n使用 echo 命令来清空文件\n\n**注意：**你应该记住空字符串并不等同于 null 。字符串表明它是一个具体的事物，只不过它的内容可能是空的，但 null 则意味着某个事物并不存在。\n\n基于这个原因，当你将 echo 命令 的输出作为输入重定向到文件后，使用 cat 命令 来查看该文件的内容时，你将看到一个空白行（即一个空字符串）。\n\n要将 null 做为输出输入到文件中，你应该使用 -n 选项，这个选项将告诉 echo 不再像上面的那个命令那样输出结尾的那个新行。\n\n```sh\necho -n \"\" > access.log\n```\n\n使用 Null 重定向来清空文件\n\n# 5. 使用 truncate 命令来清空文件内容\n\ntruncate 可被用来将一个文件缩小或者扩展到某个给定的大小。\n\n你可以利用它和 -s 参数来特别指定文件的大小。要清空文件的内容，则在下面的命令中将文件的大小设定为 0:\n\n```sh\ntruncate -s 0 access.log\n```\n\n在 Linux 中截断文件内容\n\n我要介绍的就是这么多了。在本文中，我们介绍了几种通过使用一些简单的命令行工具和 shell 重定向机制来清除或清空文件内容的方法。\n\n上面介绍的这些可能并不是达到清空文件内容这个目的的所有可行的实践方法，所以你也可以通过下面的评论栏告诉我们本文中尚未提及的其他方法。\n\n\n---\n\nvia: http://www.tecmint.com/empty-delete-file-content-linux/\n\n作者：Aaron Kili 译者：FSSlc 校对：jasminepeng\n\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","tags":["bash"],"categories":["system"]},{"title":"redis模糊删除key","url":"/2017/05/25/database/redis模糊删除key/","content":"\nRedis keys命令支持模式匹配，但是del命令不支持模式匹配，有时候需要根据一定的模式来模糊删除key，这时只能结合shell命令来完成了。 具体命令是：\n\n<!-- more -->\n\n```sh\nredis-cli KEYS \"pattern\" | xargs redis-cli DEL\n```\n\n其中pattern是keys命令支持的模式，这样就可以模糊删除key了。服务器上测试删除150万条数据的效率也是很高的。\n\n所有的Redis命令可以在这里找到：http://redis.io/commands\n\nKEYS命令：http://redis.io/commands/keys\n\nDEL命令: http://redis.io/commands/del\n\n**my demo:**\n\nprefix_: 需要删除key的匹配的前缀名\n```sh\nredis-cli KEYS \"prefix_\" | xargs redis-cli DEL \n```\n","tags":["redis"],"categories":["database"]},{"title":"Linux查看文件编码格式及文件编码转换","url":"/2017/05/25/system/Linux查看文件编码格式及文件编码转换/","content":"\n如果你需要在Linux 中操作windows下的文件，那么你可能会经常遇到文件编码转换的问题。Windows中默认的文件格式是GBK(gb2312)，而Linux一般都是UTF-8。下面介绍一下，在Linux中如何查看文件的编码及如何进行对文件进行编码转换。\n\n<!-- more -->\n\n# 查看文件编码\n\n在Linux中查看文件编码可以通过以下几种方式：\n\n### 1.在Vim 中可以直接查看文件编码\n\n```sh\n    :set fileencoding  \n```\n\n即可显示文件编码格式。\n\n如果你只是想查看其它编码格式的文件或者想解决用Vim查看文件乱码的问题，那么你可以在 `~/.vimrc` 文件中添加以下内容：\n\n```sh\n    set encoding=utf-8 fileencodings=ucs-bom,utf-8,cp936\n```\n\n这样，就可以让vim自动识别文件编码（可以自动识别UTF-8或者GBK编码的文件），其实就是依照 fileencodings提供的编码列表尝试，如果没有找到合适的编码，就用latin-1(ASCII)编码打开。\n\n### 2. enca (如果你的系统中没有安装这个命令，可以用sudo yum install -y enca 安装 )查看文件编码\n\n```sh\n$ enca filename\nfilename: Universal transformation format 8 bits; UTF-8\nCRLF line terminators\n```\n\n需要说明一点的是，enca对某些GBK编码的文件识别的不是很好，识别时会出现：\n\n```\nUnrecognized encoding\n```\n\n# 文件编码转换\n\n### 1.在Vim中直接进行转换文件编码,比如将一个文件转换成utf-8格式\n\n```sh\n    :set fileencoding=utf-8  \n```\n\n### 2. enconv 转换文件编码，比如要将一个GBK编码的文件转换成UTF-8编码，操作如下\n\n```sh\nenconv -L zh_CN -x UTF-8 filename\n```\n\n### 3. iconv 转换，iconv的命令格式如下：\n\n```sh\niconv -f encoding -t encoding inputfile\n```\n\n比如将一个UTF-8 编码的文件转换成GBK编码\n\n```sh\niconv -f GBK -t UTF-8 file1 -o file2\n```\n","tags":["字符集"],"categories":["system"]},{"title":"Bash历史中执行过的每一项命令设置时间和日期.md","url":"/2017/05/25/system/Bash历史中执行过的每一项命令设置时间和日期/","content":"\n在默认情况下，所有通过 Bash 在命令行中执行过的命令都被存储在历史缓存区或者一个叫做 ` ~/.bash_history` 的文件里。这意味着系统管理员可以看到系统上用户执行过的命令清单，或者用户可以通过像 `history` 命令这样的选项来看他或她自己的命令历史。\n<!-- more -->\n\n```sh\n[root@l-webdb-docker-dev ~]# history \n    1  vim /gotwo_data/scripts/cronjob/sync_mysql_online.sh\n    2  exit\n    3  ps -ef | grep 4004\n    4  exit\n    5  mysql\n    6  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n    7  vim /tmp/db_ad.sql \n    8  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n```\n\n从上面` history `命令的输出可知，命令被执行的日期和时间并没有显示出来。基本上所有的 Linux 发行版的默认设置都是这样的。\n\n在这篇文章里，我们将解释当在 Bash 中执行` history `命令显示每个命令时，如何配置显示时间戳信息。\n\n每个命令相关的日期和时间可以记录到历史文件中，用 `HISTTIMEFORMAT` 环境变量的设置作为命令历史的备注记录。\n\n这里有两种可行的方式来达到目的：一种是暂时的效果，一种是永久的效果。\n\n要临时设置 `HISTTIMEFORMAT `环境变量，在命令行这样输出它：\n```sh\n $ export HISTTIMEFORMAT='%F %T '\n```\n\n在上面的输出命令当中，时间戳格式如下：\n\n1. `％F`－展开为完整日期，即` ％Y-％m-％d`（年-月-日）。\n\n2. `％T`－展开为时间，即` ％H:％M:％S`（时:分:秒）。\n\n通读 date 命令的 man 手册来获得更多使用说明：\n\n```sh\nman date\n```\n\n（LCTT 译注：注意：这个功能只能用在当 HISTTIMEFORMAT 这个环境变量被设置之后，之后的那些新执行的 bash 命令才会被打上正确的时间戳。在此之前的所有命令，都将会显示成设置 HISTTIMEFORMAT 变量的时间。）\n\n然而，如果你想永久地配置该变量，用你最喜欢的编辑器打开文件 ` ~/.bashrc`\n\n```sh\n    $ vi ~/.bashrc\n```\n    \n然后在下方添加（用注释将其标记为你自己的配置）：\n  \n```sh\n# 我的配置\nexport HISTTIMEFORMAT='%F %T '\n```\n\n保存文件并退出，然后，运行下面的命令以便改动当即生效：\n\n```sh\nsource ~/.bashrc\n```\n","tags":["bash"],"categories":["system"]}]