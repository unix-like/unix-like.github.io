[{"title":"pdflush进程详解与优化","url":"/2017/05/25/pdflush进程详解与优化/","content":"# 一、简介\n\n　　由于页高速缓存的缓存作用，写操作实际上会被延迟。当页高速缓存中的数据比后台存储的数据更新时，那么该数据就被称做脏数据。在内存中累积起来的脏页最终必须被写回磁盘。\n\n<!-- more -->\n\n在以下两种情况发生时，脏页被写回磁盘：\n\n* 当空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。\n\n* 当脏页在内存中驻留时间超过一个特定的阈值时，内核必须将超时的脏页写回磁盘，以确保脏页不会无限期地驻留在内存中。\n\n　　上面两种工作的目的完全不同。实际上，在老内核中，这是由两个独立的内核线程分别完成的。但是在2.6内核中，由一群内核线程—pdflush后台回写例程—统一执行两种工作。\n\n　　我们来看看这两个目标是如何具体实现的。首先，当系统中的空闲内存低于一个特定的阈值时，pdflush线程将脏页刷新回磁盘。该后台回写例程的目的在于在可用物理内存过低时，释放脏页以重新获得内存。特定的内存阈值可以通过`dirty_background_ratio`参数设置。当空闲内存比阈值`dirty_ background_ratio`还低时，内核便会调用函数`wakeup_bdflush()`唤醒一个pdflush线程，随后pdflush线程进一步调用函数`background_writeout()`开始将脏页写回磁盘。函数`background_ writeout()`需要一个长整型参数，该参数指定试图回写的页面数目。\n\n　　函数`background_writeout()`会连续地写出数据，直到满足以下两个条件：\n\n* 已经有指定的最小数目的页被写出到磁盘。\n\n* 空闲内存数已经回升，超过了阈值dirty_background_ratio。\n\n　　上述条件确保了pdflush操作可以减轻系统中内存不足的压力。回写操作不会在达到这两个条件前停止，除非pdflush写回了所有的脏页，没有剩下的脏页可再被写回了。\n\n　　要满足第二个目标，pdflush后台例程会被周期性唤醒（和空闲内存是否过低无关），将那些在内存中驻留时间过长的脏页写出，确保内存中不会有长期存在的脏页。假如系统发生崩溃，则内存会处于混乱之中，而那些在内存中还没来得及写回磁盘的脏页就会丢失，所以周期性同步回写非常重要。\n\n　　在系统启动时，内核初始化一个定时器，让它周期地唤醒pdflush线程，随后使其运行函数`wb_kupdate()`。该函数将把所有驻留时间超过百分之`dirty_expire_centisecs`秒的脏页写回。然后定时器将再次被初始化为百分之`dirty_expire_ centisecs`秒后唤醒pdflush线程。\n\n　　总而言之，pdflush线程周期地被唤醒并且把超过特定期限的脏页写回磁盘。\n\n# 二、proc下的相关控制参数\n\n　　系统管理员可以在/proc/sys/vm中设置回写相关的参数，也可以通过sysctl系统调用设置它们。\n\n* /proc/sys/vm/dirty_ratio\n\n　　这个参数控制一个进程在文件系统中的文件系统写缓冲区的大小，单位是百分比，表示系统内存的百分比，表示当一个进程中写缓冲使用到系统内存多少的时候，再有磁盘写操作时开始向磁盘写出数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是 40。设置方法如下：\n\n```sh\necho 30 >/proc/sys/vm/dirty_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_background_ratio\n\n　　这个参数控制文件系统的pdflush进程，在何时刷新磁盘。单位是百分比，表示系统总内存的百分比，意思是当磁盘的脏数据缓冲到系统内存多少的时候，pdflush开始把脏数据刷新到磁盘。增大会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值.一般缺省是10。设置方法如下：\n\n```sh\necho 8 >/proc/sys/vm/dirty_background_ratio\n```\n\n---\n\n* /proc/sys/vm/dirty_writeback_centisecs\n\n　　Pdflush写后台进程每隔多久被唤醒并执行把脏数据写出到硬盘。单位是 1/100 秒。如果你的系统是持续地写入动作，那么实际上还是降低这个数值比较好，这样可以把尖峰的写操作削平成多次写操作。缺省数值是500，也就是 5 秒。设置方法如下：\n\n```sh\necho 200 >/proc/sys/vm/dirty_writeback_centisecs\n```\n\n---\n\n* /proc/sys/vm/dirty_expire_centisecs\n\n　　这个参数声明Linux内核写缓冲区里面的脏数据多“旧”了之后，pdflush 进程就开始考虑写到磁盘中去。单位是 1/100秒。对于特别重载的写操作来说，这个值适当缩小也是好的，但也不能缩小太多，因为缩小太多也会导致IO提高太快。缺省是 30000，也就是 30 秒的数据就算旧了，将会刷新磁盘。建议设置为 1500，也就是15秒算旧。设置方法如下：\n\n```sh\necho 1500 >/proc/sys/vm/dirty_expire_centisecs\n```\n\n---\n\n# 三、内核参数修改后的生效\n\n　　Linux在系统运行时修改内核参数(/proc/sys与/etc/sysctl.conf)，而不需要重新引导系统，这个功能是通过/proc虚拟文件系统实现的。\n\n　　在/proc/sys目录下存放着大多数的内核参数，并且设计成可以在系统运行的同时进行更改,可以通过更改/proc/sys中内核参数对应的文件达到修改内核参数的目的(修改过后，保存配置文件就马上自动生效)，不过重新启动机器后之前修改的参数值会失效，所以只能是一种临时参数变更方案。(适合调试内核参数优化值的时候使用，如果设置值有问题，重启服务器还原原来的设置参数值了。简单方便。)\n\n　　但是如果调试内核参数优化值结束后，需要永久保存参数值，就要通过修改/etc/sysctl.conf内的内核参数来永久保存更改。但只是修改sysctl文件内的参数值，确认保存修改文件后，设定的参数值并不会马上生效，如果想使参数值修改马上生效，并且不重启服务器，可以执行下面的命令：\n\n```sh\nsysctl –p\n```\n\n---\n\n　　下面介绍一下/proc/sys下内核文件与配置文件sysctl.conf中变量的对应关系：\n\n　　由于可以修改的内核参数都在/proc/sys目录下，所以sysctl.conf的变量名省略了目录的前面部分（/proc/sys）。即将/proc/sys中的文件转换成sysctl中的变量依据下面两个简单的规则：\n\n1. 去掉前面部分/proc/sys\n2. 将文件名中的斜杠变为点\n\n　　这两条规则可以将/proc/sys中的任一文件名转换成sysctl中的变量名。\n\n　　例如：\n\n```sh\n/proc/sys/net/ipv4/ip_forward ＝》 net.ipv4.ip_forward\n/proc/sys/kernel/hostname ＝》 kernel.hostname\n```\n\n　　可以使用下面命令查询所有可修改的变量名\n\n```sh\nsysctl –a\n```\n","tags":["调优"],"categories":["system"]},{"title":"MongoDB归档及压缩工具","url":"/2017/05/25/MongoDB归档及压缩工具/","content":"　　原文地址：http://t.dbdao.com/archives/archiving-and-compression-in-mongodb-tools.html\n\n\n# 介绍\n\n　　我在MongoDB World 2015做的演讲“Putting the Go in MongoDB”，重点是关于MongoDB工具的重写，从C ++到Go，这在可用性以及性能方面得到了一些改进，但是这里我只简要的说两个方面的新功能，(planned for the 3.2 release) – 归档和压缩。\n\n　　在本文中，我将对mongodump和mongorestore提供更详细的归档和压缩特性说明，并探索使用这些特性的可行用例。\n\n\n<!-- more -->\n\n# 概述\n\n　　一个通常目的的归档一般由一个或多个文件组成。这样例子如磁带归档格式(tar)，其中包含按顺序组成的一个或多个文件。归档在执行进程间通信的应用程序中尤其有用，例如，你可以通过远程服务器进行目录的tarball压缩，然后通过SSH，传送到到本机上进行解压：\n\n```ssh\nssh source.server.com tar c sourceDirectory | tar x\n```\n\n　　由于归档以顺序的方式创建，接收端将能按顺序接收到发送端按顺序发来的数据。\n\n　　在3.0中，我们增加了在MongoDB中并发执行备份和恢复多个集合的能力，这可以让你执行备份时，更加充分地利用磁盘I / O。 结果，写入mongodump的备份并不一定以顺序的方式接收。 同样，mongorestore同时读取还原操作集合，它的读取指令也并非是序列性的。\n\n　　通用归档格式，如tar，只支持连续的文件归档打包。mongodump和mongorestore利用这些备份格式，将得到一个不可接受的性能退化， 由于所有集合的数据将不得不被按顺序写入和读出。为了支持这些工具的并发行为，我们研发了一个特殊的通用备份格式，支持非并发文件的写入。 这个新的归档特性极大了提高了备份和还原操作的效率。\n\n# 背景\n\n　　为了按上下文情况进行备份，我们考虑一下你们通常是如何创建备份的。比如，假设你有一个“country”的数据库，其中含有两个集合： “nigeria” and “austria”， 你可能会这样操作：\n\n```sh\t\nmongodump --db country\n```\n\n　　上面的指令读取“country”数据库的所有集合， 然后将其写入“dump”目录。 上面的指令就会产生以下的目录列表：\n\n```sh\ndump/\n└── [4.3M]  country\n    ├── [2.1M]  austria.bson\n    ├── [  87]  austria.metadata.json\n    ├── [2.1M]  nigeria.bson\n    ├── [  87]  nigeria.metadata.json\n    └── [ 140]  system.indexes.bson\n \n1 directory, 5 files\n```\n\n　　你也可以备份整个服务器-这里的服务器包含两个数据库(country 和product)。\n\n```sh\nmongodump\n```\n\n```sh\n├── [5.4M]  dump\n│   ├── [4.03M]  country\n│   │   ├── [2.1M]  austria.bson\n│   │   ├── [  87]  austria.metadata.json\n│   │   ├── [2.1M]  nigeria.bson\n│   │   ├── [  87]  nigeria.metadata.json\n│   │   └── [ 140]  system.indexes.bson\n│   └── [1.1M]  product\n│       ├── [1.0M]  mongodump.bson\n│       ├── [  89]  mongodump.metadata.json\n│       └── [  72]  system.indexes.bson\n2 directories, 8 files\n```\n\n　　或选择备份单个集合到标准输出，而不是一个目录：\n\n```sh\t\nmongodump --db country --collection nigeria --out -\n```\n\n# 归档支持\n\n　　在3.2中，我们引入了创建备份的一个附加模式 －－ “归档”模式，写入所有转储数据，甚至从不同的数据库和集合到单一的输出文件。 使用mongodump创建归档是极为简单的 – 只需要一个附加选项：\n\n```sh\nmongodump --db country --archive=country.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 4.2M Jun 29 11:12 country.archive\n```\n\n　　上面的指令将在“country.archive”文件中创建“country”的数据库归档。默认情况下，归档被写入到标准输出。不同于目录模式的执行备份，创建目录树，默认归档模式下备份结果就是一个单一的文件， 包含“country”数据库的所有数据-所有集合，索引等。\n\n　　你也可以备份一个单一的集合或整个服务器的内容：\n\n　　**单一集合：**\n\n```sh\t\nmongodump --db country --collection nigeria --archive=nga.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 2.1M Jun 29 11:15 nga.archive\n```\n\n　　**整个服务器：**\n\n```sh\nmongodump --archive=server.archive\n\t\n-rw-rw-r-- 1 wisdom wisdom 5.3M Jun 29 11:26 server.archive\n```\n\n　　在mongodump的这种情况下，归档模式允许多个集合以非连续的方式打包在归档文件内。在mongorestore中，它允许多个集合进行并行恢复。这样，你可以在网络上执行数据迁移，降低磁盘I/O所占空间，享受到充分利用工具和底层存储引擎的并发所带来的好处。\n\n# 数据迁移\n\n　　一个新的备份改善的例子， 是mongodump和mongorestore之间的进程间通信 – 特别是能够将数据从一个传到另一个。在以前的版本中，这种支持有限 – 一个时间只能传输一个集合。现在，使用归档就没有这样的限制。这种方式对于数据库服务器出于安全考虑而安装有防火墙的情况下很有用。在这种情况下，一个通常的设计是允许一个或多个服务器方访问数据库。使用归档功能，在SSH上进行数据转移数据，就轻而易举了：\n\n```sh\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive  | ssh wisdom@target.server.com mongorestore --archive\n```\n\n　　上面的指令使用SSH方式连接到代理主机（proxy.server.com），访问源服务器（source.server.com），在代理服务器上运行mongodump，为了最终的恢复，将源服务器的发送内容（通过SSH）到目标服务器（target.server.com）。\n\n　　如果没有归档，通过mongodump完成这些操作的唯一办法就是，先执行备份到磁盘，在将文件复制到目标服务器，然后运行mongorestore。通过备份，一个指令就可以完成- 无需任何附加磁盘I/O的开销。\n\n# 压缩支持\n\n　　除了备份，我们还使用gzip进行压缩。这是通过在mongodump和mongorestore中引入一个新的指令行选项 “--gzip” 实现的。 压缩可用于目录以及归档模型下创建的备份，压缩还可以减少磁盘空间使用。\n\n```sh\nmongodump --db country --gzip\n```\n\n　　生成：\n\n```sh\ndump/\n└── [568K]  country\n    ├── [254K]  austria.bson.gz\n    ├── [ 100]  austria.metadata.json.gz\n    ├── [254K]  nigeria.bson.gz\n    ├── [ 100]  nigeria.metadata.json.gz\n    └── [  91]  system.indexes.bson.gz\n \n1 directory, 5 files\n```\n\n　　注意,目录模型的归档备份大小-568KB-比没有压缩的备份要小很多-4.3MB.\n\n　　**压缩归档：**\n\n```sh\nmongodump --db country --gzip --archive=country.archive\n\n-rw-rw-r-- 1 wisdom wisdom 509K Jun 29 11:23 country.archive\n```\n\n　　对于归档来说，数据在写入归档之前需要先压缩。\n\n　　恢复压缩目录模式备份，你应该运行：\n\n```sh\t\nmongorestore --gzip\n```\n\n　　类似用来恢复归档模式下的压缩备份的命令：\n\n```sh\t\nssh wisdom@proxy.server.com mongodump --host source.server.com --archive --gzip  | ssh wisdom@target.server.com mongorestore --archive --gzip\n```\n\n　　数据迁移不会产生任何磁盘I / O开销，由于压缩，将会使用更少的网络带宽。\n\n# 总结\n\n　　归档和压缩特性产生了许多用于进行备份和恢复操作的例子。如果你们正在使用MongoDB工具和其它类型的应用程序，我们也乐于倾听你们的经验及用例。 尽管目前最新版本工具还不文档，不过希望大家先对这些特性体验起来。\n\n　　**注：** 作为提供共享集群的集群范围快照的唯一备份解决方案，MongoDB Ops Manager和MongoDB Cloud Mannager被推荐用于较大的MongoDB部署。\n","tags":["mongodb"],"categories":["database"]},{"title":"Linux下清空或删除大文件内容的5种方法","url":"/2017/05/25/Linux下清空或删除大文件内容的5种方法/","content":"\n\n编译自：http://www.tecmint.com/empty-delete-file-content-linux/ 作者： Aaron Kili\n\n原创：LCTT https://linux.cn/article-8024-1.html 译者： FSSlc \n\n在 Linux 终端下处理文件时，有时我们想直接清空文件的内容但又不必使用任何 Linux 命令行编辑器 去打开这些文件。那怎样才能达到这个目的呢？在这篇文章中，我们将介绍几种借助一些实用的命令来清空文件内容的方法。\n\n**注意：** 在我们进一步深入了解这些方法之前，请记住: 由于在 Linux 中一切皆文件，你需要时刻注意，确保你将要清空的文件不是重要的用户文件或者系统文件。清空重要的系统文件或者配置文件可能会引发严重的应用失败或者系统错误。\n\n前面已经说道，下面的这些方法都是从命令行中达到清空文件的目的。\n\n**提示：** 在下面的示例中，我们将使用名为 access.log 的文件来作为示例样本。\n<!-- more -->\n\n# 1. 通过重定向到 Null 来清空文件内容\n\n清空或者让一个文件成为空白的最简单方式，是像下面那样，通过 shell 重定向 `null` （不存在的事物）到该文件：\n\n```sh\n> access.log\n```\n\n```sh\n[root@localhost logs]# du -sh catalina.out \n9.7G\tcatalina.out\n[root@localhost logs]# > catalina.out \n[root@localhost logs]# du -sh catalina.out \n0\tcatalina.out\n```\n\n在 Linux 下使用 Null 重定向来清空大文件\n\n# 2. 使用 `true` 命令重定向来清空文件\n\n下面我们将使用 : 符号，它是 shell 的一个内置命令，等同于 true 命令，它可被用来作为一个 no-op（即不进行任何操作）。\n\n另一种清空文件的方法是将 : 或者 true 内置命令的输出重定向到文件中，具体如下：\n\n```sh\n: > access.log\n```\n 或\n```sh\ntrue > access.log\n```\n\n使用 Linux 命令清空大文件\n\n# 3. 使用 cat/cp/dd 实用工具及 /dev/null 设备来清空文件\n\n在 Linux 中， null 设备基本上被用来丢弃某个进程不再需要的输出流，或者作为某个输入流的空白文件，这些通常可以利用重定向机制来达到。\n\n所以 /dev/null 设备文件是一个特殊的文件，它将清空送到它这里来的所有输入，而它的输出则可被视为一个空文件。\n\n另外，你可以通过使用 cat 命令 显示 /dev/null 的内容然后重定向输出到某个文件，以此来达到清空该文件的目的。\n\n```sh\ncat /dev/null > access.log\n```\n\n使用 cat 命令来清空文件\n\n下面，我们将使用 cp 命令 复制 /dev/null 的内容到某个文件来达到清空该文件的目的，具体如下所示：\n\n```sh\ncp /dev/null access.log\n```\n\n\n使用 cp 命令来清空文件\n\n而下面的命令中， if 代表输入文件，of 代表输出文件。\n\n```sh\ndd if=/dev/null of=access.log\n```\n\n\n使用 dd 命令来清空文件内容\n\n# 4. 使用 echo 命令清空文件\n\n在这里，你可以使用 echo 命令 将空字符串的内容重定向到文件中，具体如下：\n\n```sh\necho \"\" > access.log\n```\n或者\n ```sh\n echo > access.log\n```\n\n使用 echo 命令来清空文件\n\n**注意：**你应该记住空字符串并不等同于 null 。字符串表明它是一个具体的事物，只不过它的内容可能是空的，但 null 则意味着某个事物并不存在。\n\n基于这个原因，当你将 echo 命令 的输出作为输入重定向到文件后，使用 cat 命令 来查看该文件的内容时，你将看到一个空白行（即一个空字符串）。\n\n要将 null 做为输出输入到文件中，你应该使用 -n 选项，这个选项将告诉 echo 不再像上面的那个命令那样输出结尾的那个新行。\n\n```sh\necho -n \"\" > access.log\n```\n\n使用 Null 重定向来清空文件\n\n# 5. 使用 truncate 命令来清空文件内容\n\ntruncate 可被用来将一个文件缩小或者扩展到某个给定的大小。\n\n你可以利用它和 -s 参数来特别指定文件的大小。要清空文件的内容，则在下面的命令中将文件的大小设定为 0:\n\n```sh\ntruncate -s 0 access.log\n```\n\n在 Linux 中截断文件内容\n\n我要介绍的就是这么多了。在本文中，我们介绍了几种通过使用一些简单的命令行工具和 shell 重定向机制来清除或清空文件内容的方法。\n\n上面介绍的这些可能并不是达到清空文件内容这个目的的所有可行的实践方法，所以你也可以通过下面的评论栏告诉我们本文中尚未提及的其他方法。\n\n\n---\n\nvia: http://www.tecmint.com/empty-delete-file-content-linux/\n\n作者：Aaron Kili 译者：FSSlc 校对：jasminepeng\n\n本文由 LCTT 原创编译，Linux中国 荣誉推出\n","tags":["bash"],"categories":["system"]},{"title":"redis模糊删除key","url":"/2017/05/25/redis模糊删除key/","content":"\nRedis keys命令支持模式匹配，但是del命令不支持模式匹配，有时候需要根据一定的模式来模糊删除key，这时只能结合shell命令来完成了。 具体命令是：\n\n<!-- more -->\n\n```sh\nredis-cli KEYS \"pattern\" | xargs redis-cli DEL\n```\n\n其中pattern是keys命令支持的模式，这样就可以模糊删除key了。服务器上测试删除150万条数据的效率也是很高的。\n\n所有的Redis命令可以在这里找到：http://redis.io/commands\n\nKEYS命令：http://redis.io/commands/keys\n\nDEL命令: http://redis.io/commands/del\n\n**my demo:**\n\nprefix_: 需要删除key的匹配的前缀名\n```sh\nredis-cli KEYS \"prefix_\" | xargs redis-cli DEL \n```\n","tags":["redis"],"categories":["database"]},{"title":"Linux查看文件编码格式及文件编码转换","url":"/2017/05/25/Linux查看文件编码格式及文件编码转换/","content":"\n如果你需要在Linux 中操作windows下的文件，那么你可能会经常遇到文件编码转换的问题。Windows中默认的文件格式是GBK(gb2312)，而Linux一般都是UTF-8。下面介绍一下，在Linux中如何查看文件的编码及如何进行对文件进行编码转换。\n\n<!-- more -->\n\n# 查看文件编码\n\n在Linux中查看文件编码可以通过以下几种方式：\n\n### 1.在Vim 中可以直接查看文件编码\n\n```sh\n    :set fileencoding  \n```\n\n即可显示文件编码格式。\n\n如果你只是想查看其它编码格式的文件或者想解决用Vim查看文件乱码的问题，那么你可以在 `~/.vimrc` 文件中添加以下内容：\n\n```sh\n    set encoding=utf-8 fileencodings=ucs-bom,utf-8,cp936\n```\n\n这样，就可以让vim自动识别文件编码（可以自动识别UTF-8或者GBK编码的文件），其实就是依照 fileencodings提供的编码列表尝试，如果没有找到合适的编码，就用latin-1(ASCII)编码打开。\n\n### 2. enca (如果你的系统中没有安装这个命令，可以用sudo yum install -y enca 安装 )查看文件编码\n\n```sh\n$ enca filename\nfilename: Universal transformation format 8 bits; UTF-8\nCRLF line terminators\n```\n\n需要说明一点的是，enca对某些GBK编码的文件识别的不是很好，识别时会出现：\n\n```\nUnrecognized encoding\n```\n\n# 文件编码转换\n\n### 1.在Vim中直接进行转换文件编码,比如将一个文件转换成utf-8格式\n\n```sh\n    :set fileencoding=utf-8  \n```\n\n### 2. enconv 转换文件编码，比如要将一个GBK编码的文件转换成UTF-8编码，操作如下\n\n```sh\nenconv -L zh_CN -x UTF-8 filename\n```\n\n### 3. iconv 转换，iconv的命令格式如下：\n\n```sh\niconv -f encoding -t encoding inputfile\n```\n\n比如将一个UTF-8 编码的文件转换成GBK编码\n\n```sh\niconv -f GBK -t UTF-8 file1 -o file2\n```\n","tags":["字符集"],"categories":["system"]},{"title":"Bash历史中执行过的每一项命令设置时间和日期.md","url":"/2017/05/25/Bash历史中执行过的每一项命令设置时间和日期/","content":"\n在默认情况下，所有通过 Bash 在命令行中执行过的命令都被存储在历史缓存区或者一个叫做 ` ~/.bash_history` 的文件里。这意味着系统管理员可以看到系统上用户执行过的命令清单，或者用户可以通过像 `history` 命令这样的选项来看他或她自己的命令历史。\n<!-- more -->\n\n```sh\n[root@l-webdb-docker-dev ~]# history \n    1  vim /gotwo_data/scripts/cronjob/sync_mysql_online.sh\n    2  exit\n    3  ps -ef | grep 4004\n    4  exit\n    5  mysql\n    6  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n    7  vim /tmp/db_ad.sql \n    8  mysqldump -uroot -p db_ad > /tmp/db_ad.sql\n```\n\n从上面` history `命令的输出可知，命令被执行的日期和时间并没有显示出来。基本上所有的 Linux 发行版的默认设置都是这样的。\n\n在这篇文章里，我们将解释当在 Bash 中执行` history `命令显示每个命令时，如何配置显示时间戳信息。\n\n每个命令相关的日期和时间可以记录到历史文件中，用 `HISTTIMEFORMAT` 环境变量的设置作为命令历史的备注记录。\n\n这里有两种可行的方式来达到目的：一种是暂时的效果，一种是永久的效果。\n\n要临时设置 `HISTTIMEFORMAT `环境变量，在命令行这样输出它：\n```sh\n $ export HISTTIMEFORMAT='%F %T '\n```\n\n在上面的输出命令当中，时间戳格式如下：\n\n1. `％F`－展开为完整日期，即` ％Y-％m-％d`（年-月-日）。\n\n2. `％T`－展开为时间，即` ％H:％M:％S`（时:分:秒）。\n\n通读 date 命令的 man 手册来获得更多使用说明：\n\n```sh\nman date\n```\n\n（LCTT 译注：注意：这个功能只能用在当 HISTTIMEFORMAT 这个环境变量被设置之后，之后的那些新执行的 bash 命令才会被打上正确的时间戳。在此之前的所有命令，都将会显示成设置 HISTTIMEFORMAT 变量的时间。）\n\n然而，如果你想永久地配置该变量，用你最喜欢的编辑器打开文件 ` ~/.bashrc`\n\n```sh\n    $ vi ~/.bashrc\n```\n    \n然后在下方添加（用注释将其标记为你自己的配置）：\n  \n```sh\n# 我的配置\nexport HISTTIMEFORMAT='%F %T '\n```\n\n保存文件并退出，然后，运行下面的命令以便改动当即生效：\n\n```sh\nsource ~/.bashrc\n```\n","tags":["bash"],"categories":["system"]}]